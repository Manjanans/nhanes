{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *NHANES Case Study: Pre-Pandemic Health Baseline Modeling Research* #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Pandemic Health Baseline: An Analysis Based on NHANES 2017-2020 Data\n",
    "\n",
    "This report presents a comprehensive analysis of data collected by the National Health and Nutrition Examination Survey (NHANES) during the 2017-2020 cycle, specifically focusing on pre-pandemic health metrics. The NHANES technical report for this period serves as the primary source of data, documenting extensive information on demographic variables, nutritional assessments, and health indicators that characterize the population's health status before the onset of the COVID-19 pandemic.\n",
    "\n",
    "Within this report, you'll find detailed insights into age, gender, socioeconomic status, and ethnicity distributions alongside health measures such as body composition, blood pressure, dietary intake, and physical activity. This pre-pandemic data serves as a critical baseline, helping to delineate shifts in health trends and highlight areas for targeted intervention in a post-pandemic context. For complete methodologies, statistical treatments, and data interpretations, please refer to the NHANES 2017-2020 pre-pandemic technical report, which underpins this analysis and provides the foundation for all reported findings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Importing Libraries and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The kedro.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext kedro.ipython\n"
     ]
    }
   ],
   "source": [
    "%load_ext kedro.ipython\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import mstats\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.impute import KNNImputer\n",
    "scaler = StandardScaler()\n",
    "minmax = MinMaxScaler()\n",
    "pt = PowerTransformer(method='yeo-johnson')\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[10/25/24 17:59:12] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #ff8700; text-decoration-color: #ff8700\">demografia</span> <span style=\"font-weight: bold\">(</span>ParquetDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py:389</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[10/25/24 17:59:12]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[38;5;208mdemografia\u001b[0m \u001b[1m(\u001b[0mParquetDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                   \u001b[2mdata_catalog.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m389\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #ff8700; text-decoration-color: #ff8700\">insulina</span> <span style=\"font-weight: bold\">(</span>ParquetDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py:389</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[38;5;208minsulina\u001b[0m \u001b[1m(\u001b[0mParquetDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                     \u001b[2mdata_catalog.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m389\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #ff8700; text-decoration-color: #ff8700\">colesterol</span> <span style=\"font-weight: bold\">(</span>ParquetDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py:389</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[38;5;208mcolesterol\u001b[0m \u001b[1m(\u001b[0mParquetDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                   \u001b[2mdata_catalog.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m389\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #ff8700; text-decoration-color: #ff8700\">depresion</span> <span style=\"font-weight: bold\">(</span>ParquetDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py:389</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[38;5;208mdepresion\u001b[0m \u001b[1m(\u001b[0mParquetDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                    \u001b[2mdata_catalog.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m389\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #ff8700; text-decoration-color: #ff8700\">proteinaC</span> <span style=\"font-weight: bold\">(</span>ParquetDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py:389</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[38;5;208mproteinaC\u001b[0m \u001b[1m(\u001b[0mParquetDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                    \u001b[2mdata_catalog.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m389\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #ff8700; text-decoration-color: #ff8700\">perfilBioquimico</span> <span style=\"font-weight: bold\">(</span>ParquetDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py:389</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[38;5;208mperfilBioquimico\u001b[0m \u001b[1m(\u001b[0mParquetDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m             \u001b[2mdata_catalog.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m389\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #ff8700; text-decoration-color: #ff8700\">presionArterial</span> <span style=\"font-weight: bold\">(</span>ParquetDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py:389</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[38;5;208mpresionArterial\u001b[0m \u001b[1m(\u001b[0mParquetDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m              \u001b[2mdata_catalog.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m389\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #ff8700; text-decoration-color: #ff8700\">medidasCorporales</span> <span style=\"font-weight: bold\">(</span>ParquetDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py:389</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[38;5;208mmedidasCorporales\u001b[0m \u001b[1m(\u001b[0mParquetDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m            \u001b[2mdata_catalog.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m389\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "demografia = catalog.load(\"demografia\")\n",
    "insulina = catalog.load(\"insulina\")\n",
    "colesterol = catalog.load(\"colesterol\")\n",
    "depresion = catalog.load(\"depresion\")\n",
    "proteinaC = catalog.load(\"proteinaC\")\n",
    "perfilB = catalog.load(\"perfilBioquimico\")\n",
    "presion = catalog.load(\"presionArterial\")\n",
    "medidas = catalog.load(\"medidasCorporales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframes = {\n",
    "    'demografia': demografia,\n",
    "    'insulina': insulina,\n",
    "    'colesterol': colesterol,\n",
    "    'depresion': depresion,\n",
    "    'proteinaC': proteinaC,\n",
    "    'perfilBioquimico': perfilB,\n",
    "    'presionArterial': presion,\n",
    "    'medidasCorporales': medidas\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Initial Research Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the variables present in the different datasets, some questions can be posed for future research:\n",
    "\n",
    "1. What is the impact of waist circumference on serum lipid levels?\n",
    "2. How do lipid and glucose levels vary by age, and which age groups are most vulnerable to metabolic disorders?\n",
    "3. How do gender and age affect correlations among these biomarkers?\n",
    "4. What relationship exists between electrolyte levels and basic bodily functions, such as blood pressure and kidney function?\n",
    "5. As age increases, how does this affect blood insulin and cholesterol results?\n",
    "6. Does a higher poverty index level correlate with an increase in depressive symptoms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Identifying Targets for Questions and Future Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:**  \n",
    "- **Model Type:** Regression  \n",
    "- **Target Variable:** Total Cholesterol, refrigerated serum (mg/dL)  \n",
    "- **Predictive Variables:** Waist Circumference (cm), Triglycerides, refrigerated serum (mg/dL)\n",
    "\n",
    "**Question 2:**  \n",
    "- **Model Type:** Classification  \n",
    "- **Target Variable:** Age Group (e.g., pre-infant, infant, child, adolescent)  \n",
    "- **Predictive Variables:** Triglycerides, refrigerated serum (mg/dL), Total Cholesterol, refrigerated serum (mg/dL), Glucose, refrigerated serum (mg/dL), Waist Circumference (cm), BMI\n",
    "\n",
    "**Question 3:**  \n",
    "- **Model Type:** Classification  \n",
    "- **Target Variable:** Correlations among biomarkers (e.g., risk level: low, medium, high)  \n",
    "- **Predictive Variables:** Gender, Age, Total Cholesterol, refrigerated serum (mg/dL), Triglycerides, refrigerated serum (mg/dL), Glucose, refrigerated serum (mg/dL)\n",
    "\n",
    "**Question 4:**  \n",
    "- **Model Type:** Regression  \n",
    "- **Target Variable:** Basic bodily functions (e.g., blood pressure, kidney function)  \n",
    "- **Predictive Variables:** Electrolyte levels\n",
    "\n",
    "**Question 5:**  \n",
    "- **Model Type:** Regression  \n",
    "- **Target Variable:** Blood Insulin Levels and Total Cholesterol, refrigerated serum (mg/dL)  \n",
    "- **Predictive Variables:** Age\n",
    "\n",
    "**Question 6:**  \n",
    "- **Model Type:** Regression  \n",
    "- **Target Variable:** Depressive Symptoms  \n",
    "- **Predictive Variables:** Poverty Index Level, Age, Gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Data Preparation Overview ###\n",
    "\n",
    "In the data preparation phase, we will handle missing values, convert categorical variables, create age groups, scale numerical features, and identify outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "demografia.loc[demografia[\"Edad en años al momento del examen\"] <= 13, \"Nivel educativo - Adultos 20+\"] = demografia.loc[demografia[\"Edad en años al momento del examen\"] <= 13, \"Nivel educativo - Adultos 20+\"].fillna(1)\n",
    "demografia.loc[demografia[\"Edad en años al momento del examen\"] <= 19, \"Nivel educativo - Adultos 20+\"] = demografia.loc[demografia[\"Edad en años al momento del examen\"] <= 19, \"Nivel educativo - Adultos 20+\"].fillna(2)\n",
    "demografia.loc[demografia[\"Edad en años al momento del examen\"] <= 18, \"Estado civil\"] = demografia.loc[demografia[\"Edad en años al momento del examen\"] <= 18, \"Estado civil\"].fillna(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " El IQR es 10.3. El límite inferior es: -9.14, el superior es 32.06\n",
      "310\n"
     ]
    }
   ],
   "source": [
    "Q1 = insulina[\"Insulina (μU/mL)\"].quantile(0.25)\n",
    "Q3 = insulina[\"Insulina (μU/mL)\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Calculating the bounds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "print(f\" El IQR es {IQR}. El límite inferior es: {lower_bound}, el superior es {upper_bound}\")\n",
    "\n",
    "# Identifying outliers\n",
    "outliers = insulina[(insulina[\"Insulina (μU/mL)\"] < lower_bound) | (insulina[\"Insulina (μU/mL)\"] > upper_bound)]\n",
    "\n",
    "# Removing outliers\n",
    "consideracion_insulina_limpio = insulina[~((insulina[\"Insulina (μU/mL)\"] < lower_bound) | (insulina[\"Insulina (μU/mL)\"] > upper_bound))]\n",
    "\n",
    "# Checking the number of outliers\n",
    "num_outliers = len(outliers)\n",
    "\n",
    "print(num_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "escalado = scaler.fit_transform(consideracion_insulina_limpio[[\"Insulina (μU/mL)\"]])\n",
    "insulina_escalado = consideracion_insulina_limpio.copy()\n",
    "insulina_escalado[\"Insulina (μU/mL)\"]=escalado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The IQR is 1.2941829291513374. The lower bound is: -2.6984244447452377, the upper bound is 2.478307271860112\n",
      "115\n"
     ]
    }
   ],
   "source": [
    "Q1 = insulina_escalado[\"Insulina (μU/mL)\"].quantile(0.25)\n",
    "Q3 = insulina_escalado[\"Insulina (μU/mL)\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Calculating the bounds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "print(f\"The IQR is {IQR}. The lower bound is: {lower_bound}, the upper bound is {upper_bound}\")\n",
    "\n",
    "# Identifying outliers\n",
    "outliers = insulina_escalado[(insulina_escalado[\"Insulina (μU/mL)\"] < lower_bound) | (insulina_escalado[\"Insulina (μU/mL)\"] > upper_bound)]\n",
    "\n",
    "# Removing outliers\n",
    "limpieza_insulina = insulina_escalado[~((insulina_escalado[\"Insulina (μU/mL)\"] < lower_bound) | (insulina_escalado[\"Insulina (μU/mL)\"] > upper_bound))]\n",
    "\n",
    "# Checking the number of outliers\n",
    "num_outliers = len(outliers)\n",
    "\n",
    "print(num_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputador = KNNImputer(n_neighbors=3, weights=\"uniform\")\n",
    "insulina_limpia = limpieza_insulina.copy()\n",
    "insulina_limpia[\"Insulina (μU/mL)\"] = imputador.fit_transform(limpieza_insulina[[\"Insulina (μU/mL)\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "insulina_limpia[\"Insulina (μU/mL)\"] = pt.fit_transform(insulina_limpia[[\"Insulina (μU/mL)\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " El IQR es 52.0. El límite inferior es: 71.0, el superior es 279.0\n",
      "177\n"
     ]
    }
   ],
   "source": [
    "Q1 = colesterol[\"Colesterol Total (mg/dL)\"].quantile(0.25)\n",
    "Q3 = colesterol[\"Colesterol Total (mg/dL)\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Calculating the bounds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "print(f\" El IQR es {IQR}. El límite inferior es: {lower_bound}, el superior es {upper_bound}\")\n",
    "\n",
    "# Identifying outliers\n",
    "outliers_colesterol = colesterol[(colesterol[\"Colesterol Total (mg/dL)\"] < lower_bound) | (colesterol[\"Colesterol Total (mg/dL)\"] > upper_bound)]\n",
    "\n",
    "# Removing outliers\n",
    "consideracion_colesterol_limpio = colesterol[~((colesterol[\"Colesterol Total (mg/dL)\"] < lower_bound) | (colesterol[\"Colesterol Total (mg/dL)\"] > upper_bound))]\n",
    "\n",
    "# Checking the number of outliers\n",
    "num_outliers = len(outliers_colesterol)\n",
    "\n",
    "print(num_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputador_colesterol = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "colesterol_limpio = consideracion_colesterol_limpio.copy()\n",
    "colesterol_limpio[\"Colesterol Total (mg/dL)\"] = imputador_colesterol.fit_transform(colesterol_limpio[[\"Colesterol Total (mg/dL)\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "colesterol_limpio[\"Colesterol Total (mg/dL)\"] = pt.fit_transform(colesterol_limpio[[\"Colesterol Total (mg/dL)\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Datasets and Modeling ##\n",
    "\n",
    "To conduct a comprehensive analysis, we need to merge the separate datasets, especially tailored for each of the questions we aim to address."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Question 1: What is the impact of waist circumference on serum lipid levels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ID  Edad en años al momento del examen  \\\n",
      "0 109264.00                               13.00   \n",
      "1 109266.00                               29.00   \n",
      "2 109271.00                               49.00   \n",
      "3 109273.00                               36.00   \n",
      "4 109274.00                               68.00   \n",
      "\n",
      "   Triglicéridos, suero refrigerado (mg/dL)  \\\n",
      "0                                     54.00   \n",
      "1                                     86.00   \n",
      "2                                    101.00   \n",
      "3                                    178.00   \n",
      "4                                    151.00   \n",
      "\n",
      "   Colesterol Total, suero refrigerado (mg/dL)  \\\n",
      "0                                       170.00   \n",
      "1                                       199.00   \n",
      "2                                       148.00   \n",
      "3                                       168.00   \n",
      "4                                       105.00   \n",
      "\n",
      "   Circunferencia de la cintura (cm)  Índice de masa corporal (kg/m²)  \n",
      "0                              63.80                            17.60  \n",
      "1                             117.90                            37.80  \n",
      "2                             120.40                            29.70  \n",
      "3                              86.80                            21.90  \n",
      "4                             109.60                            30.20  \n",
      "Cantidad de registros combinados: (10409, 6)\n"
     ]
    }
   ],
   "source": [
    "demografia_filtered = demografia[['ID', 'Edad en años al momento del examen']]\n",
    "perfilBioquimico_filtered = perfilB[['ID', 'Triglicéridos, suero refrigerado (mg/dL)', 'Colesterol Total, suero refrigerado (mg/dL)']]\n",
    "medidasCorporales_filtered = medidas[['ID', 'Circunferencia de la cintura (cm)', 'Índice de masa corporal (kg/m²)']]\n",
    "\n",
    "# merge\n",
    "question1 = demografia_filtered.merge(perfilBioquimico_filtered, on='ID', how='inner')\n",
    "question1 = question1.merge(medidasCorporales_filtered, on='ID', how='inner')\n",
    "\n",
    "# Revisar el dataframe resultante\n",
    "print(question1.head())\n",
    "print(\"Cantidad de registros combinados:\", question1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python311\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/440 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.0702723519755353\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.07125279212325746\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.07125279212325746\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.07125279212325746\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.07125279212325746\n",
      "\n",
      "Generation 6 - Current best internal CV score: 0.07125279212325746\n",
      "\n",
      "Generation 7 - Current best internal CV score: 0.07248081105022319\n",
      "\n",
      "Generation 8 - Current best internal CV score: 0.07248081105022319\n",
      "\n",
      "Generation 9 - Current best internal CV score: 0.0736079753749836\n",
      "\n",
      "Generation 10 - Current best internal CV score: 0.0736079753749836\n",
      "\n",
      "Best pipeline: ExtraTreesRegressor(RidgeCV(input_matrix), bootstrap=True, max_features=0.9500000000000001, min_samples_leaf=20, min_samples_split=20, n_estimators=100)\n",
      "Regresión Score (R²): 0.0798373399926241\n",
      "MAE: 54.28359925891938\n",
      "MSE: 8129.0180073045985\n",
      "RMSE: 90.16106702620925\n",
      "R²: 0.0798373399926241\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Ajuste para evitar el problema de `np.float`\n",
    "if not hasattr(np, 'float'):\n",
    "    np.float = float\n",
    "\n",
    "# Selección de variables predictoras y el target\n",
    "X = question1[['Circunferencia de la cintura (cm)', 'Índice de masa corporal (kg/m²)', 'Edad en años al momento del examen']]\n",
    "y = question1['Triglicéridos, suero refrigerado (mg/dL)']\n",
    "\n",
    "# Imputación de valores faltantes en X y y\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "y_imputed = imputer.fit_transform(y.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Normalización de los datos\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "# División de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_imputed, train_size=0.75, test_size=0.25, random_state=42)\n",
    "\n",
    "# TPOT para regresión con más generaciones y mayor población\n",
    "tpot_regressor = TPOTRegressor(verbosity=2, generations=10, population_size=40, random_state=42, scoring='r2')\n",
    "tpot_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el modelo\n",
    "print(\"Regresión Score (R²):\", tpot_regressor.score(X_test, y_test))\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred = tpot_regressor.predict(X_test)\n",
    "\n",
    "# Calcular métricas de evaluación\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R²: {r2}\")\n",
    "\n",
    "# Exportar el mejor pipeline\n",
    "tpot_regressor.export('best_pipeline_regression.py')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TPOTRegressor:\n",
    "The TPOTRegressor is an **Automated Machine Learning (AutoML)** approach that uses **genetic algorithms** to optimize a regression pipeline by automatically adjusting combinations of models, preprocessing, and parameters. In this case, it was configured with **10 generations**, a **population of 20**, and a **random state (random_state=42)** to ensure reproducibility, while **verbosity 2** provides a detailed progress log.\n",
    "\n",
    "#### Preprocessing:\n",
    "- Imputation by mean to handle missing values in predictor and target variables.\n",
    "\n",
    "#### Model Results:\n",
    "- **Best pipeline:** *AdaBoostRegressor(input_matrix, learning_rate=0.001, loss=exponential, n_estimators=100)*\n",
    "\n",
    "#### Selected Model by TPOT\n",
    "The chosen model is an **ExtraTreesRegressor** with an internal **RidgeCV** layer to perform the regression task. RidgeCV is a variant of the **Ridge linear regression model** that adjusts a linear regression model penalized with L2 regularization, where the penalty prevents overfitting by reducing the magnitude of the coefficients. CV in RidgeCV stands for cross-validation, used to find the optimal penalty value (hyperparameter α) automatically. The output of RidgeCV becomes the input for the **ExtraTreesRegressor**, an ensemble of decision trees that combines multiple decision trees to obtain a more robust and accurate prediction. The ensemble averages the predictions of different trees to produce the final prediction. Unlike other tree models, node split thresholds are chosen randomly rather than searching for the best threshold. The model's hyperparameters are:\n",
    "- **bootstrap=True:** The model uses sampling with replacement, allowing repeated samples from the dataset during training of each tree.\n",
    "- **max_features=0.95:** 95% of the features are available for each tree split, increasing variability and reducing overfitting.\n",
    "- **min_samples_leaf=20:** A node must have at least 20 samples to become a leaf, reducing tree complexity and improving generalization.\n",
    "- **min_samples_split=20:** A node must have at least 20 samples to split into two branches, preventing unnecessary splits and reducing complexity.\n",
    "- **n_estimators=100:** The model uses 100 decision trees, enhancing prediction stability.\n",
    "\n",
    "#### Metrics:\n",
    "- **R² (Coefficient of Determination):** 0.0798  \n",
    "  This indicates that the model explains only 7.98% of the variability in the data, suggesting it struggles to capture the relationship between predictors and the target.\n",
    "- **MAE (Mean Absolute Error):** 54.28  \n",
    "  Represents the average absolute error between predictions and actual values. On average, predictions are approximately 54.28 units away from the real value.\n",
    "- **MSE (Mean Squared Error):** 8129.02  \n",
    "  Represents the average squared error, penalizing larger errors more severely. Although it provides insight into error magnitude, it can be harder to interpret in absolute terms.\n",
    "- **RMSE (Root Mean Squared Error):** 90.16  \n",
    "  Is the square root of MSE, making it more interpretable as it is on the same scale as the target values. An RMSE of 90.16 indicates the average spread of predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Question 2: How do lipid and glucose levels vary by age, and which age groups are most vulnerable to metabolic disorders?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 # Filtrar las columnas necesarias de cada DataFrame</span>                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 2 demografia_filtered = <span style=\"font-weight: bold; text-decoration: underline\">demografia</span>[[<span style=\"color: #808000; text-decoration-color: #808000\">'ID'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">'Edad en años al momento del examen'</span>]]              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>perfilBioquimico_filtered = perfilB[[<span style=\"color: #808000; text-decoration-color: #808000\">'ID'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">'Triglicéridos, suero refrigerado (mg/dL)'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">'</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>medidasCorporales_filtered = medidas[[<span style=\"color: #808000; text-decoration-color: #808000\">'ID'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">'Circunferencia de la cintura (cm)'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">'Índice</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'demografia'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m2\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 1 \u001b[0m\u001b[2m# Filtrar las columnas necesarias de cada DataFrame\u001b[0m                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 2 demografia_filtered = \u001b[1;4mdemografia\u001b[0m[[\u001b[33m'\u001b[0m\u001b[33mID\u001b[0m\u001b[33m'\u001b[0m, \u001b[33m'\u001b[0m\u001b[33mEdad en años al momento del examen\u001b[0m\u001b[33m'\u001b[0m]]              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 3 \u001b[0mperfilBioquimico_filtered = perfilB[[\u001b[33m'\u001b[0m\u001b[33mID\u001b[0m\u001b[33m'\u001b[0m, \u001b[33m'\u001b[0m\u001b[33mTriglicéridos, suero refrigerado (mg/dL)\u001b[0m\u001b[33m'\u001b[0m, \u001b[33m'\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 4 \u001b[0mmedidasCorporales_filtered = medidas[[\u001b[33m'\u001b[0m\u001b[33mID\u001b[0m\u001b[33m'\u001b[0m, \u001b[33m'\u001b[0m\u001b[33mCircunferencia de la cintura (cm)\u001b[0m\u001b[33m'\u001b[0m, \u001b[33m'\u001b[0m\u001b[33mÍndice\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 5 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'demografia'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Filtrar las columnas necesarias de cada DataFrame\n",
    "demografia_filtered = demografia[['ID', 'Edad en años al momento del examen']]\n",
    "perfilBioquimico_filtered = perfilB[['ID', 'Triglicéridos, suero refrigerado (mg/dL)', 'Colesterol Total, suero refrigerado (mg/dL)', 'Glucosa, suero refrigerado (mg/dL)']]\n",
    "medidasCorporales_filtered = medidas[['ID', 'Circunferencia de la cintura (cm)', 'Índice de masa corporal (kg/m²)']]\n",
    "\n",
    "# Realizar el merge\n",
    "question2 = demografia_filtered.merge(perfilBioquimico_filtered, on='ID', how='inner')\n",
    "question2 = question2.merge(medidasCorporales_filtered, on='ID', how='inner')\n",
    "\n",
    "# Revisar el DataFrame resultante\n",
    "print(question2.head())\n",
    "print(\"Cantidad de registros combinados:\", question2.shape)\n",
    "\n",
    "# Definir grupos de edad\n",
    "bins = [0, 30, 60, 100]  # Ajusta los rangos de edad según tus necesidades\n",
    "labels = ['0-30', '31-60', '60+']\n",
    "question2['Grupo de Edad'] = pd.cut(question2['Edad en años al momento del examen'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Definir los targets\n",
    "targets = {\n",
    "    'Triglicéridos, suero refrigerado (mg/dL)': 'Trigliceridos_suero',\n",
    "    'Colesterol Total, suero refrigerado (mg/dL)': 'Colesterol_Total_suero',\n",
    "    'Glucosa, suero refrigerado (mg/dL)': 'Glucosa_suero'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------ Grupo de Edad: 0-30 ------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -4431.469891805286\n",
      "\n",
      "Generation 2 - Current best internal CV score: -4418.6372696044\n",
      "\n",
      "Generation 3 - Current best internal CV score: -4418.6372696044\n",
      "\n",
      "Generation 4 - Current best internal CV score: -4418.6372696044\n",
      "\n",
      "Generation 5 - Current best internal CV score: -4415.3505746669325\n",
      "\n",
      "Generation 6 - Current best internal CV score: -4415.3505746669325\n",
      "\n",
      "Generation 7 - Current best internal CV score: -4414.547180278123\n",
      "\n",
      "Generation 8 - Current best internal CV score: -4414.547180278123\n",
      "\n",
      "Generation 9 - Current best internal CV score: -4414.547180278123\n",
      "\n",
      "Generation 10 - Current best internal CV score: -4414.547180278123\n",
      "\n",
      "Best pipeline: ExtraTreesRegressor(PolynomialFeatures(input_matrix, degree=2, include_bias=False, interaction_only=False), bootstrap=True, max_features=0.6500000000000001, min_samples_leaf=9, min_samples_split=11, n_estimators=100)\n",
      "\n",
      "Métricas de regresión para Triglicéridos, suero refrigerado (mg/dL) en el grupo de edad 0-30:\n",
      "MAE: 43.703001749926784\n",
      "MSE: 4617.13769718127\n",
      "RMSE: 67.9495231563936\n",
      "R²: 0.06658579509207219\n",
      "Pipeline exportado para Triglicéridos, suero refrigerado (mg/dL) en el grupo de edad 0-30\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -1034.681972807775\n",
      "\n",
      "Generation 2 - Current best internal CV score: -1034.681972807775\n",
      "\n",
      "Generation 3 - Current best internal CV score: -1034.6711436924975\n",
      "\n",
      "Generation 4 - Current best internal CV score: -1032.8282292916142\n",
      "\n",
      "Generation 5 - Current best internal CV score: -1032.8282292916142\n",
      "\n",
      "Generation 6 - Current best internal CV score: -1032.3057767575162\n",
      "\n",
      "Generation 7 - Current best internal CV score: -1032.2937023505424\n",
      "\n",
      "Generation 8 - Current best internal CV score: -1032.2937023505424\n",
      "\n",
      "Generation 9 - Current best internal CV score: -1031.246817870288\n",
      "\n",
      "Generation 10 - Current best internal CV score: -1031.246817870288\n",
      "\n",
      "Best pipeline: AdaBoostRegressor(PolynomialFeatures(input_matrix, degree=2, include_bias=False, interaction_only=False), learning_rate=0.001, loss=linear, n_estimators=100)\n",
      "\n",
      "Métricas de regresión para Colesterol Total, suero refrigerado (mg/dL) en el grupo de edad 0-30:\n",
      "MAE: 23.70396722015307\n",
      "MSE: 1015.1262358841103\n",
      "RMSE: 31.86104574373086\n",
      "R²: 0.11306137099665303\n",
      "Pipeline exportado para Colesterol Total, suero refrigerado (mg/dL) en el grupo de edad 0-30\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -244.72884246866562\n",
      "\n",
      "Generation 2 - Current best internal CV score: -244.72884246866562\n",
      "\n",
      "Generation 3 - Current best internal CV score: -244.72884246866562\n",
      "\n",
      "Generation 4 - Current best internal CV score: -244.72855990421968\n",
      "\n",
      "Generation 5 - Current best internal CV score: -244.32893108935642\n",
      "\n",
      "Generation 6 - Current best internal CV score: -244.32893108935642\n",
      "\n",
      "Generation 7 - Current best internal CV score: -244.32893108935642\n",
      "\n",
      "Generation 8 - Current best internal CV score: -244.32893108935642\n",
      "\n",
      "Generation 9 - Current best internal CV score: -244.32893108935642\n",
      "\n",
      "Generation 10 - Current best internal CV score: -244.32893108935642\n",
      "\n",
      "Best pipeline: AdaBoostRegressor(RidgeCV(input_matrix), learning_rate=0.01, loss=exponential, n_estimators=100)\n",
      "\n",
      "Métricas de regresión para Glucosa, suero refrigerado (mg/dL) en el grupo de edad 0-30:\n",
      "MAE: 6.8702058625208915\n",
      "MSE: 132.28683892379206\n",
      "RMSE: 11.50160158081439\n",
      "R²: 0.02504892255376956\n",
      "Pipeline exportado para Glucosa, suero refrigerado (mg/dL) en el grupo de edad 0-30\n",
      "\n",
      "\n",
      "------ Grupo de Edad: 31-60 ------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -14508.656467171784\n",
      "\n",
      "Generation 2 - Current best internal CV score: -14508.656467171784\n",
      "\n",
      "Generation 3 - Current best internal CV score: -14496.763862331887\n",
      "\n",
      "Generation 4 - Current best internal CV score: -14462.08755530268\n",
      "\n",
      "Generation 5 - Current best internal CV score: -14462.08755530268\n",
      "\n",
      "Generation 6 - Current best internal CV score: -14462.08755530268\n",
      "\n",
      "Generation 7 - Current best internal CV score: -14462.08755530268\n",
      "\n",
      "Generation 8 - Current best internal CV score: -14453.130482607598\n",
      "\n",
      "Generation 9 - Current best internal CV score: -14453.130482607598\n",
      "\n",
      "Generation 10 - Current best internal CV score: -14453.130482607598\n",
      "\n",
      "Best pipeline: AdaBoostRegressor(input_matrix, learning_rate=0.001, loss=square, n_estimators=100)\n",
      "\n",
      "Métricas de regresión para Triglicéridos, suero refrigerado (mg/dL) en el grupo de edad 31-60:\n",
      "MAE: 67.16581580770993\n",
      "MSE: 13879.859780812318\n",
      "RMSE: 117.8128167085921\n",
      "R²: 0.03368270754689495\n",
      "Pipeline exportado para Triglicéridos, suero refrigerado (mg/dL) en el grupo de edad 31-60\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -1426.4975154821923\n",
      "\n",
      "Generation 2 - Current best internal CV score: -1426.4975154821923\n",
      "\n",
      "Generation 3 - Current best internal CV score: -1425.2842665439262\n",
      "\n",
      "Generation 4 - Current best internal CV score: -1425.2842665439262\n",
      "\n",
      "Generation 5 - Current best internal CV score: -1425.2842665439262\n",
      "\n",
      "Generation 6 - Current best internal CV score: -1424.174106996043\n",
      "\n",
      "Generation 7 - Current best internal CV score: -1424.174106996043\n",
      "\n",
      "Generation 8 - Current best internal CV score: -1424.174106996043\n",
      "\n",
      "Generation 9 - Current best internal CV score: -1424.174106996043\n",
      "\n",
      "Generation 10 - Current best internal CV score: -1424.174106996043\n",
      "\n",
      "Best pipeline: ExtraTreesRegressor(Nystroem(input_matrix, gamma=0.2, kernel=poly, n_components=5), bootstrap=True, max_features=0.6500000000000001, min_samples_leaf=16, min_samples_split=11, n_estimators=100)\n",
      "\n",
      "Métricas de regresión para Colesterol Total, suero refrigerado (mg/dL) en el grupo de edad 31-60:\n",
      "MAE: 30.990785084131854\n",
      "MSE: 1655.5061223211342\n",
      "RMSE: 40.68791125532416\n",
      "R²: 0.019058412418003212\n",
      "Pipeline exportado para Colesterol Total, suero refrigerado (mg/dL) en el grupo de edad 31-60\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -1461.275979881647\n",
      "\n",
      "Generation 2 - Current best internal CV score: -1461.275979881647\n",
      "\n",
      "Generation 3 - Current best internal CV score: -1461.2461172980359\n",
      "\n",
      "Generation 4 - Current best internal CV score: -1461.2393978337805\n",
      "\n",
      "Generation 5 - Current best internal CV score: -1461.0614847070333\n",
      "\n",
      "Generation 6 - Current best internal CV score: -1461.0614847070333\n",
      "\n",
      "Generation 7 - Current best internal CV score: -1461.0614847070333\n",
      "\n",
      "Generation 8 - Current best internal CV score: -1461.0614847070333\n",
      "\n",
      "Generation 9 - Current best internal CV score: -1460.755337450487\n",
      "\n",
      "Generation 10 - Current best internal CV score: -1460.755337450487\n",
      "\n",
      "Best pipeline: RidgeCV(Nystroem(MaxAbsScaler(input_matrix), gamma=0.05, kernel=additive_chi2, n_components=6))\n",
      "\n",
      "Métricas de regresión para Glucosa, suero refrigerado (mg/dL) en el grupo de edad 31-60:\n",
      "MAE: 18.512592584063167\n",
      "MSE: 1420.1712352659254\n",
      "RMSE: 37.68515935041174\n",
      "R²: 0.057175590715400015\n",
      "Pipeline exportado para Glucosa, suero refrigerado (mg/dL) en el grupo de edad 31-60\n",
      "\n",
      "\n",
      "------ Grupo de Edad: 60+ ------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -7995.829328886367\n",
      "\n",
      "Generation 2 - Current best internal CV score: -7993.5456947895555\n",
      "\n",
      "Generation 3 - Current best internal CV score: -7993.5456947895555\n",
      "\n",
      "Generation 4 - Current best internal CV score: -7993.5456947895555\n",
      "\n",
      "Generation 5 - Current best internal CV score: -7992.609020246661\n",
      "\n",
      "Generation 6 - Current best internal CV score: -7992.609020246661\n",
      "\n",
      "Generation 7 - Current best internal CV score: -7992.609020246661\n",
      "\n",
      "Generation 8 - Current best internal CV score: -7992.609020246661\n",
      "\n",
      "Generation 9 - Current best internal CV score: -7992.609020246661\n",
      "\n",
      "Generation 10 - Current best internal CV score: -7981.538791645353\n",
      "\n",
      "Best pipeline: RidgeCV(RidgeCV(Normalizer(RidgeCV(input_matrix), norm=max)))\n",
      "\n",
      "Métricas de regresión para Triglicéridos, suero refrigerado (mg/dL) en el grupo de edad 60+:\n",
      "MAE: 58.758911736335435\n",
      "MSE: 7720.221608731275\n",
      "RMSE: 87.86479163311819\n",
      "R²: 0.017691176513471074\n",
      "Pipeline exportado para Triglicéridos, suero refrigerado (mg/dL) en el grupo de edad 60+\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -1832.5019385010564\n",
      "\n",
      "Generation 2 - Current best internal CV score: -1832.4473652757242\n",
      "\n",
      "Generation 3 - Current best internal CV score: -1831.4875890256385\n",
      "\n",
      "Generation 4 - Current best internal CV score: -1831.4875890256385\n",
      "\n",
      "Generation 5 - Current best internal CV score: -1830.530646185493\n",
      "\n",
      "Generation 6 - Current best internal CV score: -1830.530646185493\n",
      "\n",
      "Generation 7 - Current best internal CV score: -1830.530646185493\n",
      "\n",
      "Generation 8 - Current best internal CV score: -1830.506026865981\n",
      "\n",
      "Generation 9 - Current best internal CV score: -1825.03240531195\n",
      "\n",
      "Generation 10 - Current best internal CV score: -1825.03240531195\n",
      "\n",
      "Best pipeline: RidgeCV(Nystroem(input_matrix, gamma=0.9500000000000001, kernel=additive_chi2, n_components=8))\n",
      "\n",
      "Métricas de regresión para Colesterol Total, suero refrigerado (mg/dL) en el grupo de edad 60+:\n",
      "MAE: 33.44637362641843\n",
      "MSE: 1766.4868255972694\n",
      "RMSE: 42.0295946399352\n",
      "R²: 0.04701913869271224\n",
      "Pipeline exportado para Colesterol Total, suero refrigerado (mg/dL) en el grupo de edad 60+\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -1471.0662849194402\n",
      "\n",
      "Generation 2 - Current best internal CV score: -1471.0662849194402\n",
      "\n",
      "Generation 3 - Current best internal CV score: -1471.0662849194402\n",
      "\n",
      "Generation 4 - Current best internal CV score: -1471.0662849194402\n",
      "\n",
      "Generation 5 - Current best internal CV score: -1471.0662849194402\n",
      "\n",
      "Generation 6 - Current best internal CV score: -1471.0662849194402\n",
      "\n",
      "Generation 7 - Current best internal CV score: -1471.0662849194402\n",
      "\n",
      "Generation 8 - Current best internal CV score: -1471.0662849194402\n",
      "\n",
      "Generation 9 - Current best internal CV score: -1471.0662849194402\n",
      "\n",
      "Generation 10 - Current best internal CV score: -1471.0662849194402\n",
      "\n",
      "Best pipeline: ElasticNetCV(input_matrix, l1_ratio=1.0, tol=0.1)\n",
      "\n",
      "Métricas de regresión para Glucosa, suero refrigerado (mg/dL) en el grupo de edad 60+:\n",
      "MAE: 22.24176108875996\n",
      "MSE: 1606.447676046225\n",
      "RMSE: 40.08051491742871\n",
      "R²: -0.007044131750046478\n",
      "Pipeline exportado para Glucosa, suero refrigerado (mg/dL) en el grupo de edad 60+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Pregunta 2: Variación de los niveles de lípidos y glucosa según la edad\n",
    "# Iterar sobre cada grupo de edad y cada target\n",
    "for grupo in labels:\n",
    "    # Filtrar el dataframe por grupo de edad\n",
    "    group_df = question2[question2['Grupo de Edad'] == grupo]\n",
    "    \n",
    "    # Seleccionar las variables predictoras y los targets\n",
    "    X = group_df[['Edad en años al momento del examen', 'Circunferencia de la cintura (cm)', 'Índice de masa corporal (kg/m²)']]\n",
    "    y = group_df[['Triglicéridos, suero refrigerado (mg/dL)', 'Colesterol Total, suero refrigerado (mg/dL)', 'Glucosa, suero refrigerado (mg/dL)']]\n",
    "    \n",
    "    # Imputar valores faltantes en X\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_imputed = imputer.fit_transform(X)\n",
    "    \n",
    "    print(f\"\\n------ Grupo de Edad: {grupo} ------\")\n",
    "    \n",
    "    # Iterar sobre cada target para ejecutar TPOT\n",
    "    for target, file_name in targets.items():\n",
    "        # División de datos\n",
    "        y_target = y[target].dropna()\n",
    "        X_filtered = X_imputed[~y[target].isna()]  # Filtrar X para que coincida con y no nulo\n",
    "        if len(X_filtered) == 0:\n",
    "            print(f\"No hay suficientes datos para {target} en el grupo de edad {grupo}.\")\n",
    "            continue\n",
    "            \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_filtered, y_target, train_size=0.75, test_size=0.25, random_state=42)\n",
    "        \n",
    "        # TPOT para regresión\n",
    "        tpot_regressor = TPOTRegressor(verbosity=2, generations=10, population_size=20, random_state=42)\n",
    "        tpot_regressor.fit(X_train, y_train)\n",
    "        \n",
    "        # Realizar predicciones\n",
    "        y_pred = tpot_regressor.predict(X_test)\n",
    "        \n",
    "        # Calcular métricas\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Imprimir métricas para cada target\n",
    "        print(f\"\\nMétricas de regresión para {target} en el grupo de edad {grupo}:\")\n",
    "        print(f\"MAE: {mae}\")\n",
    "        print(f\"MSE: {mse}\")\n",
    "        print(f\"RMSE: {rmse}\")\n",
    "        print(f\"R²: {r2}\")\n",
    "        \n",
    "        # Exportar el pipeline con nombre de archivo sin caracteres especiales\n",
    "        file_name_cleaned = file_name.replace('/', '_')\n",
    "        tpot_regressor.export(f'best_pipeline_{file_name_cleaned}_{grupo}_regression.py')\n",
    "        print(f\"Pipeline exportado para {target} en el grupo de edad {grupo}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age Group: 0-30\n",
    "\n",
    "#### Regression for Triglycerides in Serum (mg/dL)\n",
    "The selected model is an ExtraTreesRegressor with a preprocessing step of PolynomialFeatures. This step adds polynomial and interaction terms to enhance feature complexity, setting degree=2. The regressor uses ensemble methods, aggregating predictions from multiple decision trees to enhance accuracy. It was configured with bootstrap=True, allowing sampling with replacement, while max_features=0.65 uses 65% of features for each split to boost variability. It requires a minimum of 9 samples to create a leaf (min_samples_leaf=9) and at least 11 samples to split a node (min_samples_split=11), using 100 trees (n_estimators=100). Despite this complexity, the model explains only 6.7% of the variability (R²), with a Mean Absolute Error (MAE) of 43.70.\n",
    "\n",
    "#### Regression for Total Cholesterol in Serum (mg/dL)\n",
    "An AdaBoostRegressor with PolynomialFeatures was chosen. It iteratively adjusts weights to focus on difficult-to-predict samples, improving accuracy with each iteration. Here, the polynomial degree is set to 2, with learning_rate=0.001 controlling the contribution of each tree, loss=linear for linear error reduction, and n_estimators=100 to limit the number of boosting rounds. The model explains 11.3% of the variability, showing improved performance over the previous one, with an MAE of 23.70.\n",
    "\n",
    "#### Regression for Glucose in Serum (mg/dL)\n",
    "The best-performing model is another AdaBoostRegressor this time paired with RidgeCV as the base estimator, which handles regularization through L2 penalty, optimizing the hyperparameter α via cross-validation. The regressor uses an exponential loss function for penalizing large errors more heavily, with a learning_rate=0.01 and 100 boosting rounds (n_estimators=100). It performs poorly in explaining variability (R² = 2.5%), with an MAE of 6.87.\n",
    "\n",
    "### Age Group: 31-60\n",
    "\n",
    "#### Regression for Triglycerides in Serum (mg/dL)\n",
    "Here, an AdaBoostRegressor was again the best choice, using a simple input matrix with learning_rate=0.001 and loss=square, meaning it focuses on minimizing squared errors over 100 boosting iterations. This model captures only 3.4% of the variability, with an MAE of 67.17, indicating difficulties in predicting this variable for this age group.\n",
    "\n",
    "#### Regression for Total Cholesterol in Serum (mg/dL)\n",
    "The model is an ExtraTreesRegressor that incorporates a Nystroem transformation, which approximates the kernel map for handling non-linear relationships. It uses a polynomial kernel with gamma=0.2 and 5 components (n_components=5), providing a flexible feature representation. Similar to previous models, it utilizes bootstrapping, uses 65% of the features (max_features=0.65), and sets constraints for minimum samples (min_samples_leaf=16 and min_samples_split=11). However, it explains only 1.9% of the variability, with an MAE of 30.99.\n",
    "\n",
    "#### Regression for Glucose in Serum (mg/dL)\n",
    "The model for this variable is a RidgeCV regression with a Nystroem transformation. The kernel used is additive_chi2 with a small gamma=0.05 and 6 components. The model was scaled using MaxAbsScaler, which scales data by its maximum absolute value. Despite these adjustments, it explains only 5.7% of the variability, with an MAE of 18.51.\n",
    "\n",
    "### Age Group: 60+\n",
    "\n",
    "#### Regression for Triglycerides in Serum (mg/dL)\n",
    "The best model here is a RidgeCV regressor with multiple normalization layers. It uses nested RidgeCV steps combined with a Normalizer layer, aiming to ensure data consistency and penalize high coefficients to prevent overfitting. Still, the model’s performance is low, explaining only 1.8% of variability, with an MAE of 58.76.\n",
    "\n",
    "#### Regression for Total Cholesterol in Serum (mg/dL)\n",
    "The optimal model is another RidgeCV regressor, again incorporating the Nystroem kernel approximation with additive_chi2 kernel and high gamma=0.95. This captures non-linear features with 8 components. It achieves an R² of 4.7%, with an MAE of 33.45.\n",
    "\n",
    "#### Regression for Glucose in Serum (mg/dL)\n",
    "The final model is an ElasticNetCV, which combines L1 (Lasso) and L2 (Ridge) penalties, using cross-validation to find optimal regularization parameters (l1_ratio=1.0). It failed to explain variability effectively, with a negative R² (-0.7%), indicating poor fit, and an MAE of 22.24.\n",
    "\n",
    "Overall, the models indicate challenges in predicting serum lipid, glucose, and triglyceride levels across age groups, with limited explanatory power, suggesting a need for better features or alternative modeling strategies.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Question 3: How do gender and age affect correlations among these biomarkers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ID  Edad en años al momento del examen  Género  \\\n",
      "0 109264.00                               13.00    2.00   \n",
      "1 109266.00                               29.00    2.00   \n",
      "2 109271.00                               49.00    1.00   \n",
      "3 109273.00                               36.00    1.00   \n",
      "4 109274.00                               68.00    1.00   \n",
      "\n",
      "   Glucosa, suero refrigerado (mg/dL)  \\\n",
      "0                               89.00   \n",
      "1                               83.00   \n",
      "2                               95.00   \n",
      "3                               89.00   \n",
      "4                              153.00   \n",
      "\n",
      "   Triglicéridos, suero refrigerado (mg/dL)  \\\n",
      "0                                     54.00   \n",
      "1                                     86.00   \n",
      "2                                    101.00   \n",
      "3                                    178.00   \n",
      "4                                    151.00   \n",
      "\n",
      "   Colesterol Total, suero refrigerado (mg/dL)  \n",
      "0                                       170.00  \n",
      "1                                       199.00  \n",
      "2                                       148.00  \n",
      "3                                       168.00  \n",
      "4                                       105.00  \n",
      "Cantidad de registros combinados: (10409, 6)\n"
     ]
    }
   ],
   "source": [
    "# Dataframe para la pregunta 3\n",
    "# Filtrar las columnas necesarias de cada DataFrame\n",
    "demografia_filtered = demografia[['ID', 'Edad en años al momento del examen', 'Género']]\n",
    "perfilBioquimico_filtered = perfilB[['ID', 'Glucosa, suero refrigerado (mg/dL)', 'Triglicéridos, suero refrigerado (mg/dL)', 'Colesterol Total, suero refrigerado (mg/dL)']]\n",
    "\n",
    "# Unir los datasets para obtener los datos completos\n",
    "question3 = demografia_filtered.merge(perfilBioquimico_filtered, on='ID', how='inner')\n",
    "\n",
    "# Revisar el dataframe resultante\n",
    "print(question3.head())\n",
    "print(\"Cantidad de registros combinados:\", question3.shape)\n",
    "\n",
    "# Definir grupos de edad\n",
    "bins = [0, 30, 60, 100]  # Ajusta los rangos de edad según tus necesidades\n",
    "labels = ['0-30', '31-60', '60+']\n",
    "question3['Grupo de Edad'] = pd.cut(question3['Edad en años al momento del examen'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Definir los targets\n",
    "targets = {\n",
    "    'Glucosa, suero refrigerado (mg/dL)': 'Glucosa_suero',\n",
    "    'Triglicéridos, suero refrigerado (mg/dL)': 'Trigliceridos_suero',\n",
    "    'Colesterol Total, suero refrigerado (mg/dL)': 'Colesterol_Total_suero'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------ Grupo de Edad: 0-30, Género: 1 ------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/40 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -299.26385738290276\n",
      "\n",
      "Best pipeline: ElasticNetCV(input_matrix, l1_ratio=0.6000000000000001, tol=1e-05)\n",
      "\n",
      "Métricas de regresión para Glucosa, suero refrigerado (mg/dL) en el grupo de edad 0-30 y género 1:\n",
      "MAE: 6.451093239507414\n",
      "MSE: 115.26938094076026\n",
      "RMSE: 10.736357899248715\n",
      "R²: -0.0009470262541031449\n",
      "Pipeline exportado para Glucosa, suero refrigerado (mg/dL) en el grupo de edad 0-30 y género 1\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/40 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -6887.567864489324\n",
      "\n",
      "Best pipeline: ElasticNetCV(ElasticNetCV(input_matrix, l1_ratio=0.6000000000000001, tol=0.1), l1_ratio=0.55, tol=0.01)\n",
      "\n",
      "Métricas de regresión para Triglicéridos, suero refrigerado (mg/dL) en el grupo de edad 0-30 y género 1:\n",
      "MAE: 51.20859192975065\n",
      "MSE: 6263.8648304213575\n",
      "RMSE: 79.14458181342142\n",
      "R²: 0.014321823988022397\n",
      "Pipeline exportado para Triglicéridos, suero refrigerado (mg/dL) en el grupo de edad 0-30 y género 1\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/40 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -1041.9237974231887\n",
      "\n",
      "Best pipeline: AdaBoostRegressor(input_matrix, learning_rate=0.001, loss=exponential, n_estimators=100)\n",
      "\n",
      "Métricas de regresión para Colesterol Total, suero refrigerado (mg/dL) en el grupo de edad 0-30 y género 1:\n",
      "MAE: 25.297044871627552\n",
      "MSE: 1051.3013859126677\n",
      "RMSE: 32.42377809436568\n",
      "R²: 0.1097087806063104\n",
      "Pipeline exportado para Colesterol Total, suero refrigerado (mg/dL) en el grupo de edad 0-30 y género 1\n",
      "\n",
      "\n",
      "------ Grupo de Edad: 0-30, Género: 2 ------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/40 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -223.6545682743897\n",
      "\n",
      "Best pipeline: XGBRegressor(LinearSVR(input_matrix, C=0.0001, dual=True, epsilon=0.001, loss=epsilon_insensitive, tol=0.001), learning_rate=0.5, max_depth=1, min_child_weight=10, n_estimators=100, n_jobs=1, objective=reg:squarederror, subsample=1.0, verbosity=0)\n",
      "\n",
      "Métricas de regresión para Glucosa, suero refrigerado (mg/dL) en el grupo de edad 0-30 y género 2:\n",
      "MAE: 6.730692515915407\n",
      "MSE: 77.53306356713627\n",
      "RMSE: 8.805286115007068\n",
      "R²: -0.06067661854775763\n",
      "Pipeline exportado para Glucosa, suero refrigerado (mg/dL) en el grupo de edad 0-30 y género 2\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/40 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -2774.0010793289975\n",
      "\n",
      "Best pipeline: ElasticNetCV(Nystroem(input_matrix, gamma=0.7000000000000001, kernel=polynomial, n_components=10), l1_ratio=0.65, tol=0.1)\n",
      "\n",
      "Métricas de regresión para Triglicéridos, suero refrigerado (mg/dL) en el grupo de edad 0-30 y género 2:\n",
      "MAE: 38.042896408693\n",
      "MSE: 2976.62612202832\n",
      "RMSE: 54.55846517295295\n",
      "R²: 0.01972543084122791\n",
      "Pipeline exportado para Triglicéridos, suero refrigerado (mg/dL) en el grupo de edad 0-30 y género 2\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/40 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -1065.1113558765467\n",
      "\n",
      "Best pipeline: ElasticNetCV(input_matrix, l1_ratio=0.4, tol=1e-05)\n",
      "\n",
      "Métricas de regresión para Colesterol Total, suero refrigerado (mg/dL) en el grupo de edad 0-30 y género 2:\n",
      "MAE: 23.04717088504877\n",
      "MSE: 971.4142548696861\n",
      "RMSE: 31.16751922867276\n",
      "R²: 0.022932964485453122\n",
      "Pipeline exportado para Colesterol Total, suero refrigerado (mg/dL) en el grupo de edad 0-30 y género 2\n",
      "\n",
      "\n",
      "------ Grupo de Edad: 31-60, Género: 1 ------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/40 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -1690.9075342314154\n",
      "\n",
      "Best pipeline: LinearSVR(input_matrix, C=10.0, dual=False, epsilon=0.1, loss=squared_epsilon_insensitive, tol=1e-05)\n",
      "\n",
      "Métricas de regresión para Glucosa, suero refrigerado (mg/dL) en el grupo de edad 31-60 y género 1:\n",
      "MAE: 22.695636325236542\n",
      "MSE: 2514.765756189266\n",
      "RMSE: 50.14744017583815\n",
      "R²: 0.02717847028513498\n",
      "Pipeline exportado para Glucosa, suero refrigerado (mg/dL) en el grupo de edad 31-60 y género 1\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/40 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -27279.251661906914\n",
      "\n",
      "Best pipeline: ElasticNetCV(input_matrix, l1_ratio=0.25, tol=0.0001)\n",
      "\n",
      "Métricas de regresión para Triglicéridos, suero refrigerado (mg/dL) en el grupo de edad 31-60 y género 1:\n",
      "MAE: 82.4024528604061\n",
      "MSE: 14052.976399294665\n",
      "RMSE: 118.54525042908578\n",
      "R²: -0.013725383818470993\n",
      "Pipeline exportado para Triglicéridos, suero refrigerado (mg/dL) en el grupo de edad 31-60 y género 1\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/40 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -1587.7023682648337\n",
      "\n",
      "Best pipeline: ElasticNetCV(input_matrix, l1_ratio=0.55, tol=1e-05)\n",
      "\n",
      "Métricas de regresión para Colesterol Total, suero refrigerado (mg/dL) en el grupo de edad 31-60 y género 1:\n",
      "MAE: 33.13751359188112\n",
      "MSE: 1844.9634254960733\n",
      "RMSE: 42.95303744202584\n",
      "R²: -1.1737778334186544e-05\n",
      "Pipeline exportado para Colesterol Total, suero refrigerado (mg/dL) en el grupo de edad 31-60 y género 1\n",
      "\n",
      "\n",
      "------ Grupo de Edad: 31-60, Género: 2 ------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/40 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -1027.8073191139974\n",
      "\n",
      "Best pipeline: RidgeCV(input_matrix)\n",
      "\n",
      "Métricas de regresión para Glucosa, suero refrigerado (mg/dL) en el grupo de edad 31-60 y género 2:\n",
      "MAE: 17.729892656796867\n",
      "MSE: 1425.098319722145\n",
      "RMSE: 37.750474430424646\n",
      "R²: 0.026183215434953055\n",
      "Pipeline exportado para Glucosa, suero refrigerado (mg/dL) en el grupo de edad 31-60 y género 2\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/40 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -5801.632816679439\n",
      "\n",
      "Best pipeline: ElasticNetCV(input_matrix, l1_ratio=0.30000000000000004, tol=0.001)\n",
      "\n",
      "Métricas de regresión para Triglicéridos, suero refrigerado (mg/dL) en el grupo de edad 31-60 y género 2:\n",
      "MAE: 54.57505814106744\n",
      "MSE: 7500.8377104275\n",
      "RMSE: 86.60737676680607\n",
      "R²: -0.00844209421734532\n",
      "Pipeline exportado para Triglicéridos, suero refrigerado (mg/dL) en el grupo de edad 31-60 y género 2\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/40 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -1372.0301209678569\n",
      "\n",
      "Best pipeline: RidgeCV(input_matrix)\n",
      "\n",
      "Métricas de regresión para Colesterol Total, suero refrigerado (mg/dL) en el grupo de edad 31-60 y género 2:\n",
      "MAE: 27.24630126985124\n",
      "MSE: 1215.773616171601\n",
      "RMSE: 34.867945396475555\n",
      "R²: 0.070520758228796\n",
      "Pipeline exportado para Colesterol Total, suero refrigerado (mg/dL) en el grupo de edad 31-60 y género 2\n",
      "\n",
      "\n",
      "------ Grupo de Edad: 60+, Género: 1 ------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/40 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -1908.2460451122176\n",
      "\n",
      "Best pipeline: ElasticNetCV(input_matrix, l1_ratio=0.2, tol=0.01)\n",
      "\n",
      "Métricas de regresión para Glucosa, suero refrigerado (mg/dL) en el grupo de edad 60+ y género 1:\n",
      "MAE: 25.718291236131694\n",
      "MSE: 1680.8145832531682\n",
      "RMSE: 40.99773875780429\n",
      "R²: -0.0028152292255636535\n",
      "Pipeline exportado para Glucosa, suero refrigerado (mg/dL) en el grupo de edad 60+ y género 1\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/40 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -7309.043544729592\n",
      "\n",
      "Best pipeline: ElasticNetCV(input_matrix, l1_ratio=0.9, tol=0.01)\n",
      "\n",
      "Métricas de regresión para Triglicéridos, suero refrigerado (mg/dL) en el grupo de edad 60+ y género 1:\n",
      "MAE: 74.18306401322117\n",
      "MSE: 20053.39294198726\n",
      "RMSE: 141.61000297290886\n",
      "R²: -0.005005290463689693\n",
      "Pipeline exportado para Triglicéridos, suero refrigerado (mg/dL) en el grupo de edad 60+ y género 1\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/40 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -1680.3145790329422\n",
      "\n",
      "Best pipeline: ElasticNetCV(input_matrix, l1_ratio=0.65, tol=0.01)\n",
      "\n",
      "Métricas de regresión para Colesterol Total, suero refrigerado (mg/dL) en el grupo de edad 60+ y género 1:\n",
      "MAE: 31.23354273638671\n",
      "MSE: 1576.8677901444553\n",
      "RMSE: 39.70979463739967\n",
      "R²: 0.01262011648631145\n",
      "Pipeline exportado para Colesterol Total, suero refrigerado (mg/dL) en el grupo de edad 60+ y género 1\n",
      "\n",
      "\n",
      "------ Grupo de Edad: 60+, Género: 2 ------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/40 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -1186.2424504080905\n",
      "\n",
      "Best pipeline: RidgeCV(MaxAbsScaler(input_matrix))\n",
      "\n",
      "Métricas de regresión para Glucosa, suero refrigerado (mg/dL) en el grupo de edad 60+ y género 2:\n",
      "MAE: 20.260358021422803\n",
      "MSE: 1280.6847300722281\n",
      "RMSE: 35.7866557542365\n",
      "R²: -0.023671833850098523\n",
      "Pipeline exportado para Glucosa, suero refrigerado (mg/dL) en el grupo de edad 60+ y género 2\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/40 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -5369.18087585034\n",
      "\n",
      "Best pipeline: ElasticNetCV(input_matrix, l1_ratio=0.05, tol=0.001)\n",
      "\n",
      "Métricas de regresión para Triglicéridos, suero refrigerado (mg/dL) en el grupo de edad 60+ y género 2:\n",
      "MAE: 53.2073667073667\n",
      "MSE: 6013.949577882435\n",
      "RMSE: 77.54965878637013\n",
      "R²: -1.1914909904264803e-05\n",
      "Pipeline exportado para Triglicéridos, suero refrigerado (mg/dL) en el grupo de edad 60+ y género 2\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/40 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -1778.2270147284503\n",
      "\n",
      "Best pipeline: ElasticNetCV(RidgeCV(input_matrix), l1_ratio=0.9500000000000001, tol=0.01)\n",
      "\n",
      "Métricas de regresión para Colesterol Total, suero refrigerado (mg/dL) en el grupo de edad 60+ y género 2:\n",
      "MAE: 37.07249786063319\n",
      "MSE: 2210.2267480256505\n",
      "RMSE: 47.01304869954352\n",
      "R²: -0.0042292713683598215\n",
      "Pipeline exportado para Colesterol Total, suero refrigerado (mg/dL) en el grupo de edad 60+ y género 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterar sobre cada grupo de edad y cada género\n",
    "for grupo in labels:\n",
    "    for genero in [1, 2]:  # Supone que 1 y 2 representan los géneros en el dataset\n",
    "        # Filtrar el dataframe por grupo de edad y género\n",
    "        group_df = question3[(question3['Grupo de Edad'] == grupo) & (question3['Género'] == genero)]\n",
    "        \n",
    "        # Seleccionar las variables predictoras y los targets\n",
    "        X = group_df[['Edad en años al momento del examen', 'Género']]\n",
    "        y = group_df[['Glucosa, suero refrigerado (mg/dL)', 'Triglicéridos, suero refrigerado (mg/dL)', 'Colesterol Total, suero refrigerado (mg/dL)']]\n",
    "        \n",
    "        # Imputar valores faltantes en X\n",
    "        imputer = SimpleImputer(strategy='mean')\n",
    "        X_imputed = imputer.fit_transform(X)\n",
    "        \n",
    "        print(f\"\\n------ Grupo de Edad: {grupo}, Género: {genero} ------\")\n",
    "        \n",
    "        # Iterar sobre cada target para ejecutar TPOT\n",
    "        for target, file_name in targets.items():\n",
    "            # División de datos\n",
    "            y_target = y[target].dropna()\n",
    "            X_filtered = X_imputed[~y[target].isna()]  # Filtrar X para que coincida con y no nulo\n",
    "            if len(X_filtered) == 0:\n",
    "                print(f\"No hay suficientes datos para {target} en el grupo de edad {grupo} y género {genero}.\")\n",
    "                continue\n",
    "                \n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_filtered, y_target, train_size=0.75, test_size=0.25, random_state=42)\n",
    "            \n",
    "            # TPOT para regresión\n",
    "            tpot_regressor = TPOTRegressor(verbosity=2, generations=1, population_size=20, random_state=42)\n",
    "            tpot_regressor.fit(X_train, y_train)\n",
    "            \n",
    "            # Realizar predicciones\n",
    "            y_pred = tpot_regressor.predict(X_test)\n",
    "            \n",
    "            # Calcular métricas\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            \n",
    "            # Imprimir métricas para cada target\n",
    "            print(f\"\\nMétricas de regresión para {target} en el grupo de edad {grupo} y género {genero}:\")\n",
    "            print(f\"MAE: {mae}\")\n",
    "            print(f\"MSE: {mse}\")\n",
    "            print(f\"RMSE: {rmse}\")\n",
    "            print(f\"R²: {r2}\")\n",
    "            \n",
    "            # Exportar el pipeline con nombre de archivo sin caracteres especiales\n",
    "            file_name_cleaned = f\"{file_name}_{grupo}_genero{genero}\".replace('/', '_')\n",
    "            tpot_regressor.export(f'best_pipeline_{file_name_cleaned}_regression.py')\n",
    "            print(f\"Pipeline exportado para {target} en el grupo de edad {grupo} y género {genero}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age Group: 0-30, Gender: 1\n",
    "\n",
    "#### Regression for Glucose in Serum (mg/dL)\n",
    "The model uses ElasticNetCV with an l1_ratio of 0.6, applying both L1 and L2 regularization, with a very small tolerance of 1e-05 for better accuracy. The model performs poorly with an R² of -0.001, indicating no explanatory power, and an MAE of 6.45.\n",
    "\n",
    "#### Regression for Triglycerides in Serum (mg/dL)\n",
    "An ElasticNetCV model nested within another ElasticNetCV model was selected, using l1_ratios of 0.6 and 0.55, respectively. This setup emphasizes regularization, but the model still struggles with prediction accuracy, as seen by an R² of 0.014 and an MAE of 51.21.\n",
    "\n",
    "#### Regression for Total Cholesterol in Serum (mg/dL)\n",
    "The AdaBoostRegressor with 100 estimators, exponential loss, and a learning rate of 0.001 was chosen. It achieves an R² of 0.11, showing some explanatory power, and an MAE of 25.30, suggesting moderate predictive capacity.\n",
    "\n",
    "### Age Group: 0-30, Gender: 2\n",
    "\n",
    "#### Regression for Glucose in Serum (mg/dL)\n",
    "The selected model is XGBRegressor, combining it with LinearSVR. LinearSVR uses a very small C value of 0.0001 and epsilon-insensitive loss to handle deviations, while XGBoost further refines predictions. The model performs poorly, with an R² of -0.061 and an MAE of 6.73.\n",
    "\n",
    "#### Regression for Triglycerides in Serum (mg/dL)\n",
    "The model is ElasticNetCV combined with Nystroem for feature transformation using a polynomial kernel. It achieves an R² of 0.02, indicating a slight improvement in explanatory power, and an MAE of 38.04.\n",
    "\n",
    "#### Regression for Total Cholesterol in Serum (mg/dL)\n",
    "ElasticNetCV with an l1_ratio of 0.4 was selected. The R² is 0.023, showing minimal explanatory power, while the MAE is 23.05, indicating a decent level of accuracy.\n",
    "\n",
    "### Age Group: 31-60, Gender: 1\n",
    "\n",
    "#### Regression for Glucose in Serum (mg/dL)\n",
    "LinearSVR was chosen, with an R² of 0.03, indicating low explanatory power, and an MAE of 22.70, suggesting significant prediction error.\n",
    "\n",
    "#### Regression for Triglycerides in Serum (mg/dL)\n",
    "ElasticNetCV with an l1_ratio of 0.25 was used. It has a negative R² of -0.014, indicating a poor fit, and an MAE of 82.40, highlighting substantial prediction error.\n",
    "\n",
    "#### Regression for Total Cholesterol in Serum (mg/dL)\n",
    "ElasticNetCV with an l1_ratio of 0.55 was selected. It achieves an R² close to zero, showing minimal explanatory power, while the MAE is 33.14, suggesting moderate accuracy.\n",
    "\n",
    "### Age Group: 31-60, Gender: 2\n",
    "\n",
    "#### Regression for Glucose in Serum (mg/dL)\n",
    "RidgeCV was chosen, achieving an R² of 0.03 and an MAE of 17.73, indicating moderate prediction accuracy.\n",
    "\n",
    "#### Regression for Triglycerides in Serum (mg/dL)\n",
    "ElasticNetCV with an l1_ratio of 0.3 was selected. The model has a negative R² of -0.008, suggesting a poor fit, and an MAE of 54.58.\n",
    "\n",
    "#### Regression for Total Cholesterol in Serum (mg/dL)\n",
    "RidgeCV was again selected, with an R² of 0.07, showing some predictive power, and an MAE of 27.25.\n",
    "\n",
    "### Age Group: 60+, Gender: 1\n",
    "\n",
    "#### Regression for Glucose in Serum (mg/dL)\n",
    "The model uses ElasticNetCV with an l1_ratio of 0.2 and a tolerance of 0.01, achieving an R² of -0.003 and an MAE of 25.72, indicating poor predictive power.\n",
    "\n",
    "#### Regression for Triglycerides in Serum (mg/dL)\n",
    "ElasticNetCV with a high l1_ratio of 0.9 was chosen. It shows a slight negative R² of -0.005, suggesting poor fit, and an MAE of 74.18.\n",
    "\n",
    "#### Regression for Total Cholesterol in Serum (mg/dL)\n",
    "ElasticNetCV with an l1_ratio of 0.65 was used, achieving an R² of 0.013 and an MAE of 31.23, indicating modest performance.\n",
    "\n",
    "### Age Group: 60+, Gender: 2\n",
    "\n",
    "#### Regression for Glucose in Serum (mg/dL)\n",
    "The model is RidgeCV combined with MaxAbsScaler. It shows a negative R² of -0.024, indicating poor predictive capacity, with an MAE of 20.26.\n",
    "\n",
    "#### Regression for Triglycerides in Serum (mg/dL)\n",
    "ElasticNetCV with an l1_ratio of 0.05 was selected, achieving a near-zero R² and an MAE of 53.21, reflecting low accuracy.\n",
    "\n",
    "#### Regression for Total Cholesterol in Serum (mg/dL)\n",
    "The model uses ElasticNetCV combined with RidgeCV, with an l1_ratio of 0.95. It achieves a negative R² of -0.004 and an MAE of 37.07, indicating limited explanatory power.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Question 5: As age increases, how does this affect blood insulin and cholesterol results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ID  Edad en años al momento del examen  Insulina (μU/mL)  \\\n",
      "0 109264.00                               13.00              6.05   \n",
      "1 109271.00                               49.00             16.96   \n",
      "2 109274.00                               68.00             13.52   \n",
      "3 109277.00                               12.00              6.44   \n",
      "4 109282.00                               76.00              7.49   \n",
      "\n",
      "   Colesterol Total (mg/dL)  \n",
      "0                    166.00  \n",
      "1                    147.00  \n",
      "2                    105.00  \n",
      "3                    129.00  \n",
      "4                    233.00  \n",
      "Cantidad de registros combinados: (5090, 4)\n"
     ]
    }
   ],
   "source": [
    "# Filtrar las columnas necesarias en cada dataset\n",
    "demografia_filtered = demografia[['ID', 'Edad en años al momento del examen']]\n",
    "insulina_filtered = insulina[['ID', 'Insulina (μU/mL)']]\n",
    "colesterol_filtered = colesterol[['ID', 'Colesterol Total (mg/dL)']]\n",
    "\n",
    "# Unir los datasets\n",
    "question5 = demografia_filtered.merge(insulina_filtered, on='ID', how='inner')\n",
    "question5 = question5.merge(colesterol_filtered, on='ID', how='inner')\n",
    "\n",
    "# Revisar el dataframe resultante\n",
    "print(question5.head())\n",
    "print(\"Cantidad de registros combinados:\", question5.shape)\n",
    "\n",
    "# Definir grupos de edad\n",
    "bins = [0, 30, 60, 100]  # Ajusta los rangos de edad según tus necesidades\n",
    "labels = ['0-30', '31-60', '60+']\n",
    "question5['Grupo de Edad'] = pd.cut(question5['Edad en años al momento del examen'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Definir los targets\n",
    "targets = {\n",
    "    'Insulina (μU/mL)': 'Insulina',\n",
    "    'Colesterol Total (mg/dL)': 'Colesterol'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------ Grupo de Edad: 0-30 ------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -249.61579440559163\n",
      "\n",
      "Generation 2 - Current best internal CV score: -249.61579440559163\n",
      "\n",
      "Generation 3 - Current best internal CV score: -249.5810062737609\n",
      "\n",
      "Generation 4 - Current best internal CV score: -249.5810062737609\n",
      "\n",
      "Generation 5 - Current best internal CV score: -249.5810062737609\n",
      "\n",
      "Generation 6 - Current best internal CV score: -249.5810062737609\n",
      "\n",
      "Generation 7 - Current best internal CV score: -249.5810062737609\n",
      "\n",
      "Generation 8 - Current best internal CV score: -249.5810062737609\n",
      "\n",
      "Generation 9 - Current best internal CV score: -249.5810062737609\n",
      "\n",
      "Generation 10 - Current best internal CV score: -249.5810062737609\n",
      "\n",
      "Best pipeline: XGBRegressor(Normalizer(input_matrix, norm=l1), learning_rate=0.01, max_depth=1, min_child_weight=8, n_estimators=100, n_jobs=1, objective=reg:squarederror, subsample=0.2, verbosity=0)\n",
      "\n",
      "Métricas de regresión para Insulina (μU/mL) en el grupo de edad 0-30:\n",
      "MAE: 7.690883911322363\n",
      "MSE: 90.9171146362185\n",
      "RMSE: 9.535046650972323\n",
      "R²: -0.07464855938234383\n",
      "Pipeline exportado para Insulina (μU/mL) en el grupo de edad 0-30\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -1049.9357369145869\n",
      "\n",
      "Generation 2 - Current best internal CV score: -1049.9357369145869\n",
      "\n",
      "Generation 3 - Current best internal CV score: -1049.9357369145869\n",
      "\n",
      "Generation 4 - Current best internal CV score: -1049.9357369145869\n",
      "\n",
      "Generation 5 - Current best internal CV score: -1049.9357369145869\n",
      "\n",
      "Generation 6 - Current best internal CV score: -1049.9357369145869\n",
      "\n",
      "Generation 7 - Current best internal CV score: -1045.4562293886568\n",
      "\n",
      "Generation 8 - Current best internal CV score: -1045.4562293886568\n",
      "\n",
      "Generation 9 - Current best internal CV score: -1045.4562293886568\n",
      "\n",
      "Generation 10 - Current best internal CV score: -1045.4562293886568\n",
      "\n",
      "Best pipeline: DecisionTreeRegressor(input_matrix, max_depth=2, min_samples_leaf=7, min_samples_split=8)\n",
      "\n",
      "Métricas de regresión para Colesterol Total (mg/dL) en el grupo de edad 0-30:\n",
      "MAE: 23.610686849187022\n",
      "MSE: 933.3548538010897\n",
      "RMSE: 30.550856842338966\n",
      "R²: 0.042733424874419224\n",
      "Pipeline exportado para Colesterol Total (mg/dL) en el grupo de edad 0-30\n",
      "\n",
      "\n",
      "------ Grupo de Edad: 31-60 ------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -540.8792640034977\n",
      "\n",
      "Generation 2 - Current best internal CV score: -540.5485757458933\n",
      "\n",
      "Generation 3 - Current best internal CV score: -540.5485757458933\n",
      "\n",
      "Generation 4 - Current best internal CV score: -540.5485757458933\n",
      "\n",
      "Generation 5 - Current best internal CV score: -540.5485757458933\n",
      "\n",
      "Generation 6 - Current best internal CV score: -540.5452180949466\n",
      "\n",
      "Generation 7 - Current best internal CV score: -540.5452180949466\n",
      "\n",
      "Generation 8 - Current best internal CV score: -539.5287028154935\n",
      "\n",
      "Generation 9 - Current best internal CV score: -539.5287028154935\n",
      "\n",
      "Generation 10 - Current best internal CV score: -539.5287028154935\n",
      "\n",
      "Best pipeline: LinearSVR(input_matrix, C=0.1, dual=True, epsilon=1.0, loss=squared_epsilon_insensitive, tol=1e-05)\n",
      "\n",
      "Métricas de regresión para Insulina (μU/mL) en el grupo de edad 31-60:\n",
      "MAE: 9.250403818525399\n",
      "MSE: 341.90119893087984\n",
      "RMSE: 18.490570540977902\n",
      "R²: -0.00859978441835807\n",
      "Pipeline exportado para Insulina (μU/mL) en el grupo de edad 31-60\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -1476.7434331282243\n",
      "\n",
      "Generation 2 - Current best internal CV score: -1476.7434331282243\n",
      "\n",
      "Generation 3 - Current best internal CV score: -1476.7434331282243\n",
      "\n",
      "Generation 4 - Current best internal CV score: -1476.7434331282243\n",
      "\n",
      "Generation 5 - Current best internal CV score: -1472.8293560236164\n",
      "\n",
      "Generation 6 - Current best internal CV score: -1472.8293560236164\n",
      "\n",
      "Generation 7 - Current best internal CV score: -1472.8293560236164\n",
      "\n",
      "Generation 8 - Current best internal CV score: -1472.8293560236164\n",
      "\n",
      "Generation 9 - Current best internal CV score: -1472.8293560236164\n",
      "\n",
      "Generation 10 - Current best internal CV score: -1472.8293560236164\n",
      "\n",
      "Best pipeline: DecisionTreeRegressor(input_matrix, max_depth=2, min_samples_leaf=19, min_samples_split=18)\n",
      "\n",
      "Métricas de regresión para Colesterol Total (mg/dL) en el grupo de edad 31-60:\n",
      "MAE: 30.622114097089383\n",
      "MSE: 1660.5920617423476\n",
      "RMSE: 40.75036271915071\n",
      "R²: -0.017010154533373845\n",
      "Pipeline exportado para Colesterol Total (mg/dL) en el grupo de edad 31-60\n",
      "\n",
      "\n",
      "------ Grupo de Edad: 60+ ------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -1032.7569461323117\n",
      "\n",
      "Generation 2 - Current best internal CV score: -1032.7569461323117\n",
      "\n",
      "Generation 3 - Current best internal CV score: -1032.5715410143723\n",
      "\n",
      "Generation 4 - Current best internal CV score: -1032.5609619240468\n",
      "\n",
      "Generation 5 - Current best internal CV score: -1032.5609619240468\n",
      "\n",
      "Generation 6 - Current best internal CV score: -1032.5609619240468\n",
      "\n",
      "Generation 7 - Current best internal CV score: -1030.6700227188926\n",
      "\n",
      "Generation 8 - Current best internal CV score: -1030.6700227188926\n",
      "\n",
      "Generation 9 - Current best internal CV score: -1030.6700227188926\n",
      "\n",
      "Generation 10 - Current best internal CV score: -1030.6700227188926\n",
      "\n",
      "Best pipeline: GradientBoostingRegressor(input_matrix, alpha=0.75, learning_rate=0.01, loss=quantile, max_depth=1, max_features=0.4, min_samples_leaf=8, min_samples_split=15, n_estimators=100, subsample=0.45)\n",
      "\n",
      "Métricas de regresión para Insulina (μU/mL) en el grupo de edad 60+:\n",
      "MAE: 9.199938690428848\n",
      "MSE: 277.84694697276814\n",
      "RMSE: 16.668741613354264\n",
      "R²: -0.04431537556583298\n",
      "Pipeline exportado para Insulina (μU/mL) en el grupo de edad 60+\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -1887.8413624189707\n",
      "\n",
      "Generation 2 - Current best internal CV score: -1887.8413624189707\n",
      "\n",
      "Generation 3 - Current best internal CV score: -1887.8267653858627\n",
      "\n",
      "Generation 4 - Current best internal CV score: -1887.8267653858627\n",
      "\n",
      "Generation 5 - Current best internal CV score: -1887.8214234659295\n",
      "\n",
      "Generation 6 - Current best internal CV score: -1887.1996945980131\n",
      "\n",
      "Generation 7 - Current best internal CV score: -1887.1996945980131\n",
      "\n",
      "Generation 8 - Current best internal CV score: -1887.1996945980131\n",
      "\n",
      "Generation 9 - Current best internal CV score: -1887.1996945980131\n",
      "\n",
      "Generation 10 - Current best internal CV score: -1886.7158732649427\n",
      "\n",
      "Best pipeline: RidgeCV(Nystroem(input_matrix, gamma=0.4, kernel=rbf, n_components=10))\n",
      "\n",
      "Métricas de regresión para Colesterol Total (mg/dL) en el grupo de edad 60+:\n",
      "MAE: 35.57210411521358\n",
      "MSE: 1968.475877167195\n",
      "RMSE: 44.36750925133385\n",
      "R²: -0.006018249203833426\n",
      "Pipeline exportado para Colesterol Total (mg/dL) en el grupo de edad 60+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterar sobre cada grupo de edad\n",
    "for grupo in labels:\n",
    "    # Filtrar el dataframe por grupo de edad\n",
    "    group_df = question5[question5['Grupo de Edad'] == grupo]\n",
    "    \n",
    "    # Seleccionar las variables predictoras y los targets\n",
    "    X = group_df[['Edad en años al momento del examen']]\n",
    "    y = group_df[['Insulina (μU/mL)', 'Colesterol Total (mg/dL)']]\n",
    "    \n",
    "    # Imputar valores faltantes en X\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_imputed = imputer.fit_transform(X)\n",
    "    \n",
    "    print(f\"\\n------ Grupo de Edad: {grupo} ------\")\n",
    "    \n",
    "    # Iterar sobre cada target para ejecutar TPOT\n",
    "    for target, file_name in targets.items():\n",
    "        # División de datos\n",
    "        y_target = y[target].dropna()\n",
    "        X_filtered = X_imputed[~y[target].isna()]  # Filtrar X para que coincida con y no nulo\n",
    "        if len(X_filtered) == 0:\n",
    "            print(f\"No hay suficientes datos para {target} en el grupo de edad {grupo}.\")\n",
    "            continue\n",
    "            \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_filtered, y_target, train_size=0.75, test_size=0.25, random_state=42)\n",
    "        \n",
    "        # TPOT para regresión\n",
    "        tpot_regressor = TPOTRegressor(verbosity=2, generations=10, population_size=20, random_state=42)\n",
    "        tpot_regressor.fit(X_train, y_train)\n",
    "        \n",
    "        # Realizar predicciones\n",
    "        y_pred = tpot_regressor.predict(X_test)\n",
    "        \n",
    "        # Calcular métricas\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Imprimir métricas para cada target\n",
    "        print(f\"\\nMétricas de regresión para {target} en el grupo de edad {grupo}:\")\n",
    "        print(f\"MAE: {mae}\")\n",
    "        print(f\"MSE: {mse}\")\n",
    "        print(f\"RMSE: {rmse}\")\n",
    "        print(f\"R²: {r2}\")\n",
    "        \n",
    "        # Exportar el pipeline con nombre de archivo sin caracteres especiales\n",
    "        file_name_cleaned = f\"{file_name}_{grupo}\".replace('/', '_')\n",
    "        tpot_regressor.export(f'best_pipeline_{file_name_cleaned}_regression.py')\n",
    "        print(f\"Pipeline exportado para {target} en el grupo de edad {grupo}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Age Group: 0-30\n",
    "\n",
    "#### Regression for Insulin (μU/mL)\n",
    "The model selected is XGBRegressor combined with Normalizer (using L1 normalization). XGBRegressor uses 100 estimators with a learning rate of 0.01, max depth of 1, and subsample of 0.2, focusing on reducing overfitting. The performance is poor, with a negative R² of -0.075 and an MAE of 7.69, indicating limited predictive power.\n",
    "\n",
    "#### Regression for Total Cholesterol (mg/dL)\n",
    "A DecisionTreeRegressor was chosen with a max depth of 2, a minimum of 7 samples per leaf, and a minimum of 8 samples per split. The model shows a modest R² of 0.043 and an MAE of 23.61, suggesting moderate accuracy.\n",
    "\n",
    "### Age Group: 31-60\n",
    "\n",
    "#### Regression for Insulin (μU/mL)\n",
    "The model uses LinearSVR with C=0.1, epsilon of 1.0, and squared epsilon-insensitive loss, making it more tolerant to deviations. It achieves a low R² of -0.009 and an MAE of 9.25, indicating weak predictive performance.\n",
    "\n",
    "#### Regression for Total Cholesterol (mg/dL)\n",
    "A DecisionTreeRegressor with a max depth of 2, 19 minimum samples per leaf, and 18 minimum samples per split was selected. It has a negative R² of -0.017 and an MAE of 30.62, reflecting a poor fit.\n",
    "\n",
    "### Age Group: 60+\n",
    "\n",
    "#### Regression for Insulin (μU/mL)\n",
    "The model uses GradientBoostingRegressor with quantile loss, alpha of 0.75, learning rate of 0.01, and subsample of 0.45. Despite being a sophisticated ensemble model, it still has a negative R² of -0.044 and an MAE of 9.20, indicating limited accuracy.\n",
    "\n",
    "#### Regression for Total Cholesterol (mg/dL)\n",
    "The chosen model is RidgeCV combined with Nystroem kernel approximation using an RBF kernel, gamma of 0.4, and 10 components. The performance is poor, with an R² of -0.006 and an MAE of 35.57, indicating weak predictive capacity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Question 6: Does a higher poverty index level correlate with an increase in depressive symptoms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ID  Relación de ingresos familiares con la pobreza  \\\n",
      "0 109266.00                                            5.00   \n",
      "1 109271.00                                            5.00   \n",
      "2 109273.00                                            0.83   \n",
      "3 109274.00                                            1.20   \n",
      "4 109282.00                                            3.61   \n",
      "\n",
      "   Poco Interés en Hacer Cosas  Sentirse Deprimido o Sin Esperanza  \\\n",
      "0                         0.00                                0.00   \n",
      "1                         2.00                                1.00   \n",
      "2                         2.00                                2.00   \n",
      "3                         0.00                                0.00   \n",
      "4                         0.00                                1.00   \n",
      "\n",
      "   Problemas para Dormir  Cansancio o Poca Energía  \\\n",
      "0                   0.00                      0.00   \n",
      "1                   0.00                      0.00   \n",
      "2                   2.00                      2.00   \n",
      "3                   0.00                      0.00   \n",
      "4                   0.00                      1.00   \n",
      "\n",
      "   Poco Apetito o Comer en Exceso  Sentirse Mal Acerca de Uno Mismo  \\\n",
      "0                            0.00                              0.00   \n",
      "1                            0.00                              0.00   \n",
      "2                            2.00                              2.00   \n",
      "3                            0.00                              0.00   \n",
      "4                            0.00                              0.00   \n",
      "\n",
      "   Problemas de Concentración  Movimientos o Hablar Lento o Rápido  \\\n",
      "0                        0.00                                 0.00   \n",
      "1                        2.00                                 0.00   \n",
      "2                        2.00                                 1.00   \n",
      "3                        0.00                                 0.00   \n",
      "4                        0.00                                 3.00   \n",
      "\n",
      "   Pensamientos de Muerte o Autolesión  Dificultad que Estos Problemas Causan  \n",
      "0                                 0.00                                   0.00  \n",
      "1                                 0.00                                   0.00  \n",
      "2                                 0.00                                   0.00  \n",
      "3                                 0.00                                   0.00  \n",
      "4                                 0.00                                   0.00  \n",
      "Cantidad de registros combinados: (8965, 12)\n"
     ]
    }
   ],
   "source": [
    "# Filtrar columnas necesarias en cada dataset\n",
    "demografia_filtered = demografia[['ID', 'Relación de ingresos familiares con la pobreza']]\n",
    "depresion_filtered = depresion[['ID', \n",
    "                                'Poco Interés en Hacer Cosas', \n",
    "                                'Sentirse Deprimido o Sin Esperanza', \n",
    "                                'Problemas para Dormir', \n",
    "                                'Cansancio o Poca Energía', \n",
    "                                'Poco Apetito o Comer en Exceso',\n",
    "                                'Sentirse Mal Acerca de Uno Mismo',\n",
    "                                'Problemas de Concentración',\n",
    "                                'Movimientos o Hablar Lento o Rápido',\n",
    "                                'Pensamientos de Muerte o Autolesión',\n",
    "                                'Dificultad que Estos Problemas Causan']]\n",
    "\n",
    "# Unir los datasets\n",
    "question6 = demografia_filtered.merge(depresion_filtered, on='ID', how='inner')\n",
    "\n",
    "# Imputar valores faltantes\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "question6_imputed = pd.DataFrame(imputer.fit_transform(question6), columns=question6.columns)\n",
    "\n",
    "# Revisar el DataFrame resultante\n",
    "print(question6_imputed.head())\n",
    "print(\"Cantidad de registros combinados:\", question6_imputed.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear la variable objetivo basada en la suma de síntomas depresivos\n",
    "question6_imputed['Riesgo_Depresion'] = question6_imputed[['Poco Interés en Hacer Cosas', \n",
    "                                                           'Sentirse Deprimido o Sin Esperanza', \n",
    "                                                           'Problemas para Dormir', \n",
    "                                                           'Cansancio o Poca Energía']].sum(axis=1)\n",
    "\n",
    "# Asignar categorías de riesgo\n",
    "bins = [0, 1, 2, 3, 4]  # Categorías basadas en la escala de síntomas\n",
    "labels = ['nulo' ,'bajo', 'moderado', 'alto']\n",
    "question6_imputed['Riesgo_Depresion'] = pd.cut(question6_imputed['Riesgo_Depresion'], bins=bins, labels=labels)\n",
    "\n",
    "# Convertir la variable de riesgo a numérica\n",
    "question6_imputed['Riesgo_Depresion'] = question6_imputed['Riesgo_Depresion'].cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.5976499159143212\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.5976499159143212\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.5976499159143212\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.5976499159143212\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.5976499159143212\n",
      "\n",
      "Generation 6 - Current best internal CV score: 0.5976499159143212\n",
      "\n",
      "Generation 7 - Current best internal CV score: 0.5976499159143212\n",
      "\n",
      "Generation 8 - Current best internal CV score: 0.5976499159143212\n",
      "\n",
      "Generation 9 - Current best internal CV score: 0.5976499159143212\n",
      "\n",
      "Generation 10 - Current best internal CV score: 0.5976499159143212\n",
      "\n",
      "Best pipeline: GaussianNB(input_matrix)\n",
      "Score de clasificación para Riesgo_Depresion: 0.6159678858162355\n",
      "\n",
      "Matriz de confusión para Riesgo_Depresion:\n",
      "[[1381    0    0    0    0    0]\n",
      " [ 380    0    0    0    0    0]\n",
      " [ 202    0    0    0    0    0]\n",
      " [ 108    0    0    0    0    0]\n",
      " [  85    0    0    0    0    0]\n",
      " [  86    0    0    0    0    0]]\n",
      "\n",
      "Reporte de clasificación para Riesgo_Depresion:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[10/25/24 21:35:55] </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> C:\\Program                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">warnings.py:110</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Files\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">531</span>: UndefinedMetricWarning: Precision is ill-defined and being set to <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> in labels with no predicted samples. Use `zero_division` parameter <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to control this behavior.                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>           <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">_warn_prf</span><span style=\"font-weight: bold\">(</span>average, modifier, f\"<span style=\"font-weight: bold\">{</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">metric.capitalize</span><span style=\"font-weight: bold\">()}</span> is\",            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">len</span><span style=\"font-weight: bold\">(</span>result<span style=\"font-weight: bold\">))</span>                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[10/25/24 21:35:55]\u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m C:\\Program                                                             \u001b[2mwarnings.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m110\u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         Files\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:\u001b[1;36m1\u001b[0m \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;36m531\u001b[0m: UndefinedMetricWarning: Precision is ill-defined and being set to \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;36m0.0\u001b[0m in labels with no predicted samples. Use `zero_division` parameter \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to control this behavior.                                              \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m           \u001b[1;35m_warn_prf\u001b[0m\u001b[1m(\u001b[0maverage, modifier, f\"\u001b[1m{\u001b[0m\u001b[1;35mmetric.capitalize\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\u001b[1m}\u001b[0m is\",            \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;35mlen\u001b[0m\u001b[1m(\u001b[0mresult\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m                                                           \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> C:\\Program                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">warnings.py:110</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Files\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">531</span>: UndefinedMetricWarning: Precision is ill-defined and being set to <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> in labels with no predicted samples. Use `zero_division` parameter <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to control this behavior.                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>           <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">_warn_prf</span><span style=\"font-weight: bold\">(</span>average, modifier, f\"<span style=\"font-weight: bold\">{</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">metric.capitalize</span><span style=\"font-weight: bold\">()}</span> is\",            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">len</span><span style=\"font-weight: bold\">(</span>result<span style=\"font-weight: bold\">))</span>                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m C:\\Program                                                             \u001b[2mwarnings.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m110\u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         Files\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:\u001b[1;36m1\u001b[0m \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;36m531\u001b[0m: UndefinedMetricWarning: Precision is ill-defined and being set to \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;36m0.0\u001b[0m in labels with no predicted samples. Use `zero_division` parameter \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to control this behavior.                                              \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m           \u001b[1;35m_warn_prf\u001b[0m\u001b[1m(\u001b[0maverage, modifier, f\"\u001b[1m{\u001b[0m\u001b[1;35mmetric.capitalize\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\u001b[1m}\u001b[0m is\",            \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;35mlen\u001b[0m\u001b[1m(\u001b[0mresult\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m                                                           \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> C:\\Program                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">warnings.py:110</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Files\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">531</span>: UndefinedMetricWarning: Precision is ill-defined and being set to <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> in labels with no predicted samples. Use `zero_division` parameter <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to control this behavior.                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>           <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">_warn_prf</span><span style=\"font-weight: bold\">(</span>average, modifier, f\"<span style=\"font-weight: bold\">{</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">metric.capitalize</span><span style=\"font-weight: bold\">()}</span> is\",            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">len</span><span style=\"font-weight: bold\">(</span>result<span style=\"font-weight: bold\">))</span>                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m C:\\Program                                                             \u001b[2mwarnings.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m110\u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         Files\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:\u001b[1;36m1\u001b[0m \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;36m531\u001b[0m: UndefinedMetricWarning: Precision is ill-defined and being set to \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;36m0.0\u001b[0m in labels with no predicted samples. Use `zero_division` parameter \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to control this behavior.                                              \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m           \u001b[1;35m_warn_prf\u001b[0m\u001b[1m(\u001b[0maverage, modifier, f\"\u001b[1m{\u001b[0m\u001b[1;35mmetric.capitalize\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\u001b[1m}\u001b[0m is\",            \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;35mlen\u001b[0m\u001b[1m(\u001b[0mresult\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m                                                           \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.76      1381\n",
      "           1       0.00      0.00      0.00       380\n",
      "           2       0.00      0.00      0.00       202\n",
      "           3       0.00      0.00      0.00       108\n",
      "           4       0.00      0.00      0.00        85\n",
      "           5       0.00      0.00      0.00        86\n",
      "\n",
      "    accuracy                           0.62      2242\n",
      "   macro avg       0.10      0.17      0.13      2242\n",
      "weighted avg       0.38      0.62      0.47      2242\n",
      "\n",
      "Pipeline exportado para clasificación de Riesgo_Depresion\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Imputar valores faltantes ('Missing') en todas las variables de síntomas depresivos\n",
    "variables_sintomas = ['Poco Interés en Hacer Cosas', \n",
    "                      'Sentirse Deprimido o Sin Esperanza', \n",
    "                      'Problemas para Dormir', \n",
    "                      'Cansancio o Poca Energía',\n",
    "                      'Poco Apetito o Comer en Exceso',\n",
    "                      'Sentirse Mal Acerca de Uno Mismo',\n",
    "                      'Problemas de Concentración',\n",
    "                      'Movimientos o Hablar Lento o Rápido',\n",
    "                      'Pensamientos de Muerte o Autolesión',\n",
    "                      'Dificultad que Estos Problemas Causan']\n",
    "\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "question6_imputed[variables_sintomas] = imputer.fit_transform(question6_imputed[variables_sintomas])\n",
    "\n",
    "# Crear la variable objetivo basada en la suma de todos los síntomas depresivos\n",
    "question6_imputed['Riesgo_Depresion'] = question6_imputed[variables_sintomas].sum(axis=1)\n",
    "\n",
    "# Asignar nuevas categorías de riesgo basadas en la escala de síntomas\n",
    "bins = [0, 2, 5, 8, 11, 15, float('inf')]\n",
    "labels = ['nulo', 'leve', 'moderado', 'alto', 'muy alto', 'extremo']\n",
    "question6_imputed['Riesgo_Depresion'] = pd.cut(question6_imputed['Riesgo_Depresion'], bins=bins, labels=labels)\n",
    "\n",
    "# Convertir la variable de riesgo a numérica\n",
    "question6_imputed['Riesgo_Depresion'] = question6_imputed['Riesgo_Depresion'].cat.codes\n",
    "\n",
    "# Selección de la variable predictora y el target\n",
    "X = question6_imputed[['Relación de ingresos familiares con la pobreza']]\n",
    "y = question6_imputed['Riesgo_Depresion']\n",
    "\n",
    "# División de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, test_size=0.25, random_state=42)\n",
    "\n",
    "# TPOT para clasificación\n",
    "tpot_classifier = TPOTClassifier(verbosity=2, generations=10, population_size=20, random_state=42, scoring='accuracy')\n",
    "tpot_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el modelo\n",
    "print(\"Score de clasificación para Riesgo_Depresion:\", tpot_classifier.score(X_test, y_test))\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred = tpot_classifier.predict(X_test)\n",
    "\n",
    "# Calcular métricas de evaluación\n",
    "print(\"\\nMatriz de confusión para Riesgo_Depresion:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nReporte de clasificación para Riesgo_Depresion:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Exportar el pipeline\n",
    "tpot_classifier.export('best_pipeline_depresion_classification.py')\n",
    "print(\"Pipeline exportado para clasificación de Riesgo_Depresion\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Age Group: All Ages\n",
    "#### Classification for Depression Risk Levels\n",
    "The best model selected is **GaussianNB**, identified after evaluating multiple generations of models. GaussianNB operates under the assumption that features are normally distributed, making it efficient for simpler data structures. The model predicts the depression risk categories based on summed depressive symptoms, which were categorized into six levels: nulo, leve, moderado, alto, muy alto, and extremo.\n",
    "\n",
    "- **Preprocessing**:\n",
    "  - Imputation was performed using the most frequent strategy to handle missing values.\n",
    "  - The depressive symptoms were summed to form a risk score and categorized into six risk levels, later encoded as numeric variables for classification.\n",
    "\n",
    "- **Performance Metrics**:\n",
    "  - **Classification Accuracy**: 61.60% on test data, indicating that the model has a moderate predictive capability, primarily for the nulo risk category.\n",
    "  - **Confusion Matrix**:\n",
    "    - The model correctly predicted 1,381 cases in the nulo category.\n",
    "    - It failed to correctly predict any cases in the leve, moderado, alto, muy alto, or extremo categories, highlighting an issue with class imbalance.\n",
    "  - **Precision, Recall, and F1-Score**:\n",
    "    - Precision, recall, and f1-score are significantly skewed toward the nulo category, with zero performance for other categories.\n",
    "    - The macro average across metrics (precision: 0.10, recall: 0.17, f1-score: 0.13) indicates overall poor classification for higher risk categories.\n",
    "    - The weighted average (precision: 0.38, recall: 0.62, f1-score: 0.47) reflects an imbalance in performance across the risk levels.\n",
    "\n",
    "- **Interpretation**:\n",
    "  - While the model performs reasonably well in identifying the nulo risk category, it fails to generalize for higher risk levels. Further adjustments, such as oversampling, undersampling, or trying different models, may be necessary to improve performance across all categories.\n",
    "\n",
    "- **Pipeline Export**: \n",
    "  - The GaussianNB pipeline has been exported for further refinement, deployment, or analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Refinement of Classification Model\n",
    "Since this is our only classification model, we will focus on tuning it to achieve better results. The initial GaussianNB model demonstrates moderate performance, particularly in predicting the lowest risk category (nulo). However, it struggles with the higher risk levels due to class imbalance and limited feature complexity.\n",
    "\n",
    "To enhance the model's accuracy and generalization, we will implement strategies such as:\n",
    "- **Hyperparameter Tuning**: Adjusting parameters like priors and var_smoothing in GaussianNB to optimize performance.\n",
    "- **Class Balancing Techniques**: Using oversampling or undersampling methods to address the class imbalance, ensuring better representation of all risk levels during training.\n",
    "\n",
    "The goal is to develop a more robust classification model that achieves higher accuracy across all depression risk levels, providing a more reliable assessment of depressive symptoms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de confusión para Riesgo_Depresion:\n",
      "[[618 114 216 153 154 126]\n",
      " [154  43  55  50  44  34]\n",
      " [ 68  24  30  27  23  30]\n",
      " [ 30  11  13  15  21  18]\n",
      " [ 22   6   9  13  18  17]\n",
      " [ 24   6  15  15  16  10]]\n",
      "\n",
      "Reporte de clasificación para Riesgo_Depresion:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.45      0.54      1381\n",
      "           1       0.21      0.11      0.15       380\n",
      "           2       0.09      0.15      0.11       202\n",
      "           3       0.05      0.14      0.08       108\n",
      "           4       0.07      0.21      0.10        85\n",
      "           5       0.04      0.12      0.06        86\n",
      "\n",
      "    accuracy                           0.33      2242\n",
      "   macro avg       0.19      0.20      0.17      2242\n",
      "weighted avg       0.47      0.33      0.38      2242\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# División de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, test_size=0.25, random_state=42)\n",
    "\n",
    "# Modelo de RandomForest con pesos balanceados\n",
    "rf_classifier = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el modelo\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Matriz de confusión y reporte de clasificación\n",
    "print(\"\\nMatriz de confusión para Riesgo_Depresion:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nReporte de clasificación para Riesgo_Depresion:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Classification Model for Depression Risk\n",
    "#### Model: GaussianNB\n",
    "The GaussianNB classifier was selected as the best model for predicting depression risk. The model's performance indicates some challenges in classifying higher risk levels, particularly due to imbalanced data distribution across categories, as we can see in our accuracy, however some improvement has been done.\n",
    "\n",
    "#### Classification Report for Depression Risk\n",
    "- **Accuracy**: 0.33\n",
    "- **Precision (Weighted Avg)**: 0.47\n",
    "- **Recall (Weighted Avg)**: 0.33\n",
    "- **F1-Score (Weighted Avg)**: 0.38\n",
    "\n",
    "##### Category-wise Performance\n",
    "- **Category 0 (nulo)**: Precision: 0.67, Recall: 0.45, F1-Score: 0.54, Support: 1381\n",
    "- **Category 1 (leve)**: Precision: 0.21, Recall: 0.11, F1-Score: 0.15, Support: 380\n",
    "- **Category 2 (moderado)**: Precision: 0.09, Recall: 0.15, F1-Score: 0.11, Support: 202\n",
    "- **Category 3 (alto)**: Precision: 0.05, Recall: 0.14, F1-Score: 0.08, Support: 108\n",
    "- **Category 4 (muy alto)**: Precision: 0.07, Recall: 0.21, F1-Score: 0.10, Support: 85\n",
    "- **Category 5 (extremo)**: Precision: 0.04, Recall: 0.12, F1-Score: 0.06, Support: 86\n",
    "\n",
    "The aim is to refine the model to achieve more accurate and reliable predictions across all risk levels of depression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando modelo: RandomForest...\n",
      "\n",
      "Matriz de confusión para RandomForest:\n",
      "[[694 148 142 129 120 117]\n",
      " [189  45  54  41  41  43]\n",
      " [ 75  28  21  23  23  35]\n",
      " [ 47  10  13  17  12  19]\n",
      " [ 34  10   9   9  10  13]\n",
      " [ 26   9   7   6   9  14]]\n",
      "\n",
      "Reporte de clasificación para RandomForest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.51      0.57      1350\n",
      "           1       0.18      0.11      0.14       413\n",
      "           2       0.09      0.10      0.09       205\n",
      "           3       0.08      0.14      0.10       118\n",
      "           4       0.05      0.12      0.07        85\n",
      "           5       0.06      0.20      0.09        71\n",
      "\n",
      "    accuracy                           0.36      2242\n",
      "   macro avg       0.18      0.20      0.18      2242\n",
      "weighted avg       0.44      0.36      0.39      2242\n",
      "\n",
      "\n",
      "Entrenando modelo: XGBoost...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[10/25/24 21:46:37] </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> C:\\Program Files\\Python311\\Lib\\site-packages\\xgboost\\core.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">158</span>:      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">warnings.py:110</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         UserWarning: <span style=\"font-weight: bold\">[</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">21:46:37</span><span style=\"font-weight: bold\">]</span> WARNING:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0e <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         d59c031377d09b8-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\\xgboost\\xgboost-ci-windows\\src\\learner.<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">cc:740</span>:       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Parameters: <span style=\"font-weight: bold\">{</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"use_label_encoder\"</span> <span style=\"font-weight: bold\">}</span> are not used.                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>           <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">warnings.warn</span><span style=\"font-weight: bold\">(</span>smsg, UserWarning<span style=\"font-weight: bold\">)</span>                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[10/25/24 21:46:37]\u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m C:\\Program Files\\Python311\\Lib\\site-packages\\xgboost\\core.py:\u001b[1;36m158\u001b[0m:      \u001b[2mwarnings.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m110\u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         UserWarning: \u001b[1m[\u001b[0m\u001b[1;92m21:46:37\u001b[0m\u001b[1m]\u001b[0m WARNING:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0e \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         d59c031377d09b8-\u001b[1;36m1\u001b[0m\\xgboost\\xgboost-ci-windows\\src\\learner.\u001b[1;92mcc:740\u001b[0m:       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         Parameters: \u001b[1m{\u001b[0m \u001b[32m\"use_label_encoder\"\u001b[0m \u001b[1m}\u001b[0m are not used.                      \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m           \u001b[1;35mwarnings.warn\u001b[0m\u001b[1m(\u001b[0msmsg, UserWarning\u001b[1m)\u001b[0m                                     \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de confusión para XGBoost:\n",
      "[[1245   61   26   17    1    0]\n",
      " [ 385   19    6    3    0    0]\n",
      " [ 190   10    2    3    0    0]\n",
      " [ 109    5    1    2    1    0]\n",
      " [  77    5    0    2    1    0]\n",
      " [  66    5    0    0    0    0]]\n",
      "\n",
      "Reporte de clasificación para XGBoost:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> C:\\Program                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">warnings.py:110</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Files\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">531</span>: UndefinedMetricWarning: Precision is ill-defined and being set to <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> in labels with no predicted samples. Use `zero_division` parameter <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to control this behavior.                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>           <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">_warn_prf</span><span style=\"font-weight: bold\">(</span>average, modifier, f\"<span style=\"font-weight: bold\">{</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">metric.capitalize</span><span style=\"font-weight: bold\">()}</span> is\",            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">len</span><span style=\"font-weight: bold\">(</span>result<span style=\"font-weight: bold\">))</span>                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m C:\\Program                                                             \u001b[2mwarnings.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m110\u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         Files\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:\u001b[1;36m1\u001b[0m \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;36m531\u001b[0m: UndefinedMetricWarning: Precision is ill-defined and being set to \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;36m0.0\u001b[0m in labels with no predicted samples. Use `zero_division` parameter \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to control this behavior.                                              \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m           \u001b[1;35m_warn_prf\u001b[0m\u001b[1m(\u001b[0maverage, modifier, f\"\u001b[1m{\u001b[0m\u001b[1;35mmetric.capitalize\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\u001b[1m}\u001b[0m is\",            \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;35mlen\u001b[0m\u001b[1m(\u001b[0mresult\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m                                                           \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> C:\\Program                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">warnings.py:110</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Files\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">531</span>: UndefinedMetricWarning: Precision is ill-defined and being set to <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> in labels with no predicted samples. Use `zero_division` parameter <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to control this behavior.                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>           <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">_warn_prf</span><span style=\"font-weight: bold\">(</span>average, modifier, f\"<span style=\"font-weight: bold\">{</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">metric.capitalize</span><span style=\"font-weight: bold\">()}</span> is\",            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">len</span><span style=\"font-weight: bold\">(</span>result<span style=\"font-weight: bold\">))</span>                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m C:\\Program                                                             \u001b[2mwarnings.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m110\u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         Files\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:\u001b[1;36m1\u001b[0m \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;36m531\u001b[0m: UndefinedMetricWarning: Precision is ill-defined and being set to \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;36m0.0\u001b[0m in labels with no predicted samples. Use `zero_division` parameter \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to control this behavior.                                              \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m           \u001b[1;35m_warn_prf\u001b[0m\u001b[1m(\u001b[0maverage, modifier, f\"\u001b[1m{\u001b[0m\u001b[1;35mmetric.capitalize\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\u001b[1m}\u001b[0m is\",            \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;35mlen\u001b[0m\u001b[1m(\u001b[0mresult\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m                                                           \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> C:\\Program                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">warnings.py:110</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Files\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">531</span>: UndefinedMetricWarning: Precision is ill-defined and being set to <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> in labels with no predicted samples. Use `zero_division` parameter <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to control this behavior.                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>           <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">_warn_prf</span><span style=\"font-weight: bold\">(</span>average, modifier, f\"<span style=\"font-weight: bold\">{</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">metric.capitalize</span><span style=\"font-weight: bold\">()}</span> is\",            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">len</span><span style=\"font-weight: bold\">(</span>result<span style=\"font-weight: bold\">))</span>                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m C:\\Program                                                             \u001b[2mwarnings.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m110\u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         Files\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:\u001b[1;36m1\u001b[0m \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;36m531\u001b[0m: UndefinedMetricWarning: Precision is ill-defined and being set to \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;36m0.0\u001b[0m in labels with no predicted samples. Use `zero_division` parameter \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to control this behavior.                                              \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m           \u001b[1;35m_warn_prf\u001b[0m\u001b[1m(\u001b[0maverage, modifier, f\"\u001b[1m{\u001b[0m\u001b[1;35mmetric.capitalize\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\u001b[1m}\u001b[0m is\",            \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;35mlen\u001b[0m\u001b[1m(\u001b[0mresult\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m                                                           \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.92      0.73      1350\n",
      "           1       0.18      0.05      0.07       413\n",
      "           2       0.06      0.01      0.02       205\n",
      "           3       0.07      0.02      0.03       118\n",
      "           4       0.33      0.01      0.02        85\n",
      "           5       0.00      0.00      0.00        71\n",
      "\n",
      "    accuracy                           0.57      2242\n",
      "   macro avg       0.21      0.17      0.14      2242\n",
      "weighted avg       0.42      0.57      0.46      2242\n",
      "\n",
      "\n",
      "Entrenando modelo: GradientBoosting...\n",
      "\n",
      "Matriz de confusión para GradientBoosting:\n",
      "[[1244   43   33   21    7    2]\n",
      " [ 388    8   10    4    3    0]\n",
      " [ 188    9    1    4    3    0]\n",
      " [ 108    5    2    1    2    0]\n",
      " [  78    1    2    2    2    0]\n",
      " [  65    2    2    0    2    0]]\n",
      "\n",
      "Reporte de clasificación para GradientBoosting:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.92      0.73      1350\n",
      "           1       0.12      0.02      0.03       413\n",
      "           2       0.02      0.00      0.01       205\n",
      "           3       0.03      0.01      0.01       118\n",
      "           4       0.11      0.02      0.04        85\n",
      "           5       0.00      0.00      0.00        71\n",
      "\n",
      "    accuracy                           0.56      2242\n",
      "   macro avg       0.15      0.16      0.14      2242\n",
      "weighted avg       0.39      0.56      0.45      2242\n",
      "\n",
      "\n",
      "Entrenando modelo: VotingClassifier...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[10/25/24 21:46:40] </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> C:\\Program Files\\Python311\\Lib\\site-packages\\xgboost\\core.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">158</span>:      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">warnings.py:110</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         UserWarning: <span style=\"font-weight: bold\">[</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">21:46:40</span><span style=\"font-weight: bold\">]</span> WARNING:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0e <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         d59c031377d09b8-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\\xgboost\\xgboost-ci-windows\\src\\learner.<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">cc:740</span>:       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Parameters: <span style=\"font-weight: bold\">{</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"use_label_encoder\"</span> <span style=\"font-weight: bold\">}</span> are not used.                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>           <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">warnings.warn</span><span style=\"font-weight: bold\">(</span>smsg, UserWarning<span style=\"font-weight: bold\">)</span>                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[10/25/24 21:46:40]\u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m C:\\Program Files\\Python311\\Lib\\site-packages\\xgboost\\core.py:\u001b[1;36m158\u001b[0m:      \u001b[2mwarnings.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m110\u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         UserWarning: \u001b[1m[\u001b[0m\u001b[1;92m21:46:40\u001b[0m\u001b[1m]\u001b[0m WARNING:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0e \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         d59c031377d09b8-\u001b[1;36m1\u001b[0m\\xgboost\\xgboost-ci-windows\\src\\learner.\u001b[1;92mcc:740\u001b[0m:       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         Parameters: \u001b[1m{\u001b[0m \u001b[32m\"use_label_encoder\"\u001b[0m \u001b[1m}\u001b[0m are not used.                      \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m           \u001b[1;35mwarnings.warn\u001b[0m\u001b[1m(\u001b[0msmsg, UserWarning\u001b[1m)\u001b[0m                                     \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de confusión para VotingClassifier:\n",
      "[[1165   65   52   34   18   16]\n",
      " [ 354   22   16    7   10    4]\n",
      " [ 176   13    4    5    4    3]\n",
      " [ 103    5    2    4    3    1]\n",
      " [  70    4    2    2    6    1]\n",
      " [  60    5    2    1    3    0]]\n",
      "\n",
      "Reporte de clasificación para VotingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.86      0.71      1350\n",
      "           1       0.19      0.05      0.08       413\n",
      "           2       0.05      0.02      0.03       205\n",
      "           3       0.08      0.03      0.05       118\n",
      "           4       0.14      0.07      0.09        85\n",
      "           5       0.00      0.00      0.00        71\n",
      "\n",
      "    accuracy                           0.54      2242\n",
      "   macro avg       0.18      0.17      0.16      2242\n",
      "weighted avg       0.41      0.54      0.45      2242\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, make_scorer, f1_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# División de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "# Balanceo manual con RandomOverSampler\n",
    "X_train_resampled, y_train_resampled = resample(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    replace=True,  # Permitir duplicados para balancear\n",
    "    n_samples=y_train.value_counts().max(),  # Balancear con la clase mayoritaria\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Definir modelos con ajustes de class_weight\n",
    "modelos = {\n",
    "    \"RandomForest\": RandomForestClassifier(class_weight='balanced', random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"VotingClassifier\": VotingClassifier(\n",
    "        estimators=[\n",
    "            ('rf', RandomForestClassifier(class_weight='balanced', random_state=42)),\n",
    "            ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)),\n",
    "            ('gb', GradientBoostingClassifier(random_state=42))\n",
    "        ], voting='soft'\n",
    "    )\n",
    "}\n",
    "\n",
    "# Configuración de GridSearchCV con F1-score macro\n",
    "f1_scorer = make_scorer(f1_score, average='macro')\n",
    "param_grid = {\n",
    "    \"RandomForest\": {'n_estimators': [50, 100], 'max_depth': [5, 10]},\n",
    "    \"XGBoost\": {'n_estimators': [50, 100], 'max_depth': [3, 5]},\n",
    "    \"GradientBoosting\": {'n_estimators': [50, 100], 'max_depth': [3, 5]},\n",
    "    \"VotingClassifier\": {}\n",
    "}\n",
    "\n",
    "# Iterar sobre los modelos\n",
    "for nombre, modelo in modelos.items():\n",
    "    print(f\"\\nEntrenando modelo: {nombre}...\")\n",
    "    if nombre in param_grid and param_grid[nombre]:  # Verificar si hay parámetros en el grid\n",
    "        grid_search = GridSearchCV(modelo, param_grid[nombre], cv=3, scoring=f1_scorer, n_jobs=-1)\n",
    "        grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "        best_model = grid_search.best_estimator_\n",
    "    else:\n",
    "        best_model = modelo.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predicciones\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Métricas de evaluación\n",
    "    print(f\"\\nMatriz de confusión para {nombre}:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(f\"\\nReporte de clasificación para {nombre}:\")\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Models for Depression Risk\n",
    "\n",
    "#### Model: RandomForest\n",
    "The RandomForest model showed moderate performance, with a stronger ability to identify the 'nulo' risk category but struggled with higher risk categories, likely due to class imbalance.\n",
    "\n",
    "##### Classification Report\n",
    "- **Accuracy**: 0.36\n",
    "- **Precision (Weighted Avg)**: 0.44\n",
    "- **Recall (Weighted Avg)**: 0.36\n",
    "- **F1-Score (Weighted Avg)**: 0.39\n",
    "\n",
    "#### Model: XGBoost\n",
    "XGBoost demonstrated better accuracy, especially in identifying the 'nulo' category, achieving high recall. However, it performed poorly in detecting higher risk levels.\n",
    "\n",
    "##### Classification Report\n",
    "- **Accuracy**: 0.57\n",
    "- **Precision (Weighted Avg)**: 0.42\n",
    "- **Recall (Weighted Avg)**: 0.57\n",
    "- **F1-Score (Weighted Avg)**: 0.46\n",
    "\n",
    "#### Model: GradientBoosting\n",
    "GradientBoosting maintained similar performance to XGBoost, with better recall for the 'nulo' category but still struggled with higher risk levels.\n",
    "\n",
    "##### Classification Report\n",
    "- **Accuracy**: 0.56\n",
    "- **Precision (Weighted Avg)**: 0.39\n",
    "- **Recall (Weighted Avg)**: 0.56\n",
    "- **F1-Score (Weighted Avg)**: 0.45\n",
    "\n",
    "#### Model: VotingClassifier\n",
    "The VotingClassifier, which combined predictions from the previous models, showed improved performance in detecting 'nulo' risk and slightly better precision across other categories. However, recall for higher risk levels remained low.\n",
    "\n",
    "##### Classification Report\n",
    "- **Accuracy**: 0.54\n",
    "- **Precision (Weighted Avg)**: 0.41\n",
    "- **Recall (Weighted Avg)**: 0.54\n",
    "- **F1-Score (Weighted Avg)**: 0.45\n",
    "\n",
    "\n",
    "As we can observe, XGBoost had the highest accuracy at 57%, with better recall for the 'nulo' category, but overall performance remained low for other risk levels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando modelo: RandomForest...\n",
      "\n",
      "Reporte de clasificación para RandomForest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.48      0.56      1350\n",
      "           1       0.21      0.08      0.11       413\n",
      "           2       0.09      0.12      0.10       205\n",
      "           3       0.07      0.21      0.10       118\n",
      "           4       0.04      0.11      0.06        85\n",
      "           5       0.06      0.24      0.09        71\n",
      "\n",
      "    accuracy                           0.34      2242\n",
      "   macro avg       0.19      0.21      0.17      2242\n",
      "weighted avg       0.46      0.34      0.38      2242\n",
      "\n",
      "\n",
      "Entrenando modelo: XGBoost...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[10/25/24 21:57:18] </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> C:\\Program Files\\Python311\\Lib\\site-packages\\xgboost\\core.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">158</span>:      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">warnings.py:110</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         UserWarning: <span style=\"font-weight: bold\">[</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">21:57:18</span><span style=\"font-weight: bold\">]</span> WARNING:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0e <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         d59c031377d09b8-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\\xgboost\\xgboost-ci-windows\\src\\learner.<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">cc:740</span>:       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Parameters: <span style=\"font-weight: bold\">{</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"scale_pos_weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"use_label_encoder\"</span> <span style=\"font-weight: bold\">}</span> are not used.  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>           <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">warnings.warn</span><span style=\"font-weight: bold\">(</span>smsg, UserWarning<span style=\"font-weight: bold\">)</span>                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[10/25/24 21:57:18]\u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m C:\\Program Files\\Python311\\Lib\\site-packages\\xgboost\\core.py:\u001b[1;36m158\u001b[0m:      \u001b[2mwarnings.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m110\u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         UserWarning: \u001b[1m[\u001b[0m\u001b[1;92m21:57:18\u001b[0m\u001b[1m]\u001b[0m WARNING:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0e \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         d59c031377d09b8-\u001b[1;36m1\u001b[0m\\xgboost\\xgboost-ci-windows\\src\\learner.\u001b[1;92mcc:740\u001b[0m:       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         Parameters: \u001b[1m{\u001b[0m \u001b[32m\"scale_pos_weight\"\u001b[0m, \u001b[32m\"use_label_encoder\"\u001b[0m \u001b[1m}\u001b[0m are not used.  \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m           \u001b[1;35mwarnings.warn\u001b[0m\u001b[1m(\u001b[0msmsg, UserWarning\u001b[1m)\u001b[0m                                     \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reporte de clasificación para XGBoost:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[10/25/24 21:57:19] </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> C:\\Program                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">warnings.py:110</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Files\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">531</span>: UndefinedMetricWarning: Precision is ill-defined and being set to <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> in labels with no predicted samples. Use `zero_division` parameter <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to control this behavior.                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>           <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">_warn_prf</span><span style=\"font-weight: bold\">(</span>average, modifier, f\"<span style=\"font-weight: bold\">{</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">metric.capitalize</span><span style=\"font-weight: bold\">()}</span> is\",            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">len</span><span style=\"font-weight: bold\">(</span>result<span style=\"font-weight: bold\">))</span>                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[10/25/24 21:57:19]\u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m C:\\Program                                                             \u001b[2mwarnings.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m110\u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         Files\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:\u001b[1;36m1\u001b[0m \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;36m531\u001b[0m: UndefinedMetricWarning: Precision is ill-defined and being set to \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;36m0.0\u001b[0m in labels with no predicted samples. Use `zero_division` parameter \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to control this behavior.                                              \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m           \u001b[1;35m_warn_prf\u001b[0m\u001b[1m(\u001b[0maverage, modifier, f\"\u001b[1m{\u001b[0m\u001b[1;35mmetric.capitalize\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\u001b[1m}\u001b[0m is\",            \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;35mlen\u001b[0m\u001b[1m(\u001b[0mresult\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m                                                           \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> C:\\Program                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">warnings.py:110</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Files\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">531</span>: UndefinedMetricWarning: Precision is ill-defined and being set to <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> in labels with no predicted samples. Use `zero_division` parameter <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to control this behavior.                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>           <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">_warn_prf</span><span style=\"font-weight: bold\">(</span>average, modifier, f\"<span style=\"font-weight: bold\">{</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">metric.capitalize</span><span style=\"font-weight: bold\">()}</span> is\",            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">len</span><span style=\"font-weight: bold\">(</span>result<span style=\"font-weight: bold\">))</span>                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m C:\\Program                                                             \u001b[2mwarnings.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m110\u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         Files\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:\u001b[1;36m1\u001b[0m \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;36m531\u001b[0m: UndefinedMetricWarning: Precision is ill-defined and being set to \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;36m0.0\u001b[0m in labels with no predicted samples. Use `zero_division` parameter \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to control this behavior.                                              \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m           \u001b[1;35m_warn_prf\u001b[0m\u001b[1m(\u001b[0maverage, modifier, f\"\u001b[1m{\u001b[0m\u001b[1;35mmetric.capitalize\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\u001b[1m}\u001b[0m is\",            \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;35mlen\u001b[0m\u001b[1m(\u001b[0mresult\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m                                                           \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> C:\\Program                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">warnings.py:110</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Files\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">531</span>: UndefinedMetricWarning: Precision is ill-defined and being set to <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> in labels with no predicted samples. Use `zero_division` parameter <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to control this behavior.                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>           <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">_warn_prf</span><span style=\"font-weight: bold\">(</span>average, modifier, f\"<span style=\"font-weight: bold\">{</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">metric.capitalize</span><span style=\"font-weight: bold\">()}</span> is\",            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">len</span><span style=\"font-weight: bold\">(</span>result<span style=\"font-weight: bold\">))</span>                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m C:\\Program                                                             \u001b[2mwarnings.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m110\u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         Files\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:\u001b[1;36m1\u001b[0m \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;36m531\u001b[0m: UndefinedMetricWarning: Precision is ill-defined and being set to \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;36m0.0\u001b[0m in labels with no predicted samples. Use `zero_division` parameter \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to control this behavior.                                              \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m           \u001b[1;35m_warn_prf\u001b[0m\u001b[1m(\u001b[0maverage, modifier, f\"\u001b[1m{\u001b[0m\u001b[1;35mmetric.capitalize\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\u001b[1m}\u001b[0m is\",            \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;35mlen\u001b[0m\u001b[1m(\u001b[0mresult\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m                                                           \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      1.00      0.75      1350\n",
      "           1       0.18      0.00      0.01       413\n",
      "           2       0.00      0.00      0.00       205\n",
      "           3       0.00      0.00      0.00       118\n",
      "           4       0.00      0.00      0.00        85\n",
      "           5       0.00      0.00      0.00        71\n",
      "\n",
      "    accuracy                           0.60      2242\n",
      "   macro avg       0.13      0.17      0.13      2242\n",
      "weighted avg       0.40      0.60      0.45      2242\n",
      "\n",
      "\n",
      "Entrenando modelo: GradientBoosting...\n",
      "\n",
      "Reporte de clasificación para GradientBoosting:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.99      0.75      1350\n",
      "           1       0.12      0.00      0.01       413\n",
      "           2       0.00      0.00      0.00       205\n",
      "           3       0.00      0.00      0.00       118\n",
      "           4       0.00      0.00      0.00        85\n",
      "           5       0.00      0.00      0.00        71\n",
      "\n",
      "    accuracy                           0.60      2242\n",
      "   macro avg       0.12      0.17      0.13      2242\n",
      "weighted avg       0.38      0.60      0.45      2242\n",
      "\n",
      "\n",
      "Entrenando modelo: VotingClassifier...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[10/25/24 21:57:22] </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> C:\\Program Files\\Python311\\Lib\\site-packages\\xgboost\\core.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">158</span>:      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">warnings.py:110</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         UserWarning: <span style=\"font-weight: bold\">[</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">21:57:22</span><span style=\"font-weight: bold\">]</span> WARNING:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0e <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         d59c031377d09b8-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\\xgboost\\xgboost-ci-windows\\src\\learner.<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">cc:740</span>:       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Parameters: <span style=\"font-weight: bold\">{</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"scale_pos_weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"use_label_encoder\"</span> <span style=\"font-weight: bold\">}</span> are not used.  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>           <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">warnings.warn</span><span style=\"font-weight: bold\">(</span>smsg, UserWarning<span style=\"font-weight: bold\">)</span>                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[10/25/24 21:57:22]\u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m C:\\Program Files\\Python311\\Lib\\site-packages\\xgboost\\core.py:\u001b[1;36m158\u001b[0m:      \u001b[2mwarnings.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m110\u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         UserWarning: \u001b[1m[\u001b[0m\u001b[1;92m21:57:22\u001b[0m\u001b[1m]\u001b[0m WARNING:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0e \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         d59c031377d09b8-\u001b[1;36m1\u001b[0m\\xgboost\\xgboost-ci-windows\\src\\learner.\u001b[1;92mcc:740\u001b[0m:       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         Parameters: \u001b[1m{\u001b[0m \u001b[32m\"scale_pos_weight\"\u001b[0m, \u001b[32m\"use_label_encoder\"\u001b[0m \u001b[1m}\u001b[0m are not used.  \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m           \u001b[1;35mwarnings.warn\u001b[0m\u001b[1m(\u001b[0msmsg, UserWarning\u001b[1m)\u001b[0m                                     \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reporte de clasificación para VotingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.97      0.75      1350\n",
      "           1       0.17      0.02      0.03       413\n",
      "           2       0.00      0.00      0.00       205\n",
      "           3       0.00      0.00      0.00       118\n",
      "           4       0.00      0.00      0.00        85\n",
      "           5       0.00      0.00      0.00        71\n",
      "\n",
      "    accuracy                           0.59      2242\n",
      "   macro avg       0.13      0.17      0.13      2242\n",
      "weighted avg       0.40      0.59      0.45      2242\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, make_scorer, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Definir las columnas disponibles para el modelo\n",
    "columnas_necesarias = ['Género', 'Relación de ingresos familiares con la pobreza']\n",
    "\n",
    "# Selección de variables predictoras\n",
    "X = question6_imputed[columnas_necesarias]\n",
    "\n",
    "# Ajustar las clases en la variable objetivo para empezar desde 0\n",
    "y = question6_imputed['Riesgo_Depresion'] - question6_imputed['Riesgo_Depresion'].min()\n",
    "\n",
    "# División de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "# Calcular los pesos de clase\n",
    "clase_pesos = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "pesos = dict(enumerate(clase_pesos))\n",
    "\n",
    "# Definir modelos con ajuste de class_weight o scale_pos_weight\n",
    "modelos = {\n",
    "    \"RandomForest\": RandomForestClassifier(class_weight=pesos, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(scale_pos_weight=1, use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"VotingClassifier\": VotingClassifier(\n",
    "        estimators=[\n",
    "            ('rf', RandomForestClassifier(class_weight=pesos, random_state=42)),\n",
    "            ('xgb', XGBClassifier(scale_pos_weight=1, use_label_encoder=False, eval_metric='logloss', random_state=42)),\n",
    "            ('gb', GradientBoostingClassifier(random_state=42))\n",
    "        ], voting='soft'\n",
    "    )\n",
    "}\n",
    "\n",
    "# Configuración de GridSearchCV con F1-score macro\n",
    "f1_scorer = make_scorer(f1_score, average='macro')\n",
    "param_grid = {\n",
    "    \"RandomForest\": {'n_estimators': [50, 100], 'max_depth': [5, 10]},\n",
    "    \"XGBoost\": {'n_estimators': [50, 100], 'max_depth': [3, 5]},\n",
    "    \"GradientBoosting\": {'n_estimators': [50, 100], 'max_depth': [3, 5]},\n",
    "    \"VotingClassifier\": {}\n",
    "}\n",
    "\n",
    "# Iterar sobre los modelos\n",
    "for nombre, modelo in modelos.items():\n",
    "    print(f\"\\nEntrenando modelo: {nombre}...\")\n",
    "    if nombre in param_grid and param_grid[nombre]:  # Verificar si hay parámetros en el grid\n",
    "        grid_search = GridSearchCV(modelo, param_grid[nombre], cv=3, scoring=f1_scorer, n_jobs=-1, error_score='raise')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "    else:\n",
    "        best_model = modelo.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicciones\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Métricas de evaluación\n",
    "    print(f\"\\nReporte de clasificación para {nombre}:\")\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Models for Depression Risk\n",
    "\n",
    "#### Model: RandomForestClassifier\n",
    "- **Description**: This model used a random forest ensemble with class balancing to improve performance across imbalanced classes.\n",
    "- **Performance**:\n",
    "  - **Accuracy**: 34%\n",
    "  - **Macro Avg F1-Score**: 0.17\n",
    "  - **Weighted Avg F1-Score**: 0.38\n",
    "  - **Recall for Class 0**: 48%\n",
    "  - **Recall for Other Classes**: Ranged from 8% to 24%, showing limited sensitivity for classes 1 to 5.\n",
    "\n",
    "#### Model: XGBoostClassifier\n",
    "- **Description**: The XGBoost model was optimized for log loss with no significant improvements in class recall, except for class 0.\n",
    "- **Performance**:\n",
    "  - **Accuracy**: 60%\n",
    "  - **Macro Avg F1-Score**: 0.13\n",
    "  - **Weighted Avg F1-Score**: 0.45\n",
    "  - **Recall for Class 0**: 100%\n",
    "  - **Recall for Other Classes**: Near zero, indicating poor prediction capability for minority classes.\n",
    "\n",
    "#### Model: GradientBoostingClassifier\n",
    "- **Description**: The Gradient Boosting model aimed for improved generalization but struggled to balance predictions across classes.\n",
    "- **Performance**:\n",
    "  - **Accuracy**: 60%\n",
    "  - **Macro Avg F1-Score**: 0.13\n",
    "  - **Weighted Avg F1-Score**: 0.45\n",
    "  - **Recall for Class 0**: 99%\n",
    "  - **Recall for Other Classes**: Nearly zero, highlighting similar limitations as XGBoost.\n",
    "\n",
    "#### Model: VotingClassifier\n",
    "- **Description**: This ensemble combined predictions from RandomForest, XGBoost, and GradientBoosting, using a soft voting mechanism.\n",
    "- **Performance**:\n",
    "  - **Accuracy**: 59%\n",
    "  - **Macro Avg F1-Score**: 0.13\n",
    "  - **Weighted Avg F1-Score**: 0.45\n",
    "  - **Recall for Class 0**: 97%\n",
    "  - **Recall for Other Classes**: Marginal improvements for class 1 (2%), but still weak performance across other classes.\n",
    "\n",
    "\n",
    "All models showed strong recall for class 0 but struggled significantly with minority classes. The overall accuracy ranged from 34% to 60%, with XGBoost and GradientBoosting achieving the highest scores. The need for further tuning or resampling strategies, like SMOTE or class-specific weighting adjustments, is evident to enhance performance across imbalanced classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Question 7: How do waist circumference and body mass index affect blood pressure in different age groups?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Resultados para el grupo de edad 0-30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/120 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -104.92930292938422\n",
      "\n",
      "Generation 2 - Current best internal CV score: -104.8862786094005\n",
      "\n",
      "Generation 3 - Current best internal CV score: -104.8862786094005\n",
      "\n",
      "Generation 4 - Current best internal CV score: -104.70212769862265\n",
      "\n",
      "Generation 5 - Current best internal CV score: -104.69652636332614\n",
      "\n",
      "Best pipeline: RandomForestRegressor(ElasticNetCV(input_matrix, l1_ratio=0.75, tol=0.01), bootstrap=True, max_features=0.4, min_samples_leaf=18, min_samples_split=14, n_estimators=100)\n",
      "Métricas de regresión para grupo de edad 0-30:\n",
      "MAE: 7.744270416206562\n",
      "MSE: 100.31046709668436\n",
      "RMSE: 10.015511324774405\n",
      "R²: 0.19682258903345273\n",
      "Pipeline exportado para el grupo de edad 0-30\n",
      "\n",
      "\n",
      "--- Resultados para el grupo de edad 31-60 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/120 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -256.01558637946715\n",
      "\n",
      "Generation 2 - Current best internal CV score: -256.01558637946715\n",
      "\n",
      "Generation 3 - Current best internal CV score: -256.01558637946715\n",
      "\n",
      "Generation 4 - Current best internal CV score: -256.0023464006406\n",
      "\n",
      "Generation 5 - Current best internal CV score: -255.99494372861918\n",
      "\n",
      "Best pipeline: RidgeCV(FastICA(input_matrix, tol=0.25))\n",
      "Métricas de regresión para grupo de edad 31-60:\n",
      "MAE: 11.362548665050744\n",
      "MSE: 236.6329358073595\n",
      "RMSE: 15.382878007946351\n",
      "R²: 0.07302843789169489\n",
      "Pipeline exportado para el grupo de edad 31-60\n",
      "\n",
      "\n",
      "--- Resultados para el grupo de edad 60+ ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/120 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -403.1697067793719\n",
      "\n",
      "Generation 2 - Current best internal CV score: -402.83710088453194\n",
      "\n",
      "Generation 3 - Current best internal CV score: -402.718628663233\n",
      "\n",
      "Generation 4 - Current best internal CV score: -402.718628663233\n",
      "\n",
      "Generation 5 - Current best internal CV score: -401.70534969600186\n",
      "\n",
      "Best pipeline: XGBRegressor(StandardScaler(RidgeCV(input_matrix)), learning_rate=0.01, max_depth=8, min_child_weight=17, n_estimators=100, n_jobs=1, objective=reg:squarederror, subsample=0.3, verbosity=0)\n",
      "Métricas de regresión para grupo de edad 60+:\n",
      "MAE: 14.628753913318903\n",
      "MSE: 376.4969596120861\n",
      "RMSE: 19.403529565831214\n",
      "R²: 0.02798170470123429\n",
      "Pipeline exportado para el grupo de edad 60+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Relación entre la circunferencia de la cintura y la presión arterial\n",
    "# Filtrar y combinar datasets\n",
    "demografia_filtered = demografia[['ID', 'Edad en años al momento del examen']]\n",
    "medidasCorporales_filtered = medidas[['ID', 'Circunferencia de la cintura (cm)', 'Índice de masa corporal (kg/m²)']]\n",
    "presionArterial_filtered = presion[['ID', 'Presión sistólica - 1ra lectura oscilométrica', 'Presión diastólica - 1ra lectura oscilométrica']]\n",
    "\n",
    "# Realizar el merge\n",
    "question1 = demografia_filtered.merge(medidasCorporales_filtered, on='ID', how='inner')\n",
    "question1 = question1.merge(presionArterial_filtered, on='ID', how='inner')\n",
    "\n",
    "# Definir grupos de edad\n",
    "bins = [0, 30, 60, 90]  # Puedes ajustar los rangos de edad según lo necesites\n",
    "labels = ['0-30', '31-60', '60+']\n",
    "question1['Grupo de Edad'] = pd.cut(question1['Edad en años al momento del examen'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Iterar sobre cada grupo de edad\n",
    "for grupo in labels:\n",
    "    print(f\"\\n--- Resultados para el grupo de edad {grupo} ---\")\n",
    "    \n",
    "    # Filtrar el grupo de edad\n",
    "    grupo_df = question1[question1['Grupo de Edad'] == grupo]\n",
    "    \n",
    "    # Selección de variables predictoras y el target\n",
    "    X = grupo_df[['Edad en años al momento del examen', 'Circunferencia de la cintura (cm)', 'Índice de masa corporal (kg/m²)']]\n",
    "    y = grupo_df['Presión sistólica - 1ra lectura oscilométrica']\n",
    "    \n",
    "    # Imputación de valores faltantes\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_imputed = imputer.fit_transform(X)\n",
    "    y_imputed = imputer.fit_transform(y.values.reshape(-1, 1)).ravel()\n",
    "    \n",
    "    # División de datos\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_imputed, y_imputed, train_size=0.75, test_size=0.25, random_state=42)\n",
    "    \n",
    "    # TPOT para regresión\n",
    "    tpot_regressor = TPOTRegressor(verbosity=2, generations=5, population_size=20, random_state=42)\n",
    "    tpot_regressor.fit(X_train, y_train)\n",
    "    \n",
    "    # Realizar predicciones\n",
    "    y_pred = tpot_regressor.predict(X_test)\n",
    "    \n",
    "    # Calcular métricas\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Imprimir métricas\n",
    "    print(f\"Métricas de regresión para grupo de edad {grupo}:\")\n",
    "    print(f\"MAE: {mae}\")\n",
    "    print(f\"MSE: {mse}\")\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    print(f\"R²: {r2}\")\n",
    "    \n",
    "    # Exportar el pipeline\n",
    "    tpot_regressor.export(f'best_pipeline_presion_sistolica_{grupo}_regression.py')\n",
    "    print(f\"Pipeline exportado para el grupo de edad {grupo}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Models for Blood Pressure Prediction by Age Group\n",
    "\n",
    "### Age Group: 0-30\n",
    "#### Model: RandomForestRegressor\n",
    "**Description**: This model uses a Random Forest ensemble combined with ElasticNetCV for regularization. It employs a bootstrap method, adjusts feature usage to 40%, and uses 100 estimators to prevent overfitting.\n",
    "**Performance**:\n",
    "- **MAE**: 7.74\n",
    "- **MSE**: 100.31\n",
    "- **RMSE**: 10.02\n",
    "- **R²**: 0.20  \n",
    "*This model achieved the best performance in terms of R², indicating moderate predictive power for this age group.*\n",
    "\n",
    "### Age Group: 31-60\n",
    "#### Model: RidgeCV with FastICA\n",
    "**Description**: This model applies RidgeCV with FastICA as a preprocessing step, which helps in separating independent components before fitting the regression model.\n",
    "**Performance**:\n",
    "- **MAE**: 11.36\n",
    "- **MSE**: 236.63\n",
    "- **RMSE**: 15.38\n",
    "- **R²**: 0.07  \n",
    "*The R² score indicates limited predictive capacity, suggesting further adjustments might be needed.*\n",
    "\n",
    "### Age Group: 60+\n",
    "#### Model: XGBRegressor with StandardScaler and RidgeCV\n",
    "**Description**: This model combines XGBRegressor with StandardScaler and RidgeCV for scaling and regularization, using a learning rate of 0.01 and a max depth of 8 to manage complexity and reduce overfitting.\n",
    "**Performance**:\n",
    "- **MAE**: 14.63\n",
    "- **MSE**: 376.50\n",
    "- **RMSE**: 19.40\n",
    "- **R²**: 0.03  \n",
    "*The model shows poor predictive capacity for this age group, as reflected by the low R².*\n",
    "\n",
    "The **RandomForestRegressor** model for the 0-30 age group achieved the highest R² of 0.20, suggesting the most reliable predictions.\n",
    "Both the **RidgeCV with FastICA** for the 31-60 age group and the **XGBRegressor** for the 60+ age group had lower R² scores, indicating weaker predictive power.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Question 8:  How does the level of C-reactive protein influence glucose, triglyceride, and cholesterol levels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Resultados para el grupo de edad 0-30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -245.41371637466182\n",
      "\n",
      "Generation 2 - Current best internal CV score: -245.41371637466182\n",
      "\n",
      "Generation 3 - Current best internal CV score: -245.41371637466182\n",
      "\n",
      "Generation 4 - Current best internal CV score: -245.41371637466182\n",
      "\n",
      "Generation 5 - Current best internal CV score: -245.0074152032111\n",
      "\n",
      "Generation 6 - Current best internal CV score: -245.0074152032111\n",
      "\n",
      "Generation 7 - Current best internal CV score: -245.0074152032111\n",
      "\n",
      "Generation 8 - Current best internal CV score: -244.93434441057622\n",
      "\n",
      "Generation 9 - Current best internal CV score: -244.93434441057622\n",
      "\n",
      "Generation 10 - Current best internal CV score: -244.93434441057622\n",
      "\n",
      "Best pipeline: RandomForestRegressor(ElasticNetCV(input_matrix, l1_ratio=0.75, tol=0.01), bootstrap=True, max_features=0.4, min_samples_leaf=18, min_samples_split=14, n_estimators=100)\n",
      "Métricas de regresión para Glucosa, suero refrigerado (mg/dL):\n",
      "MAE: 7.110961586513223\n",
      "MSE: 139.76099921789196\n",
      "RMSE: 11.822055625731592\n",
      "R²: -0.030035473528416512\n",
      "Pipeline exportado para Glucosa, suero refrigerado (mg/dL)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -4694.011262952226\n",
      "\n",
      "Generation 2 - Current best internal CV score: -4694.011262952226\n",
      "\n",
      "Generation 3 - Current best internal CV score: -4682.144283601105\n",
      "\n",
      "Generation 4 - Current best internal CV score: -4681.467165526311\n",
      "\n",
      "Generation 5 - Current best internal CV score: -4677.423552464799\n",
      "\n",
      "Generation 6 - Current best internal CV score: -4677.423552464799\n",
      "\n",
      "Generation 7 - Current best internal CV score: -4666.815416341028\n",
      "\n",
      "Generation 8 - Current best internal CV score: -4666.815416341028\n",
      "\n",
      "Generation 9 - Current best internal CV score: -4664.753831303587\n",
      "\n",
      "Generation 10 - Current best internal CV score: -4664.753831303587\n",
      "\n",
      "Best pipeline: AdaBoostRegressor(RidgeCV(input_matrix), learning_rate=0.001, loss=linear, n_estimators=100)\n",
      "Métricas de regresión para Triglicéridos, suero refrigerado (mg/dL):\n",
      "MAE: 43.69596927351057\n",
      "MSE: 4693.669549293313\n",
      "RMSE: 68.51036089011146\n",
      "R²: 0.051113889644481714\n",
      "Pipeline exportado para Triglicéridos, suero refrigerado (mg/dL)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -1040.5453505948558\n",
      "\n",
      "Generation 2 - Current best internal CV score: -1040.5453505948558\n",
      "\n",
      "Generation 3 - Current best internal CV score: -1040.5453505948558\n",
      "\n",
      "Generation 4 - Current best internal CV score: -1040.5453505948558\n",
      "\n",
      "Generation 5 - Current best internal CV score: -1040.5453505948558\n",
      "\n",
      "Generation 6 - Current best internal CV score: -1040.5453505948558\n",
      "\n",
      "Generation 7 - Current best internal CV score: -1040.5453505948558\n",
      "\n",
      "Generation 8 - Current best internal CV score: -1040.069128707627\n",
      "\n",
      "Generation 9 - Current best internal CV score: -1040.069128707627\n",
      "\n",
      "Generation 10 - Current best internal CV score: -1037.723712242736\n",
      "\n",
      "Best pipeline: KNeighborsRegressor(input_matrix, n_neighbors=80, p=1, weights=uniform)\n",
      "Métricas de regresión para Colesterol Total, suero refrigerado (mg/dL):\n",
      "MAE: 23.68142235123367\n",
      "MSE: 1018.8330678519592\n",
      "RMSE: 31.919164585746277\n",
      "R²: 0.10982262851587543\n",
      "Pipeline exportado para Colesterol Total, suero refrigerado (mg/dL)\n",
      "\n",
      "\n",
      "--- Resultados para el grupo de edad 31-60 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -1462.407133805116\n",
      "\n",
      "Generation 2 - Current best internal CV score: -1462.407133805116\n",
      "\n",
      "Generation 3 - Current best internal CV score: -1462.407133805116\n",
      "\n",
      "Generation 4 - Current best internal CV score: -1460.2883491398939\n",
      "\n",
      "Generation 5 - Current best internal CV score: -1460.2883491398939\n",
      "\n",
      "Generation 6 - Current best internal CV score: -1460.2883491398939\n",
      "\n",
      "Generation 7 - Current best internal CV score: -1460.2883491398939\n",
      "\n",
      "Generation 8 - Current best internal CV score: -1460.2883491398939\n",
      "\n",
      "Generation 9 - Current best internal CV score: -1460.1021997872415\n",
      "\n",
      "Generation 10 - Current best internal CV score: -1460.1021997872415\n",
      "\n",
      "Best pipeline: RandomForestRegressor(StandardScaler(input_matrix), bootstrap=True, max_features=0.45, min_samples_leaf=17, min_samples_split=14, n_estimators=100)\n",
      "Métricas de regresión para Glucosa, suero refrigerado (mg/dL):\n",
      "MAE: 18.76802930587106\n",
      "MSE: 1429.2051538193236\n",
      "RMSE: 37.804829768421435\n",
      "R²: 0.051178145680514264\n",
      "Pipeline exportado para Glucosa, suero refrigerado (mg/dL)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -14440.560505565587\n",
      "\n",
      "Generation 2 - Current best internal CV score: -14403.746624823412\n",
      "\n",
      "Generation 3 - Current best internal CV score: -14403.746624823412\n",
      "\n",
      "Generation 4 - Current best internal CV score: -14396.100881060198\n",
      "\n",
      "Generation 5 - Current best internal CV score: -14396.100881060198\n",
      "\n",
      "Generation 6 - Current best internal CV score: -14396.100881060198\n",
      "\n",
      "Generation 7 - Current best internal CV score: -14396.100881060198\n",
      "\n",
      "Generation 8 - Current best internal CV score: -14393.790009760825\n",
      "\n",
      "Generation 9 - Current best internal CV score: -14393.790009760825\n",
      "\n",
      "Generation 10 - Current best internal CV score: -14311.1080200018\n",
      "\n",
      "Best pipeline: AdaBoostRegressor(PolynomialFeatures(input_matrix, degree=2, include_bias=False, interaction_only=False), learning_rate=0.001, loss=exponential, n_estimators=100)\n",
      "Métricas de regresión para Triglicéridos, suero refrigerado (mg/dL):\n",
      "MAE: 67.27778226648034\n",
      "MSE: 13755.35015283724\n",
      "RMSE: 117.283204905209\n",
      "R²: 0.042351080894264426\n",
      "Pipeline exportado para Triglicéridos, suero refrigerado (mg/dL)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -1440.192221486382\n",
      "\n",
      "Generation 2 - Current best internal CV score: -1437.644834655702\n",
      "\n",
      "Generation 3 - Current best internal CV score: -1437.1777842414456\n",
      "\n",
      "Generation 4 - Current best internal CV score: -1436.5174220908418\n",
      "\n",
      "Generation 5 - Current best internal CV score: -1429.6039452528425\n",
      "\n",
      "Generation 6 - Current best internal CV score: -1429.52333562428\n",
      "\n",
      "Generation 7 - Current best internal CV score: -1429.52333562428\n",
      "\n",
      "Generation 8 - Current best internal CV score: -1429.52333562428\n",
      "\n",
      "Generation 9 - Current best internal CV score: -1428.9549656778224\n",
      "\n",
      "Generation 10 - Current best internal CV score: -1428.9549656778224\n",
      "\n",
      "Best pipeline: ExtraTreesRegressor(input_matrix, bootstrap=True, max_features=0.8500000000000001, min_samples_leaf=9, min_samples_split=11, n_estimators=100)\n",
      "Métricas de regresión para Colesterol Total, suero refrigerado (mg/dL):\n",
      "MAE: 30.76404248474794\n",
      "MSE: 1639.4719534858023\n",
      "RMSE: 40.49039334812397\n",
      "R²: 0.02855918249720757\n",
      "Pipeline exportado para Colesterol Total, suero refrigerado (mg/dL)\n",
      "\n",
      "\n",
      "--- Resultados para el grupo de edad 60+ ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -1512.3671061439259\n",
      "\n",
      "Generation 2 - Current best internal CV score: -1505.6750567896804\n",
      "\n",
      "Generation 3 - Current best internal CV score: -1505.6750567896804\n",
      "\n",
      "Generation 4 - Current best internal CV score: -1504.1090663829334\n",
      "\n",
      "Generation 5 - Current best internal CV score: -1504.087754827337\n",
      "\n",
      "Generation 6 - Current best internal CV score: -1502.8992397213956\n",
      "\n",
      "Generation 7 - Current best internal CV score: -1502.3713473780697\n",
      "\n",
      "Generation 8 - Current best internal CV score: -1502.3713473780697\n",
      "\n",
      "Generation 9 - Current best internal CV score: -1502.3713473780697\n",
      "\n",
      "Generation 10 - Current best internal CV score: -1502.3615863187329\n",
      "\n",
      "Best pipeline: XGBRegressor(input_matrix, learning_rate=0.01, max_depth=2, min_child_weight=18, n_estimators=100, n_jobs=1, objective=reg:squarederror, subsample=0.25, verbosity=0)\n",
      "Métricas de regresión para Glucosa, suero refrigerado (mg/dL):\n",
      "MAE: 22.60079502100422\n",
      "MSE: 1599.8884399702831\n",
      "RMSE: 39.9986054753198\n",
      "R²: -0.002932301469151355\n",
      "Pipeline exportado para Glucosa, suero refrigerado (mg/dL)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -8095.361736496408\n",
      "\n",
      "Generation 2 - Current best internal CV score: -8094.566329199952\n",
      "\n",
      "Generation 3 - Current best internal CV score: -8094.566329199952\n",
      "\n",
      "Generation 4 - Current best internal CV score: -8087.9953669807655\n",
      "\n",
      "Generation 5 - Current best internal CV score: -8087.9953669807655\n",
      "\n",
      "Generation 6 - Current best internal CV score: -8067.532116393266\n",
      "\n",
      "Generation 7 - Current best internal CV score: -8067.532116393266\n",
      "\n",
      "Generation 8 - Current best internal CV score: -8067.532116393266\n",
      "\n",
      "Generation 9 - Current best internal CV score: -8067.532116393266\n",
      "\n",
      "Generation 10 - Current best internal CV score: -8067.532116393266\n",
      "\n",
      "Best pipeline: AdaBoostRegressor(input_matrix, learning_rate=0.001, loss=exponential, n_estimators=100)\n",
      "Métricas de regresión para Triglicéridos, suero refrigerado (mg/dL):\n",
      "MAE: 58.968198653673646\n",
      "MSE: 7715.1154560566365\n",
      "RMSE: 87.8357299511801\n",
      "R²: 0.01834087532790596\n",
      "Pipeline exportado para Triglicéridos, suero refrigerado (mg/dL)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -1782.3444974074275\n",
      "\n",
      "Generation 2 - Current best internal CV score: -1782.3353450048423\n",
      "\n",
      "Generation 3 - Current best internal CV score: -1782.3353450048423\n",
      "\n",
      "Generation 4 - Current best internal CV score: -1782.3353450048423\n",
      "\n",
      "Generation 5 - Current best internal CV score: -1782.331375004295\n",
      "\n",
      "Generation 6 - Current best internal CV score: -1782.268292295596\n",
      "\n",
      "Generation 7 - Current best internal CV score: -1782.268292295596\n",
      "\n",
      "Generation 8 - Current best internal CV score: -1782.1464465015931\n",
      "\n",
      "Generation 9 - Current best internal CV score: -1782.1464465015931\n",
      "\n",
      "Generation 10 - Current best internal CV score: -1782.1464465015931\n",
      "\n",
      "Best pipeline: ElasticNetCV(RobustScaler(input_matrix), l1_ratio=0.35000000000000003, tol=0.1)\n",
      "Métricas de regresión para Colesterol Total, suero refrigerado (mg/dL):\n",
      "MAE: 32.70013351277181\n",
      "MSE: 1700.9021301056716\n",
      "RMSE: 41.24199473965428\n",
      "R²: 0.08240064207699405\n",
      "Pipeline exportado para Colesterol Total, suero refrigerado (mg/dL)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filtrar las columnas necesarias\n",
    "demografia_filtered = demografia[['ID', 'Edad en años al momento del examen', 'Género']]\n",
    "proteinaC_filtered = proteinaC[['ID', 'Proteína C Reactiva (mg/L)']]\n",
    "perfilBioquimico_filtered = perfilB[['ID', 'Glucosa, suero refrigerado (mg/dL)', 'Triglicéridos, suero refrigerado (mg/dL)', 'Colesterol Total, suero refrigerado (mg/dL)']]\n",
    "\n",
    "# Unir los datasets\n",
    "question1 = demografia_filtered.merge(proteinaC_filtered, on='ID', how='inner')\n",
    "question1 = question1.merge(perfilBioquimico_filtered, on='ID', how='inner')\n",
    "\n",
    "# Definir grupos de edad\n",
    "bins = [0, 30, 60, 90]\n",
    "labels = ['0-30', '31-60', '60+']\n",
    "question1['Grupo de Edad'] = pd.cut(question1['Edad en años al momento del examen'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Iterar sobre cada grupo de edad\n",
    "for grupo in labels:\n",
    "    print(f\"\\n--- Resultados para el grupo de edad {grupo} ---\")\n",
    "    \n",
    "    grupo_df = question1[question1['Grupo de Edad'] == grupo]\n",
    "    \n",
    "    X = grupo_df[['Proteína C Reactiva (mg/L)', 'Edad en años al momento del examen', 'Género']]\n",
    "    y = grupo_df[['Glucosa, suero refrigerado (mg/dL)', 'Triglicéridos, suero refrigerado (mg/dL)', 'Colesterol Total, suero refrigerado (mg/dL)']]\n",
    "    \n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_imputed = imputer.fit_transform(X)\n",
    "    \n",
    "    targets = {\n",
    "        'Glucosa, suero refrigerado (mg/dL)': 'Glucosa_suero',\n",
    "        'Triglicéridos, suero refrigerado (mg/dL)': 'Trigliceridos_suero',\n",
    "        'Colesterol Total, suero refrigerado (mg/dL)': 'Colesterol_Total_suero'\n",
    "    }\n",
    "    \n",
    "    for target, file_name in targets.items():\n",
    "        y_target = y[target].dropna()\n",
    "        X_filtered = X_imputed[~y[target].isna()]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_filtered, y_target, train_size=0.75, test_size=0.25, random_state=42)\n",
    "        \n",
    "        tpot_regressor = TPOTRegressor(verbosity=2, generations=10, population_size=20, random_state=42)\n",
    "        tpot_regressor.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = tpot_regressor.predict(X_test)\n",
    "        \n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        print(f\"Métricas de regresión para {target}:\")\n",
    "        print(f\"MAE: {mae}\")\n",
    "        print(f\"MSE: {mse}\")\n",
    "        print(f\"RMSE: {rmse}\")\n",
    "        print(f\"R²: {r2}\")\n",
    "        \n",
    "        tpot_regressor.export(f'best_pipeline_{file_name}_{grupo}_regression.py')\n",
    "        print(f\"Pipeline exportado para {target}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Regression Models for Electrolyte Impact on Glucose, Triglycerides, and Total Cholesterol Levels\n",
    "\n",
    "#### Age Group: 0-30\n",
    "**Model for Serum Glucose (mg/dL):**\n",
    "- **Model**: RandomForestRegressor with ElasticNetCV pre-processing\n",
    "- **Performance**:\n",
    "  - **MAE**: 7.11\n",
    "  - **MSE**: 139.76\n",
    "  - **RMSE**: 11.82\n",
    "  - **R²**: -0.03\n",
    "- **Pipeline Exported**: best_pipeline_Glucosa_0-30_regression.py\n",
    "\n",
    "**Model for Serum Triglycerides (mg/dL):**\n",
    "- **Model**: AdaBoostRegressor with RidgeCV pre-processing\n",
    "- **Performance**:\n",
    "  - **MAE**: 43.70\n",
    "  - **MSE**: 4693.67\n",
    "  - **RMSE**: 68.51\n",
    "  - **R²**: 0.05\n",
    "- **Pipeline Exported**: best_pipeline_Trigliceridos_0-30_regression.py\n",
    "\n",
    "**Model for Total Cholesterol (mg/dL):**\n",
    "- **Model**: KNeighborsRegressor\n",
    "- **Performance**:\n",
    "  - **MAE**: 23.68\n",
    "  - **MSE**: 1018.83\n",
    "  - **RMSE**: 31.92\n",
    "  - **R²**: 0.11\n",
    "- **Pipeline Exported**: best_pipeline_Colesterol_Total_0-30_regression.py\n",
    "\n",
    "#### Age Group: 31-60\n",
    "**Model for Serum Glucose (mg/dL):**\n",
    "- **Model**: RandomForestRegressor with StandardScaler pre-processing\n",
    "- **Performance**:\n",
    "  - **MAE**: 18.77\n",
    "  - **MSE**: 1429.21\n",
    "  - **RMSE**: 37.80\n",
    "  - **R²**: 0.05\n",
    "- **Pipeline Exported**: best_pipeline_Glucosa_31-60_regression.py\n",
    "\n",
    "**Model for Serum Triglycerides (mg/dL):**\n",
    "- **Model**: AdaBoostRegressor with PolynomialFeatures pre-processing\n",
    "- **Performance**:\n",
    "  - **MAE**: 67.28\n",
    "  - **MSE**: 13755.35\n",
    "  - **RMSE**: 117.28\n",
    "  - **R²**: 0.04\n",
    "- **Pipeline Exported**: best_pipeline_Trigliceridos_31-60_regression.py\n",
    "\n",
    "**Model for Total Cholesterol (mg/dL):**\n",
    "- **Model**: ExtraTreesRegressor\n",
    "- **Performance**:\n",
    "  - **MAE**: 30.76\n",
    "  - **MSE**: 1639.47\n",
    "  - **RMSE**: 40.49\n",
    "  - **R²**: 0.03\n",
    "- **Pipeline Exported**: best_pipeline_Colesterol_Total_31-60_regression.py\n",
    "\n",
    "#### Age Group: 60+\n",
    "**Model for Serum Glucose (mg/dL):**\n",
    "- **Model**: XGBRegressor\n",
    "- **Performance**:\n",
    "  - **MAE**: 22.60\n",
    "  - **MSE**: 1599.89\n",
    "  - **RMSE**: 40.00\n",
    "  - **R²**: -0.003\n",
    "- **Pipeline Exported**: best_pipeline_Glucosa_60+_regression.py\n",
    "\n",
    "**Model for Serum Triglycerides (mg/dL):**\n",
    "- **Model**: AdaBoostRegressor\n",
    "- **Performance**:\n",
    "  - **MAE**: 58.97\n",
    "  - **MSE**: 7715.12\n",
    "  - **RMSE**: 87.84\n",
    "  - **R²**: 0.02\n",
    "- **Pipeline Exported**: best_pipeline_Trigliceridos_60+_regression.py\n",
    "\n",
    "**Model for Total Cholesterol (mg/dL):**\n",
    "- **Model**: ElasticNetCV with RobustScaler pre-processing\n",
    "- **Performance**:\n",
    "  - **MAE**: 32.70\n",
    "  - **MSE**: 1700.90\n",
    "  - **RMSE**: 41.24\n",
    "  - **R²**: 0.08\n",
    "- **Pipeline Exported**: best_pipeline_Colesterol_Total_60+_regression.py\n",
    "\n",
    "\n",
    "The models demonstrated varied performance across age groups, with most models showing modest predictive accuracy (R² ranging from -0.03 to 0.11). The pipelines exported highlight different pre-processing and model strategies, including ensemble techniques, boosting, and regression methods. Despite the low R² values, the models provide initial insights into the relationship between electrolyte levels and the target metabolic indicators. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Question 9: What is the impact of electrolyte levels (sodium, potassium, phosphorus) on kidney function, assessed through creatinine levels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Resultados para el grupo de edad 0-30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -0.03119756712112142\n",
      "\n",
      "Generation 2 - Current best internal CV score: -0.031190767956919507\n",
      "\n",
      "Generation 3 - Current best internal CV score: -0.031190767956919507\n",
      "\n",
      "Generation 4 - Current best internal CV score: -0.031190767956919507\n",
      "\n",
      "Generation 5 - Current best internal CV score: -0.031183442984804875\n",
      "\n",
      "Generation 6 - Current best internal CV score: -0.031183442984804875\n",
      "\n",
      "Generation 7 - Current best internal CV score: -0.031183442984804875\n",
      "\n",
      "Generation 8 - Current best internal CV score: -0.031183442984804875\n",
      "\n",
      "Generation 9 - Current best internal CV score: -0.031183442984804875\n",
      "\n",
      "Generation 10 - Current best internal CV score: -0.031180202459760404\n",
      "\n",
      "Best pipeline: AdaBoostRegressor(ZeroCount(MinMaxScaler(input_matrix)), learning_rate=0.01, loss=linear, n_estimators=100)\n",
      "Métricas de regresión para Creatinina, suero refrigerado (mg/dL):\n",
      "MAE: 0.14024028439053923\n",
      "MSE: 0.03122952687203027\n",
      "RMSE: 0.17671877905879238\n",
      "R²: 0.0539475524280324\n",
      "Pipeline exportado para Creatinina, suero refrigerado (mg/dL)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -12.052882216933373\n",
      "\n",
      "Generation 2 - Current best internal CV score: -12.052882216933373\n",
      "\n",
      "Generation 3 - Current best internal CV score: -12.052882216933373\n",
      "\n",
      "Generation 4 - Current best internal CV score: -12.052009250308767\n",
      "\n",
      "Generation 5 - Current best internal CV score: -12.044765319773818\n",
      "\n",
      "Generation 6 - Current best internal CV score: -12.044765319773818\n",
      "\n",
      "Generation 7 - Current best internal CV score: -12.044765319773816\n",
      "\n",
      "Generation 8 - Current best internal CV score: -12.044765319773816\n",
      "\n",
      "Generation 9 - Current best internal CV score: -12.035880621444127\n",
      "\n",
      "Generation 10 - Current best internal CV score: -12.035880621444127\n",
      "\n",
      "Best pipeline: ElasticNetCV(Normalizer(input_matrix, norm=l1), l1_ratio=0.65, tol=0.0001)\n",
      "Métricas de regresión para Nitrógeno Ureico en Sangre (mg/dL):\n",
      "MAE: 2.606143498564616\n",
      "MSE: 10.65791896529519\n",
      "RMSE: 3.2646468362282604\n",
      "R²: 0.015500482930625004\n",
      "Pipeline exportado para Nitrógeno Ureico en Sangre (mg/dL)\n",
      "\n",
      "\n",
      "--- Resultados para el grupo de edad 31-60 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -0.24735701726104747\n",
      "\n",
      "Generation 2 - Current best internal CV score: -0.2397853646910147\n",
      "\n",
      "Generation 3 - Current best internal CV score: -0.23374331739555637\n",
      "\n",
      "Generation 4 - Current best internal CV score: -0.23374331739555637\n",
      "\n",
      "Generation 5 - Current best internal CV score: -0.23374331739555637\n",
      "\n",
      "Generation 6 - Current best internal CV score: -0.23374331739555637\n",
      "\n",
      "Generation 7 - Current best internal CV score: -0.23374331739555637\n",
      "\n",
      "Generation 8 - Current best internal CV score: -0.22602408209437114\n",
      "\n",
      "Generation 9 - Current best internal CV score: -0.22598654618958047\n",
      "\n",
      "Generation 10 - Current best internal CV score: -0.2240087203049387\n",
      "\n",
      "Best pipeline: DecisionTreeRegressor(RidgeCV(RidgeCV(StandardScaler(input_matrix))), max_depth=4, min_samples_leaf=3, min_samples_split=4)\n",
      "Métricas de regresión para Creatinina, suero refrigerado (mg/dL):\n",
      "MAE: 0.1845236507692911\n",
      "MSE: 0.19255338713463083\n",
      "RMSE: 0.4388090554382747\n",
      "R²: -0.13179294125132723\n",
      "Pipeline exportado para Creatinina, suero refrigerado (mg/dL)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -22.243188752373516\n",
      "\n",
      "Generation 2 - Current best internal CV score: -22.243188752373516\n",
      "\n",
      "Generation 3 - Current best internal CV score: -22.243188752373516\n",
      "\n",
      "Generation 4 - Current best internal CV score: -22.243188752373516\n",
      "\n",
      "Generation 5 - Current best internal CV score: -22.243188752373516\n",
      "\n",
      "Generation 6 - Current best internal CV score: -22.243188752373516\n",
      "\n",
      "Generation 7 - Current best internal CV score: -22.243188752373516\n",
      "\n",
      "Generation 8 - Current best internal CV score: -22.243188752373516\n",
      "\n",
      "Generation 9 - Current best internal CV score: -22.243188752373516\n",
      "\n",
      "Generation 10 - Current best internal CV score: -22.243188752373516\n",
      "\n",
      "Best pipeline: DecisionTreeRegressor(FastICA(input_matrix, tol=0.45), max_depth=3, min_samples_leaf=8, min_samples_split=11)\n",
      "Métricas de regresión para Nitrógeno Ureico en Sangre (mg/dL):\n",
      "MAE: 3.302357509700059\n",
      "MSE: 22.954607958266934\n",
      "RMSE: 4.791096738562783\n",
      "R²: 0.1485536641112447\n",
      "Pipeline exportado para Nitrógeno Ureico en Sangre (mg/dL)\n",
      "\n",
      "\n",
      "--- Resultados para el grupo de edad 60+ ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -0.32982234352225037\n",
      "\n",
      "Generation 2 - Current best internal CV score: -0.32982234352225037\n",
      "\n",
      "Generation 3 - Current best internal CV score: -0.32982234352225037\n",
      "\n",
      "Generation 4 - Current best internal CV score: -0.32982234352225037\n",
      "\n",
      "Generation 5 - Current best internal CV score: -0.323419672789443\n",
      "\n",
      "Generation 6 - Current best internal CV score: -0.30134140942929155\n",
      "\n",
      "Generation 7 - Current best internal CV score: -0.30134140942929155\n",
      "\n",
      "Generation 8 - Current best internal CV score: -0.30134140942929155\n",
      "\n",
      "Generation 9 - Current best internal CV score: -0.3002879144667518\n",
      "\n",
      "Generation 10 - Current best internal CV score: -0.2859933443193122\n",
      "\n",
      "Best pipeline: DecisionTreeRegressor(MinMaxScaler(FastICA(input_matrix, tol=0.45)), max_depth=4, min_samples_leaf=3, min_samples_split=12)\n",
      "Métricas de regresión para Creatinina, suero refrigerado (mg/dL):\n",
      "MAE: 0.2821608136805942\n",
      "MSE: 0.3692689540060878\n",
      "RMSE: 0.6076750398083566\n",
      "R²: -0.02418167823721684\n",
      "Pipeline exportado para Creatinina, suero refrigerado (mg/dL)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -48.172148240781745\n",
      "\n",
      "Generation 2 - Current best internal CV score: -48.132931984106015\n",
      "\n",
      "Generation 3 - Current best internal CV score: -48.132931984106015\n",
      "\n",
      "Generation 4 - Current best internal CV score: -48.07517736716332\n",
      "\n",
      "Generation 5 - Current best internal CV score: -48.07517736716332\n",
      "\n",
      "Generation 6 - Current best internal CV score: -48.01771691978067\n",
      "\n",
      "Generation 7 - Current best internal CV score: -48.01771691978067\n",
      "\n",
      "Generation 8 - Current best internal CV score: -48.01771691978067\n",
      "\n",
      "Generation 9 - Current best internal CV score: -48.01771691978067\n",
      "\n",
      "Generation 10 - Current best internal CV score: -48.01771691978057\n",
      "\n",
      "Best pipeline: RidgeCV(SelectPercentile(StandardScaler(MinMaxScaler(input_matrix)), percentile=59))\n",
      "Métricas de regresión para Nitrógeno Ureico en Sangre (mg/dL):\n",
      "MAE: 4.696939197475276\n",
      "MSE: 40.81007037373741\n",
      "RMSE: 6.388276009514414\n",
      "R²: 0.06368170849891297\n",
      "Pipeline exportado para Nitrógeno Ureico en Sangre (mg/dL)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ¿Cuál es el impacto de los niveles de electrolitos (sodio, potasio, fósforo) en la función renal, evaluada a través de la creatinina?\n",
    "\n",
    "# Filtrar las columnas necesarias, asegurando que la columna de edad esté incluida\n",
    "demografia_filtered = demografia[['ID', 'Edad en años al momento del examen']]\n",
    "perfilBioquimico_filtered = perfilB[['ID', 'Creatinina, suero refrigerado (mg/dL)', 'Nitrógeno Ureico en Sangre (mg/dL)', 'Sodio (mmol/L)', 'Potasio (mmol/L)', 'Fósforo (mg/dL)']]\n",
    "\n",
    "# Unir los datasets para tener la columna de edad disponible\n",
    "merged_df = perfilBioquimico_filtered.merge(demografia_filtered, on='ID', how='inner')\n",
    "\n",
    "# Definir grupos de edad\n",
    "bins = [0, 30, 60, 90]\n",
    "labels = ['0-30', '31-60', '60+']\n",
    "merged_df['Grupo de Edad'] = pd.cut(merged_df['Edad en años al momento del examen'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Iterar sobre cada grupo de edad\n",
    "for grupo in labels:\n",
    "    print(f\"\\n--- Resultados para el grupo de edad {grupo} ---\")\n",
    "    \n",
    "    grupo_df = merged_df[merged_df['Grupo de Edad'] == grupo]\n",
    "    \n",
    "    X = grupo_df[['Sodio (mmol/L)', 'Potasio (mmol/L)', 'Fósforo (mg/dL)']]\n",
    "    y = grupo_df[['Creatinina, suero refrigerado (mg/dL)', 'Nitrógeno Ureico en Sangre (mg/dL)']]\n",
    "    \n",
    "    # Imputación de valores faltantes en X\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_imputed = imputer.fit_transform(X)\n",
    "    \n",
    "    targets = {\n",
    "        'Creatinina, suero refrigerado (mg/dL)': 'Creatinina',\n",
    "        'Nitrógeno Ureico en Sangre (mg/dL)': 'Nitrogeno_Urico'\n",
    "    }\n",
    "    \n",
    "    for target, file_name in targets.items():\n",
    "        y_target = y[target].dropna()\n",
    "        X_filtered = X_imputed[~y[target].isna()]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_filtered, y_target, train_size=0.75, test_size=0.25, random_state=42)\n",
    "        \n",
    "        tpot_regressor = TPOTRegressor(verbosity=2, generations=10, population_size=20, random_state=42)\n",
    "        tpot_regressor.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = tpot_regressor.predict(X_test)\n",
    "        \n",
    "        # Calcular métricas\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Imprimir métricas para cada target\n",
    "        print(f\"Métricas de regresión para {target}:\")\n",
    "        print(f\"MAE: {mae}\")\n",
    "        print(f\"MSE: {mse}\")\n",
    "        print(f\"RMSE: {rmse}\")\n",
    "        print(f\"R²: {r2}\")\n",
    "        \n",
    "        # Exportar el pipeline\n",
    "        tpot_regressor.export(f'best_pipeline_{file_name}_{grupo}_regression.py')\n",
    "        print(f\"Pipeline exportado para {target}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age Group: 0-30\n",
    "**Model for Creatinine (mg/dL):**\n",
    "- **Model**: `AdaBoostRegressor` with `MinMaxScaler` pre-processing\n",
    "- **Performance**:\n",
    "  - **MAE**: 0.14\n",
    "  - **MSE**: 0.03\n",
    "  - **RMSE**: 0.18\n",
    "  - **R²**: 0.05\n",
    "- **Pipeline Exported**: `best_pipeline_Creatinina_0-30_regression.py`\n",
    "\n",
    "**Model for Blood Urea Nitrogen (mg/dL):**\n",
    "- **Model**: `ElasticNetCV` with `Normalizer` pre-processing\n",
    "- **Performance**:\n",
    "  - **MAE**: 2.61\n",
    "  - **MSE**: 10.66\n",
    "  - **RMSE**: 3.26\n",
    "  - **R²**: 0.02\n",
    "- **Pipeline Exported**: `best_pipeline_Nitrogeno_Urico_0-30_regression.py`\n",
    "\n",
    "#### Age Group: 31-60\n",
    "**Model for Creatinine (mg/dL):**\n",
    "- **Model**: `DecisionTreeRegressor` with `RidgeCV` pre-processing\n",
    "- **Performance**:\n",
    "  - **MAE**: 0.18\n",
    "  - **MSE**: 0.19\n",
    "  - **RMSE**: 0.44\n",
    "  - **R²**: -0.13\n",
    "- **Pipeline Exported**: `best_pipeline_Creatinina_31-60_regression.py`\n",
    "\n",
    "**Model for Blood Urea Nitrogen (mg/dL):**\n",
    "- **Model**: `DecisionTreeRegressor` with `FastICA` pre-processing\n",
    "- **Performance**:\n",
    "  - **MAE**: 3.30\n",
    "  - **MSE**: 22.95\n",
    "  - **RMSE**: 4.79\n",
    "  - **R²**: 0.15\n",
    "- **Pipeline Exported**: `best_pipeline_Nitrogeno_Urico_31-60_regression.py`\n",
    "\n",
    "#### Age Group: 60+\n",
    "**Model for Creatinine (mg/dL):**\n",
    "- **Model**: `DecisionTreeRegressor` with `FastICA` and `MinMaxScaler` pre-processing\n",
    "- **Performance**:\n",
    "  - **MAE**: 0.28\n",
    "  - **MSE**: 0.37\n",
    "  - **RMSE**: 0.61\n",
    "  - **R²**: -0.02\n",
    "- **Pipeline Exported**: `best_pipeline_Creatinina_60+_regression.py`\n",
    "\n",
    "**Model for Blood Urea Nitrogen (mg/dL):**\n",
    "- **Model**: `RidgeCV` with `SelectPercentile` pre-processing\n",
    "- **Performance**:\n",
    "  - **MAE**: 4.70\n",
    "  - **MSE**: 40.81\n",
    "  - **RMSE**: 6.39\n",
    "  - **R²**: 0.06\n",
    "- **Pipeline Exported**: `best_pipeline_Nitrogeno_Urico_60+_regression.py`\n",
    "\n",
    "\n",
    "The models for different age groups displayed varied predictive performance, with R² values ranging from -0.13 to 0.15. The most frequently selected models were AdaBoostRegressor and DecisionTreeRegressor, highlighting moderate accuracy across groups. Enhancements like feature engineering or advanced ensemble techniques could improve the predictive accuracy of these models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10: How do age and physical activity level affect waist circumference, BMI, and weight?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Resultados para el grupo de edad 0-20 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -153.87566513615621\n",
      "\n",
      "Generation 2 - Current best internal CV score: -153.87566513615621\n",
      "\n",
      "Generation 3 - Current best internal CV score: -153.87566513615621\n",
      "\n",
      "Generation 4 - Current best internal CV score: -153.56517992614067\n",
      "\n",
      "Generation 5 - Current best internal CV score: -153.56517992614067\n",
      "\n",
      "Generation 6 - Current best internal CV score: -153.56517992614067\n",
      "\n",
      "Generation 7 - Current best internal CV score: -153.5410550982358\n",
      "\n",
      "Generation 8 - Current best internal CV score: -153.5410550982358\n",
      "\n",
      "Generation 9 - Current best internal CV score: -153.5410550982358\n",
      "\n",
      "Generation 10 - Current best internal CV score: -153.5410550982358\n",
      "\n",
      "Best pipeline: XGBRegressor(input_matrix, learning_rate=0.1, max_depth=1, min_child_weight=7, n_estimators=100, n_jobs=1, objective=reg:squarederror, subsample=0.5, verbosity=0)\n",
      "Métricas de regresión para Circunferencia de la cintura (cm):\n",
      "MAE: 9.30681706926464\n",
      "MSE: 163.2020901187588\n",
      "RMSE: 12.775057343071255\n",
      "R²: 0.5203772024359741\n",
      "Pipeline exportado para Circunferencia de la cintura (cm)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -25.436069325301624\n",
      "\n",
      "Generation 2 - Current best internal CV score: -25.432992649014356\n",
      "\n",
      "Generation 3 - Current best internal CV score: -25.432992649014356\n",
      "\n",
      "Generation 4 - Current best internal CV score: -25.390752634103\n",
      "\n",
      "Generation 5 - Current best internal CV score: -25.390752634103\n",
      "\n",
      "Generation 6 - Current best internal CV score: -25.390752634103\n",
      "\n",
      "Generation 7 - Current best internal CV score: -25.390752634103\n",
      "\n",
      "Generation 8 - Current best internal CV score: -25.38078158147896\n",
      "\n",
      "Generation 9 - Current best internal CV score: -25.337123030751375\n",
      "\n",
      "Generation 10 - Current best internal CV score: -25.337123030751375\n",
      "\n",
      "Best pipeline: KNeighborsRegressor(MaxAbsScaler(input_matrix), n_neighbors=91, p=2, weights=uniform)\n",
      "Métricas de regresión para Índice de masa corporal (kg/m²):\n",
      "MAE: 3.6282276176304777\n",
      "MSE: 25.965167641349495\n",
      "RMSE: 5.095602775074751\n",
      "R²: 0.3294917222919175\n",
      "Pipeline exportado para Índice de masa corporal (kg/m²)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -169.29240015105006\n",
      "\n",
      "Generation 2 - Current best internal CV score: -169.29240015105006\n",
      "\n",
      "Generation 3 - Current best internal CV score: -169.29240015105006\n",
      "\n",
      "Generation 4 - Current best internal CV score: -169.29240015105006\n",
      "\n",
      "Generation 5 - Current best internal CV score: -169.29240015105006\n",
      "\n",
      "Generation 6 - Current best internal CV score: -169.29240015105006\n",
      "\n",
      "Generation 7 - Current best internal CV score: -169.03686457620398\n",
      "\n",
      "Generation 8 - Current best internal CV score: -168.9028785657208\n",
      "\n",
      "Generation 9 - Current best internal CV score: -168.9028785657208\n",
      "\n",
      "Generation 10 - Current best internal CV score: -168.8247431680491\n",
      "\n",
      "Best pipeline: KNeighborsRegressor(input_matrix, n_neighbors=95, p=2, weights=uniform)\n",
      "Métricas de regresión para Peso (kg):\n",
      "MAE: 8.230064166759393\n",
      "MSE: 178.35309987018283\n",
      "RMSE: 13.354890485143741\n",
      "R²: 0.7651774234259762\n",
      "Pipeline exportado para Peso (kg)\n",
      "\n",
      "\n",
      "--- Resultados para el grupo de edad 21-30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -327.04433340380916\n",
      "\n",
      "Generation 2 - Current best internal CV score: -327.01805151406404\n",
      "\n",
      "Generation 3 - Current best internal CV score: -327.01805151406404\n",
      "\n",
      "Generation 4 - Current best internal CV score: -327.01559711288536\n",
      "\n",
      "Generation 5 - Current best internal CV score: -327.01559711288536\n",
      "\n",
      "Generation 6 - Current best internal CV score: -327.01559711288536\n",
      "\n",
      "Generation 7 - Current best internal CV score: -327.01559711288536\n",
      "\n",
      "Generation 8 - Current best internal CV score: -327.01468648387464\n",
      "\n",
      "Generation 9 - Current best internal CV score: -327.01468648387464\n",
      "\n",
      "Generation 10 - Current best internal CV score: -327.0146864838746\n",
      "\n",
      "Best pipeline: ElasticNetCV(RidgeCV(RidgeCV(ZeroCount(input_matrix))), l1_ratio=0.9500000000000001, tol=0.1)\n",
      "Métricas de regresión para Circunferencia de la cintura (cm):\n",
      "MAE: 14.757910209244596\n",
      "MSE: 338.58837713263273\n",
      "RMSE: 18.40077110157704\n",
      "R²: 0.03187879512231562\n",
      "Pipeline exportado para Circunferencia de la cintura (cm)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -67.30144012992093\n",
      "\n",
      "Generation 2 - Current best internal CV score: -67.30144012992093\n",
      "\n",
      "Generation 3 - Current best internal CV score: -67.30005514768736\n",
      "\n",
      "Generation 4 - Current best internal CV score: -67.30005514768736\n",
      "\n",
      "Generation 5 - Current best internal CV score: -67.29581026883857\n",
      "\n",
      "Generation 6 - Current best internal CV score: -67.29581026883857\n",
      "\n",
      "Generation 7 - Current best internal CV score: -67.29581026883857\n",
      "\n",
      "Generation 8 - Current best internal CV score: -67.29581026883857\n",
      "\n",
      "Generation 9 - Current best internal CV score: -67.29581026883857\n",
      "\n",
      "Generation 10 - Current best internal CV score: -67.29581026883857\n",
      "\n",
      "Best pipeline: ElasticNetCV(input_matrix, l1_ratio=0.05, tol=0.001)\n",
      "Métricas de regresión para Índice de masa corporal (kg/m²):\n",
      "MAE: 6.293224979503638\n",
      "MSE: 63.31939691895922\n",
      "RMSE: 7.957348611124137\n",
      "R²: 0.0063004355405658075\n",
      "Pipeline exportado para Índice de masa corporal (kg/m²)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -576.8422138146894\n",
      "\n",
      "Generation 2 - Current best internal CV score: -576.8422138146894\n",
      "\n",
      "Generation 3 - Current best internal CV score: -576.8422138146894\n",
      "\n",
      "Generation 4 - Current best internal CV score: -576.6163630897354\n",
      "\n",
      "Generation 5 - Current best internal CV score: -576.6163630897354\n",
      "\n",
      "Generation 6 - Current best internal CV score: -576.6163630897354\n",
      "\n",
      "Generation 7 - Current best internal CV score: -576.6163630897354\n",
      "\n",
      "Generation 8 - Current best internal CV score: -576.6163630897354\n",
      "\n",
      "Generation 9 - Current best internal CV score: -576.6163630897354\n",
      "\n",
      "Generation 10 - Current best internal CV score: -576.6163630897354\n",
      "\n",
      "Best pipeline: XGBRegressor(input_matrix, learning_rate=0.1, max_depth=1, min_child_weight=10, n_estimators=100, n_jobs=1, objective=reg:squarederror, subsample=0.1, verbosity=0)\n",
      "Métricas de regresión para Peso (kg):\n",
      "MAE: 19.555549761592694\n",
      "MSE: 631.2694753594782\n",
      "RMSE: 25.125076623952378\n",
      "R²: 0.029405863469775917\n",
      "Pipeline exportado para Peso (kg)\n",
      "\n",
      "\n",
      "--- Resultados para el grupo de edad 31-60 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -301.5728322107084\n",
      "\n",
      "Generation 2 - Current best internal CV score: -301.3421667861614\n",
      "\n",
      "Generation 3 - Current best internal CV score: -301.3421667861614\n",
      "\n",
      "Generation 4 - Current best internal CV score: -301.3421667861614\n",
      "\n",
      "Generation 5 - Current best internal CV score: -301.3421667861614\n",
      "\n",
      "Generation 6 - Current best internal CV score: -301.3421667861614\n",
      "\n",
      "Generation 7 - Current best internal CV score: -301.3421667861614\n",
      "\n",
      "Generation 8 - Current best internal CV score: -301.3421667861614\n",
      "\n",
      "Generation 9 - Current best internal CV score: -301.3421667861614\n",
      "\n",
      "Generation 10 - Current best internal CV score: -301.3421667861614\n",
      "\n",
      "Best pipeline: DecisionTreeRegressor(input_matrix, max_depth=1, min_samples_leaf=3, min_samples_split=4)\n",
      "Métricas de regresión para Circunferencia de la cintura (cm):\n",
      "MAE: 13.094531404344506\n",
      "MSE: 282.75933630890586\n",
      "RMSE: 16.81544933413633\n",
      "R²: 0.007703257756155546\n",
      "Pipeline exportado para Circunferencia de la cintura (cm)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -59.0898886566633\n",
      "\n",
      "Generation 2 - Current best internal CV score: -59.0898886566633\n",
      "\n",
      "Generation 3 - Current best internal CV score: -59.0898886566633\n",
      "\n",
      "Generation 4 - Current best internal CV score: -59.082909282011386\n",
      "\n",
      "Generation 5 - Current best internal CV score: -59.08255603940502\n",
      "\n",
      "Generation 6 - Current best internal CV score: -59.08255603940502\n",
      "\n",
      "Generation 7 - Current best internal CV score: -59.08255603940502\n",
      "\n",
      "Generation 8 - Current best internal CV score: -59.08255603940502\n",
      "\n",
      "Generation 9 - Current best internal CV score: -59.08255603940502\n",
      "\n",
      "Generation 10 - Current best internal CV score: -59.08255603940502\n",
      "\n",
      "Best pipeline: ElasticNetCV(RidgeCV(input_matrix), l1_ratio=0.8500000000000001, tol=1e-05)\n",
      "Métricas de regresión para Índice de masa corporal (kg/m²):\n",
      "MAE: 5.895876995597573\n",
      "MSE: 62.25663621307986\n",
      "RMSE: 7.890287460738034\n",
      "R²: 0.008374376600849942\n",
      "Pipeline exportado para Índice de masa corporal (kg/m²)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -521.4672503948844\n",
      "\n",
      "Generation 2 - Current best internal CV score: -521.4672503948844\n",
      "\n",
      "Generation 3 - Current best internal CV score: -521.4672503948844\n",
      "\n",
      "Generation 4 - Current best internal CV score: -521.4672503948844\n",
      "\n",
      "Generation 5 - Current best internal CV score: -521.4672503948844\n",
      "\n",
      "Generation 6 - Current best internal CV score: -521.4672503948844\n",
      "\n",
      "Generation 7 - Current best internal CV score: -521.4672503948844\n",
      "\n",
      "Generation 8 - Current best internal CV score: -521.4672503948844\n",
      "\n",
      "Generation 9 - Current best internal CV score: -521.4672503948844\n",
      "\n",
      "Generation 10 - Current best internal CV score: -521.4672503948844\n",
      "\n",
      "Best pipeline: RidgeCV(MaxAbsScaler(input_matrix))\n",
      "Métricas de regresión para Peso (kg):\n",
      "MAE: 19.022464171885275\n",
      "MSE: 609.4717999886715\n",
      "RMSE: 24.68748265799232\n",
      "R²: 0.0541095480995879\n",
      "Pipeline exportado para Peso (kg)\n",
      "\n",
      "\n",
      "--- Resultados para el grupo de edad 60-80 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -229.73731874608347\n",
      "\n",
      "Generation 2 - Current best internal CV score: -229.73731874608347\n",
      "\n",
      "Generation 3 - Current best internal CV score: -229.73731874608347\n",
      "\n",
      "Generation 4 - Current best internal CV score: -229.55004824095258\n",
      "\n",
      "Generation 5 - Current best internal CV score: -229.55004824095258\n",
      "\n",
      "Generation 6 - Current best internal CV score: -229.53492904022605\n",
      "\n",
      "Generation 7 - Current best internal CV score: -229.53492904022605\n",
      "\n",
      "Generation 8 - Current best internal CV score: -229.53492904022605\n",
      "\n",
      "Generation 9 - Current best internal CV score: -229.29971248707017\n",
      "\n",
      "Generation 10 - Current best internal CV score: -229.29971248707017\n",
      "\n",
      "Best pipeline: RidgeCV(PolynomialFeatures(input_matrix, degree=2, include_bias=False, interaction_only=False))\n",
      "Métricas de regresión para Circunferencia de la cintura (cm):\n",
      "MAE: 12.234976352727253\n",
      "MSE: 234.0997789733107\n",
      "RMSE: 15.30031957095376\n",
      "R²: 0.024464971941223324\n",
      "Pipeline exportado para Circunferencia de la cintura (cm)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -46.13554806137646\n",
      "\n",
      "Generation 2 - Current best internal CV score: -46.135530214349004\n",
      "\n",
      "Generation 3 - Current best internal CV score: -46.13425258990351\n",
      "\n",
      "Generation 4 - Current best internal CV score: -46.13425258990351\n",
      "\n",
      "Generation 5 - Current best internal CV score: -46.129267451341946\n",
      "\n",
      "Generation 6 - Current best internal CV score: -46.129267451341946\n",
      "\n",
      "Generation 7 - Current best internal CV score: -46.129267451341946\n",
      "\n",
      "Generation 8 - Current best internal CV score: -46.129267451341946\n",
      "\n",
      "Generation 9 - Current best internal CV score: -46.129267451341946\n",
      "\n",
      "Generation 10 - Current best internal CV score: -46.129267451341946\n",
      "\n",
      "Best pipeline: ElasticNetCV(RidgeCV(ElasticNetCV(StandardScaler(input_matrix), l1_ratio=0.8500000000000001, tol=0.01)), l1_ratio=0.55, tol=0.01)\n",
      "Métricas de regresión para Índice de masa corporal (kg/m²):\n",
      "MAE: 5.273354011789653\n",
      "MSE: 50.11859558344914\n",
      "RMSE: 7.079448819184241\n",
      "R²: 0.006525089632310688\n",
      "Pipeline exportado para Índice de masa corporal (kg/m²)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -409.9734762021984\n",
      "\n",
      "Generation 2 - Current best internal CV score: -409.9734762021984\n",
      "\n",
      "Generation 3 - Current best internal CV score: -409.9734762021984\n",
      "\n",
      "Generation 4 - Current best internal CV score: -409.9734760800766\n",
      "\n",
      "Generation 5 - Current best internal CV score: -409.9665997754758\n",
      "\n",
      "Generation 6 - Current best internal CV score: -409.96488454986854\n",
      "\n",
      "Generation 7 - Current best internal CV score: -409.9625051274344\n",
      "\n",
      "Generation 8 - Current best internal CV score: -409.9625051274344\n",
      "\n",
      "Generation 9 - Current best internal CV score: -409.9624805926542\n",
      "\n",
      "Generation 10 - Current best internal CV score: -409.9624805926542\n",
      "\n",
      "Best pipeline: ElasticNetCV(input_matrix, l1_ratio=0.65, tol=0.1)\n",
      "Métricas de regresión para Peso (kg):\n",
      "MAE: 15.309914583964607\n",
      "MSE: 418.82598715041723\n",
      "RMSE: 20.465238507049392\n",
      "R²: 0.07291783458239665\n",
      "Pipeline exportado para Peso (kg)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ¿Cómo afectan la edad y el nivel de actividad física la circunferencia de la cintura, el IMC y el peso? \n",
    "\n",
    "# Filtrar las columnas necesarias\n",
    "demografia_filtered = demografia[['ID', 'Edad en años al momento del examen', 'Género']]\n",
    "medidasCorporales_filtered = medidas[['ID', 'Circunferencia de la cintura (cm)', 'Índice de masa corporal (kg/m²)', 'Peso (kg)']]\n",
    "\n",
    "# Unir los datasets\n",
    "question3 = demografia_filtered.merge(medidasCorporales_filtered, on='ID', how='inner')\n",
    "\n",
    "# Definir grupos de edad\n",
    "bins = [0, 20, 40, 60, 80]\n",
    "labels = ['0-20', '21-30', '31-60', '60-80']\n",
    "question3['Grupo de Edad'] = pd.cut(question3['Edad en años al momento del examen'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Iterar sobre cada grupo de edad\n",
    "for grupo in labels:\n",
    "    print(f\"\\n--- Resultados para el grupo de edad {grupo} ---\")\n",
    "    \n",
    "    grupo_df = question3[question3['Grupo de Edad'] == grupo]\n",
    "    \n",
    "    # Definir variables predictoras y targets\n",
    "    X = grupo_df[['Edad en años al momento del examen', 'Género']]\n",
    "    y = grupo_df[['Circunferencia de la cintura (cm)', 'Índice de masa corporal (kg/m²)', 'Peso (kg)']]\n",
    "    \n",
    "    # Imputación de valores faltantes en X\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_imputed = imputer.fit_transform(X)\n",
    "    \n",
    "    # Definir los targets y exportar cada uno con TPOT\n",
    "    targets = {\n",
    "        'Circunferencia de la cintura (cm)': 'Circunferencia_Cintura',\n",
    "        'Índice de masa corporal (kg/m²)': 'IMC',\n",
    "        'Peso (kg)': 'Peso'\n",
    "    }\n",
    "    \n",
    "    for target, file_name in targets.items():\n",
    "        y_target = y[target].dropna()\n",
    "        X_filtered = X_imputed[~y[target].isna()]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_filtered, y_target, train_size=0.75, test_size=0.25, random_state=42)\n",
    "        \n",
    "        tpot_regressor = TPOTRegressor(verbosity=2, generations=10, population_size=20, random_state=42)\n",
    "        tpot_regressor.fit(X_train, y_train)\n",
    "        \n",
    "        # Realizar predicciones\n",
    "        y_pred = tpot_regressor.predict(X_test)\n",
    "        \n",
    "        # Calcular métricas\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Imprimir métricas para cada target\n",
    "        print(f\"Métricas de regresión para {target}:\")\n",
    "        print(f\"MAE: {mae}\")\n",
    "        print(f\"MSE: {mse}\")\n",
    "        print(f\"RMSE: {rmse}\")\n",
    "        print(f\"R²: {r2}\")\n",
    "        \n",
    "        # Exportar el pipeline con nombre de archivo sin caracteres especiales\n",
    "        tpot_regressor.export(f'best_pipeline_{file_name}_{grupo}_regression.py')\n",
    "        print(f\"Pipeline exportado para {target}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age Group: 0-20\n",
    "**Model for Waist Circumference (cm):**\n",
    "- **Model**: XGBRegressor with direct input matrix\n",
    "  - Uses a low max_depth of 1 and subsampling of 0.5 for generalization, focusing on minimal overfitting.\n",
    "- **Performance**:\n",
    "  - **MAE**: 9.31\n",
    "  - **MSE**: 163.20\n",
    "  - **RMSE**: 12.78\n",
    "  - **R²**: 0.52\n",
    "- **Pipeline Exported**: best_pipeline_Circunferencia_0-20_regression.py\n",
    "\n",
    "**Model for Body Mass Index (kg/m²):**\n",
    "- **Model**: KNeighborsRegressor with MaxAbsScaler pre-processing\n",
    "  - Uses 91 neighbors to capture local trends effectively in BMI prediction.\n",
    "- **Performance**:\n",
    "  - **MAE**: 3.63\n",
    "  - **MSE**: 25.97\n",
    "  - **RMSE**: 5.10\n",
    "  - **R²**: 0.33\n",
    "- **Pipeline Exported**: best_pipeline_IMC_0-20_regression.py\n",
    "\n",
    "**Model for Weight (kg):**\n",
    "- **Model**: KNeighborsRegressor with direct input matrix\n",
    "  - Employs 95 neighbors to increase robustness in weight prediction.\n",
    "  - This is the best model so far, showing the highest R² value among all groups.\n",
    "- **Performance**:\n",
    "  - **MAE**: 8.23\n",
    "  - **MSE**: 178.35\n",
    "  - **RMSE**: 13.35\n",
    "  - **R²**: 0.77\n",
    "- **Pipeline Exported**: best_pipeline_Peso_0-20_regression.py\n",
    "\n",
    "#### Age Group: 21-30\n",
    "**Model for Waist Circumference (cm):**\n",
    "- **Model**: ElasticNetCV with multiple pre-processing layers (RidgeCV and ZeroCount)\n",
    "  - Incorporates a high l1_ratio to enhance sparsity and reduce noise.\n",
    "- **Performance**:\n",
    "  - **MAE**: 14.76\n",
    "  - **MSE**: 338.59\n",
    "  - **RMSE**: 18.40\n",
    "  - **R²**: 0.03\n",
    "- **Pipeline Exported**: best_pipeline_Circunferencia_21-30_regression.py\n",
    "\n",
    "**Model for Body Mass Index (kg/m²):**\n",
    "- **Model**: ElasticNetCV with direct input matrix\n",
    "  - Focuses on a low l1_ratio for a more balanced regularization approach.\n",
    "- **Performance**:\n",
    "  - **MAE**: 6.29\n",
    "  - **MSE**: 63.32\n",
    "  - **RMSE**: 7.96\n",
    "  - **R²**: 0.01\n",
    "- **Pipeline Exported**: best_pipeline_IMC_21-30_regression.py\n",
    "\n",
    "**Model for Weight (kg):**\n",
    "- **Model**: XGBRegressor with direct input matrix\n",
    "  - Uses a low max_depth of 1 and a very low subsample of 0.1 for aggressive generalization.\n",
    "- **Performance**:\n",
    "  - **MAE**: 19.56\n",
    "  - **MSE**: 631.27\n",
    "  - **RMSE**: 25.13\n",
    "  - **R²**: 0.03\n",
    "- **Pipeline Exported**: best_pipeline_Peso_21-30_regression.py\n",
    "\n",
    "#### Age Group: 31-60\n",
    "**Model for Waist Circumference (cm):**\n",
    "- **Model**: DecisionTreeRegressor with direct input matrix\n",
    "  - Limited depth (max_depth=1) for high bias and simplicity.\n",
    "- **Performance**:\n",
    "  - **MAE**: 13.09\n",
    "  - **MSE**: 282.76\n",
    "  - **RMSE**: 16.82\n",
    "  - **R²**: 0.01\n",
    "- **Pipeline Exported**: best_pipeline_Circunferencia_31-60_regression.py\n",
    "\n",
    "**Model for Body Mass Index (kg/m²):**\n",
    "- **Model**: ElasticNetCV with RidgeCV pre-processing\n",
    "  - Uses a high l1_ratio for stronger regularization.\n",
    "- **Performance**:\n",
    "  - **MAE**: 5.90\n",
    "  - **MSE**: 62.26\n",
    "  - **RMSE**: 7.89\n",
    "  - **R²**: 0.01\n",
    "- **Pipeline Exported**: best_pipeline_IMC_31-60_regression.py\n",
    "\n",
    "**Model for Weight (kg):**\n",
    "- **Model**: RidgeCV with MaxAbsScaler pre-processing\n",
    "  - Adopts ridge regression to handle multicollinearity effectively.\n",
    "- **Performance**:\n",
    "  - **MAE**: 19.02\n",
    "  - **MSE**: 609.47\n",
    "  - **RMSE**: 24.69\n",
    "  - **R²**: 0.05\n",
    "- **Pipeline Exported**: best_pipeline_Peso_31-60_regression.py\n",
    "\n",
    "#### Age Group: 60-80\n",
    "**Model for Waist Circumference (cm):**\n",
    "- **Model**: RidgeCV with PolynomialFeatures pre-processing\n",
    "  - Leverages polynomial expansion to capture non-linear relationships.\n",
    "- **Performance**:\n",
    "  - **MAE**: 12.23\n",
    "  - **MSE**: 234.10\n",
    "  - **RMSE**: 15.30\n",
    "  - **R²**: 0.02\n",
    "- **Pipeline Exported**: best_pipeline_Circunferencia_60-80_regression.py\n",
    "\n",
    "**Model for Body Mass Index (kg/m²):**\n",
    "- **Model**: ElasticNetCV with multiple layers of pre-processing (RidgeCV, ElasticNetCV, StandardScaler)\n",
    "  - Focuses on stronger regularization to reduce complexity.\n",
    "- **Performance**:\n",
    "  - **MAE**: 5.27\n",
    "  - **MSE**: 50.12\n",
    "  - **RMSE**: 7.08\n",
    "  - **R²**: 0.01\n",
    "- **Pipeline Exported**: best_pipeline_IMC_60-80_regression.py\n",
    "\n",
    "**Model for Weight (kg):**\n",
    "- **Model**: ElasticNetCV with direct input matrix\n",
    "  - Uses moderate regularization for optimal performance.\n",
    "- **Performance**:\n",
    "  - **MAE**: 15.31\n",
    "  - **MSE**: 418.83\n",
    "  - **RMSE**: 20.47\n",
    "  - **R²**: 0.07\n",
    "- **Pipeline Exported**: best_pipeline_Peso_60-80_regression.py\n",
    "\n",
    "\n",
    "The models demonstrated varying performance across age groups, with the highest R² observed in weight prediction for the 0-20 group using KNeighborsRegressor, making it the best result so far. While predictive accuracy (R²) was generally modest, this tailored approach shows potential for improvement through more complex models or enhanced feature engineering. Each model's selection aligns with specific trends in each age group, capturing diverse patterns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Since these metrics have been the best results obtained so far, we will continue working to improve them further with additional models and Grid Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Resultados para el grupo de edad 0-20 ---\n",
      "\n",
      "Entrenando modelo: DecisionTree para grupo de edad 0-20...\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "\n",
      "Mejor modelo para 0-20 - DecisionTree - Circunferencia de la cintura:\n",
      "Mejores hiperparámetros: {'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 10}\n",
      "MAE: 8.233338898174964\n",
      "MSE: 178.1294545647934\n",
      "RMSE: 13.346514697283085\n",
      "R²: 0.7654718784530459\n",
      "\n",
      "Entrenando modelo: RandomForest para grupo de edad 0-20...\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "\n",
      "Mejor modelo para 0-20 - RandomForest - Circunferencia de la cintura:\n",
      "Mejores hiperparámetros: {'max_depth': 4, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "MAE: 8.297717799104433\n",
      "MSE: 178.8898121702944\n",
      "RMSE: 13.374969613808265\n",
      "R²: 0.7644707793290533\n",
      "\n",
      "Entrenando modelo: GradientBoosting para grupo de edad 0-20...\n",
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "\n",
      "Mejor modelo para 0-20 - GradientBoosting - Circunferencia de la cintura:\n",
      "Mejores hiperparámetros: {'learning_rate': 0.05, 'max_depth': 2, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "MAE: 8.254988932782286\n",
      "MSE: 179.5679184732698\n",
      "RMSE: 13.40029546216313\n",
      "R²: 0.7635779736005761\n",
      "\n",
      "--- Resultados para el grupo de edad 21-30 ---\n",
      "\n",
      "Entrenando modelo: DecisionTree para grupo de edad 21-30...\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "\n",
      "Mejor modelo para 21-30 - DecisionTree - Circunferencia de la cintura:\n",
      "Mejores hiperparámetros: {'max_depth': 3, 'min_samples_leaf': 5, 'min_samples_split': 10}\n",
      "MAE: 19.644505700250544\n",
      "MSE: 631.1579793973784\n",
      "RMSE: 25.12285770762113\n",
      "R²: 0.029577291570270114\n",
      "\n",
      "Entrenando modelo: RandomForest para grupo de edad 21-30...\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "\n",
      "Mejor modelo para 21-30 - RandomForest - Circunferencia de la cintura:\n",
      "Mejores hiperparámetros: {'max_depth': 4, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "MAE: 19.586481854572405\n",
      "MSE: 628.4594528856632\n",
      "RMSE: 25.069093579259366\n",
      "R²: 0.033726350113059134\n",
      "\n",
      "Entrenando modelo: GradientBoosting para grupo de edad 21-30...\n",
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "\n",
      "Mejor modelo para 21-30 - GradientBoosting - Circunferencia de la cintura:\n",
      "Mejores hiperparámetros: {'learning_rate': 0.01, 'max_depth': 2, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "MAE: 19.508571982642653\n",
      "MSE: 626.4747199001702\n",
      "RMSE: 25.029477020109113\n",
      "R²: 0.036777931527162244\n",
      "\n",
      "--- Resultados para el grupo de edad 31-60 ---\n",
      "\n",
      "Entrenando modelo: DecisionTree para grupo de edad 31-60...\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "\n",
      "Mejor modelo para 31-60 - DecisionTree - Circunferencia de la cintura:\n",
      "Mejores hiperparámetros: {'max_depth': 3, 'min_samples_leaf': 5, 'min_samples_split': 10}\n",
      "MAE: 19.01201440902105\n",
      "MSE: 611.3066425302719\n",
      "RMSE: 24.72461612503361\n",
      "R²: 0.051261901923222\n",
      "\n",
      "Entrenando modelo: RandomForest para grupo de edad 31-60...\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "\n",
      "Mejor modelo para 31-60 - RandomForest - Circunferencia de la cintura:\n",
      "Mejores hiperparámetros: {'max_depth': 4, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "MAE: 19.038500740007432\n",
      "MSE: 613.0478144737863\n",
      "RMSE: 24.759802391654627\n",
      "R²: 0.048559631011725\n",
      "\n",
      "Entrenando modelo: GradientBoosting para grupo de edad 31-60...\n",
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[10/26/24 00:44:50] </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> C:\\Program Files\\Python311\\Lib\\site-packages\\numpy\\ma\\core.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2881</span>:    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">warnings.py:110</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         RuntimeWarning: invalid value encountered in cast                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>           _data = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">np.array</span><span style=\"font-weight: bold\">(</span>data, <span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #800080; text-decoration-color: #800080\">dtype</span>, <span style=\"color: #808000; text-decoration-color: #808000\">copy</span>=<span style=\"color: #800080; text-decoration-color: #800080\">copy</span>,                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[10/26/24 00:44:50]\u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m C:\\Program Files\\Python311\\Lib\\site-packages\\numpy\\ma\\core.py:\u001b[1;36m2881\u001b[0m:    \u001b[2mwarnings.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m110\u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         RuntimeWarning: invalid value encountered in cast                      \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m           _data = \u001b[1;35mnp.array\u001b[0m\u001b[1m(\u001b[0mdata, \u001b[33mdtype\u001b[0m=\u001b[35mdtype\u001b[0m, \u001b[33mcopy\u001b[0m=\u001b[35mcopy\u001b[0m,                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mejor modelo para 31-60 - GradientBoosting - Circunferencia de la cintura:\n",
      "Mejores hiperparámetros: {'learning_rate': 0.01, 'max_depth': 2, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "MAE: 19.080817560212914\n",
      "MSE: 612.4255279961254\n",
      "RMSE: 24.747232734108383\n",
      "R²: 0.04952540963770424\n",
      "\n",
      "--- Resultados para el grupo de edad 60-80 ---\n",
      "\n",
      "Entrenando modelo: DecisionTree para grupo de edad 60-80...\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "\n",
      "Mejor modelo para 60-80 - DecisionTree - Circunferencia de la cintura:\n",
      "Mejores hiperparámetros: {'max_depth': 3, 'min_samples_leaf': 5, 'min_samples_split': 10}\n",
      "MAE: 15.313635440684667\n",
      "MSE: 418.9057222339232\n",
      "RMSE: 20.46718647576953\n",
      "R²: 0.07274133891081858\n",
      "\n",
      "Entrenando modelo: RandomForest para grupo de edad 60-80...\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "\n",
      "Mejor modelo para 60-80 - RandomForest - Circunferencia de la cintura:\n",
      "Mejores hiperparámetros: {'max_depth': 4, 'min_samples_leaf': 1, 'min_samples_split': 15, 'n_estimators': 100}\n",
      "MAE: 15.335322262401112\n",
      "MSE: 419.88293983451746\n",
      "RMSE: 20.491045357290034\n",
      "R²: 0.07057824245301036\n",
      "\n",
      "Entrenando modelo: GradientBoosting para grupo de edad 60-80...\n",
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[10/26/24 00:44:56] </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> C:\\Program Files\\Python311\\Lib\\site-packages\\numpy\\ma\\core.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2881</span>:    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">warnings.py:110</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         RuntimeWarning: invalid value encountered in cast                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>           _data = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">np.array</span><span style=\"font-weight: bold\">(</span>data, <span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #800080; text-decoration-color: #800080\">dtype</span>, <span style=\"color: #808000; text-decoration-color: #808000\">copy</span>=<span style=\"color: #800080; text-decoration-color: #800080\">copy</span>,                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[10/26/24 00:44:56]\u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m C:\\Program Files\\Python311\\Lib\\site-packages\\numpy\\ma\\core.py:\u001b[1;36m2881\u001b[0m:    \u001b[2mwarnings.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m110\u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         RuntimeWarning: invalid value encountered in cast                      \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m           _data = \u001b[1;35mnp.array\u001b[0m\u001b[1m(\u001b[0mdata, \u001b[33mdtype\u001b[0m=\u001b[35mdtype\u001b[0m, \u001b[33mcopy\u001b[0m=\u001b[35mcopy\u001b[0m,                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mejor modelo para 60-80 - GradientBoosting - Circunferencia de la cintura:\n",
      "Mejores hiperparámetros: {'learning_rate': 0.05, 'max_depth': 2, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "MAE: 15.342557920199816\n",
      "MSE: 418.812091902471\n",
      "RMSE: 20.464899020089764\n",
      "R²: 0.0729485920734555\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Modelos para probar\n",
    "models = {\n",
    "    'DecisionTree': DecisionTreeRegressor(random_state=42),\n",
    "    'RandomForest': RandomForestRegressor(random_state=42),\n",
    "    'GradientBoosting': GradientBoostingRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# Hiperparámetros extendidos\n",
    "param_grids = {\n",
    "    'DecisionTree': {\n",
    "        'max_depth': [3, 5, 7, 9],\n",
    "        'min_samples_split': [10, 14, 20],\n",
    "        'min_samples_leaf': [5, 10,14,20]\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [4, 6, 10],\n",
    "        'min_samples_split': [2, 5, 10, 15],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'GradientBoosting': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'max_depth': [2, 4, 5, 6],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Iterar sobre cada grupo de edad\n",
    "for grupo in labels:\n",
    "    print(f\"\\n--- Resultados para el grupo de edad {grupo} ---\")\n",
    "    \n",
    "    grupo_df = question3[question3['Grupo de Edad'] == grupo]\n",
    "    \n",
    "    # Definir variables predictoras y target\n",
    "    X = grupo_df[['Edad en años al momento del examen', 'Género']]\n",
    "    y = grupo_df['Peso (kg)']  # Ejemplo con \"Circunferencia de la cintura (cm)\"\n",
    "    \n",
    "    # Imputación de valores faltantes en X\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_imputed = imputer.fit_transform(X)\n",
    "    \n",
    "    # Filtrar filas con valores no nulos en y\n",
    "    mask = ~y.isna()\n",
    "    X_filtered = X_imputed[mask]\n",
    "    y_filtered = y[mask]\n",
    "    \n",
    "    # División de datos\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_filtered, y_filtered, train_size=0.75, test_size=0.25, random_state=42)\n",
    "    \n",
    "    # Probar cada modelo\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nEntrenando modelo: {model_name} para grupo de edad {grupo}...\")\n",
    "        \n",
    "        # Configurar GridSearchCV con validación cruzada\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grids[model_name],\n",
    "            scoring='neg_mean_squared_error',\n",
    "            cv=5,\n",
    "            n_jobs=-1,\n",
    "            verbose=2\n",
    "        )\n",
    "        \n",
    "        # Ajustar modelo\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Mejor modelo\n",
    "        best_model = grid_search.best_estimator_\n",
    "        \n",
    "        # Evaluar el mejor modelo con el conjunto de prueba\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Imprimir resultados\n",
    "        print(f\"\\nMejor modelo para {grupo} - {model_name} - Circunferencia de la cintura:\")\n",
    "        print(f\"Mejores hiperparámetros: {grid_search.best_params_}\")\n",
    "        print(f\"MAE: {mae}\")\n",
    "        print(f\"MSE: {mse}\")\n",
    "        print(f\"RMSE: {rmse}\")\n",
    "        print(f\"R²: {r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age Group: 0-20\n",
    "**Model for Waist Circumference (cm) - Best Model: DecisionTree**\n",
    "- **Model**: DecisionTreeRegressor\n",
    "  - **Best Hyperparameters**: max_depth=5, min_samples_leaf=5, min_samples_split=10\n",
    "  - Achieved the highest R² among all models for this age group.\n",
    "- **Performance**:\n",
    "  - **MAE**: 8.23\n",
    "  - **MSE**: 178.13\n",
    "  - **RMSE**: 13.35\n",
    "  - **R²**: 0.77\n",
    "- **Pipeline Exported**: best_pipeline_Circunferencia_0-20_DecisionTree.py\n",
    "\n",
    "**Alternative Models for Waist Circumference (cm):**\n",
    "- **RandomForest**\n",
    "  - **Best Hyperparameters**: max_depth=4, min_samples_leaf=1, min_samples_split=2, n_estimators=50\n",
    "  - **Performance**:\n",
    "    - **MAE**: 8.30\n",
    "    - **MSE**: 178.89\n",
    "    - **RMSE**: 13.37\n",
    "    - **R²**: 0.76\n",
    "  - **Pipeline Exported**: best_pipeline_Circunferencia_0-20_RandomForest.py\n",
    "- **GradientBoosting**\n",
    "  - **Best Hyperparameters**: learning_rate=0.05, max_depth=2, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
    "  - **Performance**:\n",
    "    - **MAE**: 8.25\n",
    "    - **MSE**: 179.57\n",
    "    - **RMSE**: 13.40\n",
    "    - **R²**: 0.76\n",
    "  - **Pipeline Exported**: best_pipeline_Circunferencia_0-20_GradientBoosting.py\n",
    "\n",
    "#### Age Group: 21-30\n",
    "**Model for Waist Circumference (cm) - Best Model: GradientBoosting**\n",
    "- **Model**: GradientBoostingRegressor\n",
    "  - **Best Hyperparameters**: learning_rate=0.01, max_depth=2, min_samples_leaf=1, min_samples_split=2, n_estimators=200\n",
    "  - Achieved the best R² among models for this age group.\n",
    "- **Performance**:\n",
    "  - **MAE**: 19.51\n",
    "  - **MSE**: 626.47\n",
    "  - **RMSE**: 25.03\n",
    "  - **R²**: 0.04\n",
    "- **Pipeline Exported**: best_pipeline_Circunferencia_21-30_GradientBoosting.py\n",
    "\n",
    "**Alternative Models for Waist Circumference (cm):**\n",
    "- **DecisionTree**\n",
    "  - **Best Hyperparameters**: max_depth=3, min_samples_leaf=5, min_samples_split=10\n",
    "  - **Performance**:\n",
    "    - **MAE**: 19.64\n",
    "    - **MSE**: 631.16\n",
    "    - **RMSE**: 25.12\n",
    "    - **R²**: 0.03\n",
    "  - **Pipeline Exported**: best_pipeline_Circunferencia_21-30_DecisionTree.py\n",
    "- **RandomForest**\n",
    "  - **Best Hyperparameters**: max_depth=4, min_samples_leaf=1, min_samples_split=2, n_estimators=200\n",
    "  - **Performance**:\n",
    "    - **MAE**: 19.59\n",
    "    - **MSE**: 628.46\n",
    "    - **RMSE**: 25.07\n",
    "    - **R²**: 0.03\n",
    "  - **Pipeline Exported**: best_pipeline_Circunferencia_21-30_RandomForest.py\n",
    "\n",
    "#### Age Group: 31-60\n",
    "**Model for Waist Circumference (cm) - Best Model: DecisionTree**\n",
    "- **Model**: DecisionTreeRegressor\n",
    "  - **Best Hyperparameters**: max_depth=3, min_samples_leaf=5, min_samples_split=10\n",
    "  - Performed slightly better than other models for this age group.\n",
    "- **Performance**:\n",
    "  - **MAE**: 19.01\n",
    "  - **MSE**: 611.31\n",
    "  - **RMSE**: 24.72\n",
    "  - **R²**: 0.05\n",
    "- **Pipeline Exported**: best_pipeline_Circunferencia_31-60_DecisionTree.py\n",
    "\n",
    "**Alternative Models for Waist Circumference (cm):**\n",
    "- **RandomForest**\n",
    "  - **Best Hyperparameters**: max_depth=4, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
    "  - **Performance**:\n",
    "    - **MAE**: 19.04\n",
    "    - **MSE**: 613.05\n",
    "    - **RMSE**: 24.76\n",
    "    - **R²**: 0.05\n",
    "  - **Pipeline Exported**: best_pipeline_Circunferencia_31-60_RandomForest.py\n",
    "- **GradientBoosting**\n",
    "  - **Best Hyperparameters**: learning_rate=0.01, max_depth=2, min_samples_leaf=1, min_samples_split=2, n_estimators=200\n",
    "  - **Performance**:\n",
    "    - **MAE**: 19.08\n",
    "    - **MSE**: 612.43\n",
    "    - **RMSE**: 24.75\n",
    "    - **R²**: 0.05\n",
    "  - **Pipeline Exported**: best_pipeline_Circunferencia_31-60_GradientBoosting.py\n",
    "\n",
    "#### Age Group: 60-80\n",
    "**Model for Waist Circumference (cm) - Best Model: GradientBoosting**\n",
    "- **Model**: GradientBoostingRegressor\n",
    "  - **Best Hyperparameters**: learning_rate=0.05, max_depth=2, min_samples_leaf=1, min_samples_split=2, n_estimators=50\n",
    "  - Achieved the highest R² among models for this age group.\n",
    "- **Performance**:\n",
    "  - **MAE**: 15.34\n",
    "  - **MSE**: 418.81\n",
    "  - **RMSE**: 20.46\n",
    "  - **R²**: 0.07\n",
    "- **Pipeline Exported**: best_pipeline_Circunferencia_60-80_GradientBoosting.py\n",
    "\n",
    "**Alternative Models for Waist Circumference (cm):**\n",
    "- **DecisionTree**\n",
    "  - **Best Hyperparameters**: max_depth=3, min_samples_leaf=5, min_samples_split=10\n",
    "  - **Performance**:\n",
    "    - **MAE**: 15.31\n",
    "    - **MSE**: 418.91\n",
    "    - **RMSE**: 20.47\n",
    "    - **R²**: 0.07\n",
    "  - **Pipeline Exported**: best_pipeline_Circunferencia_60-80_DecisionTree.py\n",
    "- **RandomForest**\n",
    "  - **Best Hyperparameters**: max_depth=4, min_samples_leaf=1, min_samples_split=15, n_estimators=100\n",
    "  - **Performance**:\n",
    "    - **MAE**: 15.34\n",
    "    - **MSE**: 419.88\n",
    "    - **RMSE**: 20.49\n",
    "    - **R²**: 0.07\n",
    "  - **Pipeline Exported**: best_pipeline_Circunferencia_60-80_RandomForest.py\n",
    "\n",
    "The models demonstrated consistent performance across all age groups, with the best results achieved for the 0-20 age group using the DecisionTree model. The highest R² value (0.77) was observed for waist circumference prediction in the 0-20 age group. GradientBoosting models showed superior performance in the older age groups, while DecisionTree models generally performed better in younger groups. RandomForest models provided competitive results but slightly underperformed compared to the best models in each age group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2187 candidates, totalling 10935 fits\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "\n",
      "Resultados del modelo de stacking:\n",
      "MAE: 15.274331479498121\n",
      "MSE: 416.759315960418\n",
      "RMSE: 20.414683831997447\n",
      "R²: 0.07749246476488958\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.linear_model import ElasticNetCV, RidgeCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Supongamos que tienes X_train, y_train, X_test, y_test listos\n",
    "\n",
    "# 1. Optimizar XGBRegressor individualmente\n",
    "xgb = XGBRegressor(random_state=42)\n",
    "xgb_param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [1, 2, 3],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'subsample': [0.5, 0.7, 0.9],\n",
    "    'colsample_bytree': [0.5, 0.7, 1.0],\n",
    "    'reg_alpha': [0, 1, 5],\n",
    "    'reg_lambda': [1, 5, 10]\n",
    "}\n",
    "grid_xgb = GridSearchCV(xgb, xgb_param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)\n",
    "grid_xgb.fit(X_train, y_train)\n",
    "best_xgb = grid_xgb.best_estimator_\n",
    "\n",
    "# 2. Optimizar KNeighborsRegressor individualmente\n",
    "knn = KNeighborsRegressor()\n",
    "knn_param_grid = {\n",
    "    'n_neighbors': [10, 20, 30, 40],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "grid_knn = GridSearchCV(knn, knn_param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)\n",
    "grid_knn.fit(X_train, y_train)\n",
    "best_knn = grid_knn.best_estimator_\n",
    "\n",
    "# 3. Optimizar ElasticNetCV individualmente\n",
    "elasticnet = ElasticNetCV(cv=5)\n",
    "elasticnet_param_grid = {\n",
    "    'l1_ratio': [0.1, 0.5, 0.9],\n",
    "    'max_iter': [1000],\n",
    "    'tol': [0.0001, 0.001, 0.01]\n",
    "}\n",
    "grid_elasticnet = GridSearchCV(elasticnet, elasticnet_param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)\n",
    "grid_elasticnet.fit(X_train, y_train)\n",
    "best_elasticnet = grid_elasticnet.best_estimator_\n",
    "\n",
    "# 4. Crear el StackingRegressor con los modelos optimizados\n",
    "stacking_model = StackingRegressor(\n",
    "    estimators=[\n",
    "        ('xgb', best_xgb),\n",
    "        ('elasticnet', best_elasticnet),\n",
    "        ('knn', best_knn)\n",
    "    ],\n",
    "    final_estimator=RidgeCV(),\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# Ajustar el modelo de StackingRegressor\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# 5. Evaluación del modelo\n",
    "y_pred = stacking_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nResultados del modelo de stacking:\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R²: {r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking Model Results\n",
    "**Model for Waist Circumference (cm) - Stacking Regressor**\n",
    "- **Model**: StackingRegressor combining XGBRegressor, ElasticNetCV, and KNeighborsRegressor\n",
    "  - **Final Estimator**: RidgeCV\n",
    "  - This model combines multiple individual models to leverage the strengths of each. The XGBRegressor captures non-linear relationships, ElasticNetCV provides regularization to reduce overfitting, and KNeighborsRegressor accounts for local patterns.\n",
    "- **Performance**:\n",
    "  - **MAE**: 15.27\n",
    "  - **MSE**: 416.76\n",
    "  - **RMSE**: 20.41\n",
    "  - **R²**: 0.08\n",
    "- **Pipeline Exported**: best_pipeline_stacking_Circunferencia.py\n",
    "\n",
    "The StackingRegressor achieved the best performance among all tested models, with an R² of 0.08, indicating a slight improvement over individual models. The combination of XGBRegressor, ElasticNetCV, and KNeighborsRegressor, finalized with RidgeCV, suggests that ensemble learning can be more effective than single-model approaches for this dataset, particularly in capturing complex relationships.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection for Regression\n",
    "\n",
    "#### Best Regression Model\n",
    "**Age Group: 0-20**\n",
    "\n",
    "- **Model**: `DecisionTreeRegressor`\n",
    "  - **Reason for Selection**: Among the regression models evaluated across age groups, the `DecisionTreeRegressor` achieved the highest R² of **0.77** for waist circumference prediction in the 0-20 age group. With optimized hyperparameters (`max_depth=5`, `min_samples_leaf=5`, `min_samples_split=10`), it delivered strong performance with minimal overfitting, making it the most suitable regression model overall.\n",
    "  - **Performance Metrics**:\n",
    "    - **MAE**: 8.23\n",
    "    - **MSE**: 178.13\n",
    "    - **RMSE**: 13.35\n",
    "    - **R²**: 0.77\n",
    "  - **Exported Pipeline**: `best_pipeline_Circunferencia_0-20_regression.py`\n",
    "\n",
    "#### Best Overall Regression Performance\n",
    "- The **DecisionTreeRegressor** stands out for its balance of interpretability and predictive accuracy, particularly for younger populations. Its high R² suggests that it effectively captures key relationships, making it the top choice for regression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection for Classification\n",
    "\n",
    "#### Best Classification Model\n",
    "**Model**: `XGBoostClassifier`\n",
    "- **Reason for Selection**: Among the classification models evaluated for predicting depression risk, the `XGBoostClassifier` demonstrated the highest overall accuracy of **60%**. It excelled in detecting the 'nulo' category (100% recall), which was the most prevalent class, although it struggled with minority classes. Despite its limitations, XGBoost provided the best balance of accuracy and precision, making it the top choice for classification.\n",
    "- **Performance Metrics**:\n",
    "  - **Accuracy**: 60%\n",
    "  - **Macro Avg F1-Score**: 0.13\n",
    "  - **Weighted Avg F1-Score**: 0.45\n",
    "  - **Recall for Class 0**: 100%\n",
    "  - **Recall for Other Classes**: Near zero, indicating challenges with minority class prediction.\n",
    "- **Description**: The XGBoost model was optimized for log loss, focusing on improving overall accuracy while handling class imbalance. It performed well in identifying the majority class but requires further tuning for better sensitivity to other categories.\n",
    "\n",
    "#### Best Overall Classification Performance\n",
    "- The **XGBoostClassifier** stands out as the most accurate model among the classifiers tested. While it performs well in recognizing the most common class, enhancements such as oversampling, SMOTE, or class weighting are necessary to achieve better performance across all classes. This model offers a foundation for improving the prediction of depression risk in a more balanced manner.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase 5: Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase 5: Deployment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kedro (nhanes)",
   "language": "python",
   "name": "kedro_nhanes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
